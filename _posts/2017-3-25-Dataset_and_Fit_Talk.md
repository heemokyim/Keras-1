---
layout: post
title:  "학습인자와 데이터셋 이야기"
author: Taeyoung, Kim
date:   2017-03-25 12:00:00
categories: Keras
comments: true
image: http://tykimos.github.com/Keras/warehouse/2017-3-25-Dataset_and_Fit_Talk_6.png
---
본 강좌에서는 딥러닝 모델 학습 시 설정하는 학습인자와 어떻게 데이터셋을 구성하는 지에 대해서 알아보겠습니다. 딥러닝 모델이 학습하는 방식이랑 사람이 학습하는 방식이랑 비슷하므로 수능 공부하는 것에 비유를 들어서 설명해봤습니다.

---

## 학습인자

케라스에서 만든 모델을 학습할 때는 fit()함수를 사용합니다. 

    model.fit(x, y, batch_size=32, epochs=10)

주요인자는 다음과 같습니다. 
- x : 입력 데이터
- y : 라벨 값
- batch_size : 몇 개의 샘플로 가중치를 갱신할 것인지 지정
- epochs : 학습 반복 횟수

학습에 관련된 인자이므로 시험 공부하는 것에 비유를 해보겠습니다. 먼저 모의고사 1회분을 가지고 학습해봅시다. 이 1회분은 100문항이 있고, 해답지도 제공합니다. 해답지가 없으면 학습이 안 됩니다. 위의 주요인자은 다음과 같이 비유할 수 있습니다. 

### x
100문항의 문제들입니다.

### y
100문항의 답들입니다.

### batch_size(배치사이즈)
몇 문항을 보고 해답을 맞추어볼까 입니다. 배치사이즈가 100이면 전체를 다 풀고 난 뒤에 해답을 맞춰보는 것입니다. 우리가 해답을 맞춰볼 때 '아하, 이렇게 푸는구나'라고 느끼면서 학습하는 것처럼 모델도 이러한 과정을 통해 가중치가 갱신됩니다. 배치사이즈가 1이면 한 문제 풀고 해답 맞춰보고 또 한 문제 풀고 맞춰보고 하는 것입니다. 배치사이즈가 10이면 열 문제씩 풀어보고 해답 맞춰보는 것입니다. 100문제 다 풀고 해답을 맞히는 것과 1문제씩 풀고 해답을 맞히는 것은 어떤 차이가 있을까요? 언뜻 생각해서는 별 반 차이가 없어 보입니다. 하지만 모의고사 1회분에 비슷한 문항이 있다고 가정했을 때, 배치사이즈가 100일 때는 다 풀어보고 해답을 맞춰보기 때문에 한 문제를 틀릴 경우 이후 유사 문제를 모두 틀릴 경우가 많습니다.

![img](http://tykimos.github.com/Keras/warehouse/2017-3-25-Dataset_and_Fit_Talk_1.png)

배치사이즈가 1일때는 한 문제씩 풀어보고 해답을 맞춰보기 때문에 유사문제 중 첫 문제를 틀렸다고 하더라도 해답을 보면서 학습하게 되므로 나머지 문제는 맞추게 됩니다. 

![img](http://tykimos.github.com/Keras/warehouse/2017-3-25-Dataset_and_Fit_Talk_2.png)

자 그럼 이 배치사이즈가 어떨 때 학습효과가 좋을까요? 사람이 학습하는 것이랑 비슷합니다. 100문항 다 풀고 해답과 맞추어보려면 문제가 무엇이었는지 다 기억을 해야 맞춰보면서 학습이 되겠죠? 기억력(용량)이 커야합니다. 1문항씩 풀고 해답 맞추면 학습은 꼼꼼히 잘 되겠지만 시간이 너무 걸리겠죠? 그리고 해답지를 보다가 다음 문제의 답을 봐버리는 불상사가 생기겠죠(이것은 컴퓨터에서는 일어나지 않는 일입니다.)


### epchos(에포크)
에포크는 모의고사 1회분을 몇 번 풀어볼까 입니다. 즉 100문항의 문제들을 몇 번이나 반복해서 풀어보는 지 정하는 것입니다. 에포크가 10이면 모의고사 1회분을 10번 푸는 것입니다. 처음에는 같은 문제를 반복적으로 풀어보는 것이 무슨 효과가 있는 지 의문이 들었지만 우리가 같은 문제집을 여러 번 풀면서 점차 학습되듯이 모델도 같은 데이터셋으로 반복적으로 가중치를 갱신하면서 모델이 학습됩니다. 모의고사 1회분을 10번 푸는 것과 서로 다른 모의고사 10회분을 1번 푸는 것과는 어떤 차이가 있을까요? 이것은 분야에 따라 데이터특성에 따라 다를 것이라고 생각합니다. 잡다한 문제를 많이 푸는 것보다 양질의 문제를 여러 번 푸는 것이 도움이 된다고 생각합니다. 피아노를 배울 때도 기본 곡을 반복적으로 학습하면 다양한 악보도 쉽게 보는 반면 이곡 저곡 연습하면 제대로 익히기 쉽지 않습니다. 이런 문제를 제외하고도 현실적으로 데이터를 구하기가 쉽지 않기 때문에 제한된 데이터셋으로 반복적으로 학습하는 것이 효율적입니다. 그럼 이 에포크를 무조건 크게 하면 좋을까요? 하나의 문제집만 계속 학습하면 오히려 역효과가 발생할 수 있습니다. 피아노 칠 때 처음에 곡을 연습할 때는 악보를 보면서 치다가 다음엔 악보안보고도 치고, 나중엔 눈감고도 칩니다. 눈감고만 치다보면 악보 보는 법을 까먹게 되고 다른 곡을 치지 못하는 지경에 이릅니다. 연습한 곡은 완벽하게 칠 지 몰라도 다른 곡은 치지 못하는 상태가 됩니다. 우린 이것을 오버피팅(overfitting)이라고 부릅니다. 악보보고 잘 치는 정도에서 그만 연습하는 것이 더 좋았을 수 있습니다. 실제로 모델을 학습할 때도 오버피팅이 일어나는 지 체크하다가 조짐이 보이면 학습을 중단합니다. 

---

## 데이터셋

이번에는 데이터셋을 어떻게 구성하고 모델을 어떻게 검증할 지 알아보겠습니다.

당신이 고등학교 담임 선생님이고 수능 볼 학생이 3명이 있다고 가정을 해봅시다. 이 세 명 중 누가 수능을 가장 잘 볼지 알아 맞혀보도록 하겠습니다. 당신에게는 모의고사 5회분과 작년 수능 문제 1회분을 가지고 있습니다. 다음과 같이 비유될 수 있습니다. 
- 모의고사 5회분 : 훈련셋
- 작년 수능 문제 : 시험셋
- 학생 3명 : 모델 3개
- 올해 수능 문제 : 실제 데이터 (아직 보지 못한 데이터)

![img](http://tykimos.github.com/Keras/warehouse/2017-3-25-Dataset_and_Fit_Talk_3.png)

참고로 '학습'의 의미는 문제와 해답지를 같이 줘서 풀고 맞춰봐라는 것이고 '평가'의 의미는 문제만 주고 풀게한 뒤 답을 맞춰봐서 점수를 계산하는 것입니다. 이 과정에서는 학생은 점수만 얻지 답을 맞춰가면서 오답정리를 하지 않기 때문에 학습되지 않습니다.

### 경우 1
올해 수능을 가장 볼 수 있는 학생을 고르는 가장 쉬운 방법은 무엇일까요? 바로 올해 수능 문제로 시험 쳐서 점수가 가장 높은 학생을 고르면 됩니다. 하지만 안타깝게도 올해 수능 문제를 수능 전에 알아낼 수 없습니다.

![img](http://tykimos.github.com/Keras/warehouse/2017-3-25-Dataset_and_Fit_Talk_4.png)

### 경우 2
그럼 모의고사 5회분을 학습시킨 뒤 작년 수능 문제로 평가해서 가장 점수가 높은 학생을 고를까요? 작년 수능 문제로 점수가 높다고 해서 올해 수능도 점수가 높은지는 장담은 못하지만 그나마 해볼 수 있는 평가 방법입니다. 여기서 공정한 평가를 위해서 작년 수능 문제는 학생들에게 학습시키면 안됩니다. 

![img](http://tykimos.github.com/Keras/warehouse/2017-3-25-Dataset_and_Fit_Talk_5.png)

### 경우 3
학생들이 스스로 학습 상태를 확인하고 학습 방법을 바꾸거나 학습을 그만하거나 하는 시점을 정할 수 없을까요? 이를 위해서 검증셋이 필요합니다. 학습할 때는 모의고사 1회~4회만 사용하고, 모의고사 5회분을 검증셋으로 두어 학습할 때는 사용하지 않습니다. 이렇게 하면 두 가지 효과를 얻을 수 있습니다. 
학습 방법을 바꾼 후 훈련셋으로 학습을 해보고 검증셋으로 평가해볼 수 있습니다. 검증셋으로 가장 높은 평가를 받은 학습 방법이 최적의 학습 방법이라고 생각하면 됩니다. 이러한 학습 방법을 결정하는 파라미터를 하이퍼파라미터(hyperparameter)라고 하고 최적의 학습 방법을 찾아가는 것을 하이퍼파라미터 튜닝이라고 합니다.
훈련셋을 몇 번 반복해서 학습할 것인가를 정하는 것이 에포크라고 했습니다. 얼마정보 반복 학습이 좋을 지를 정하기 위해서 검증셋을 사용할 수 있습니다. 초기에는 에포크가 증가될수록 검증셋의 평가도 높아집니다. 그러다가 에포크가 어느 이상 증가되면, 더이상 검증셋의 평가는 높아지지 않고 오버피팅이 되어 오히려 떨어집니다. 이 시점에서 학습을 그만두면 됩니다.

![img](http://tykimos.github.com/Keras/warehouse/2017-3-25-Dataset_and_Fit_Talk_6.png)

### 경우 4
모의고사 5회분으로만 검증셋을 사용할 경우 여러가지 문제가 발생할 수 있습니다. 

- 모의고사 5회분에서 출제가 되지 않는 분야가 있을 수 있습니다.
- 작년 수능이나 올해 수능 문제와 많이 다를 수도 있습니다. 
- 모의고사 1회~4회분과의 난이도 및 범위가 다를 수도 있습니다. 

이런 이유로 모의고사 5회분으로만 검증셋을 사용하기에는 객관적인 평가가 이루어졌다고 보기 힘듭니다.  이 때 사용하는 것이 교차검증(cross-validation) 입니다. 하는 방법은 다음과 같습니다. 

- 모의고사 1회~4회분을 학습한 뒤 모의고사 5회분으로 평가를 수행합니다. 
- 학습된 상태를 초기화한 후 다시 모의고사 1, 2, 3, 5회분을 학습한 뒤 4회분으로 검증합니다.
- 학습된 상태를 초기화한 후 다시 모의고사 1, 2, 4, 5회분을 학습한 뒤 3회분으로 검증합니다.
- 학습된 상태를 초기화한 후 다시 모의고사 1, 3, 4, 5회분을 학습한 뒤 2회분으로 검증합니다.
- 학습된 상태를 초기화한 후 다시 모의고사 2, 2, 4, 5회분을 학습한 뒤 1회분으로 검증합니다.

다섯번의 검증결과를 평균내어 이 평균값으로 성능을 정의합니다.

![img](http://tykimos.github.com/Keras/warehouse/2017-3-25-Dataset_and_Fit_Talk_7.png)

단 교차검증은 계산량이 많기 때문에 데이터수가 많지 않을 때 사용합니다.

그렇다고 작년 수능 문제가 무의미 하지는 않습니다. 담임은 올해 수능 문제를 알 수는 없으므로 평가 시에 사용할 최소한의 문제들입니다. 담임은 작년 수능 문제로 학습을 시키거나 이것으로 테스트해서 가장 높은 점수를 받았다고 그 학생을 고르지는 않겠지만, 그나마 실전에서 나왔던 문제니 평가지표로는 삼아야 합니다. 단 기출문제를 평가지표로 삼기위해서는 기출문제를 학생들에게 학습시키게 해서는 안됩니다.

---

## Q & A

Q1) 검증셋이 학습 시에 사용되기 때문에 가중치 갱신에 영향을 미치나요?

A1) 아닙니다. 학습 시에 현재 학습된 상태에서 평가로만 사용되므로 가중치 갱신은 일어나지 않습니다.

Q2) 교차검증 시에 검증셋을 바꿀 때 마다 학습된 상태를 초기화해야 하나요?

A2) 맞습니다. 첫번째 검증 시 모의고사 5회분을 사용하였고, 두번째 검증 시 모의고사 4회분을 사용할 경우, 첫번째 검증 시에 모의고사 1회~4회분을 학습한 상태이기 때문에 만약 초기화하지 않으면 두번째 검증 시에 이미 모의고사 4회분을 학습한 상태에서 검증하기 때문에 공정한 평가라고 보기 힘듭니다.

---

### 결론

저는 딥러닝 모델을 처음 접할 때 어떻게 학습되는 지 이해하기가 쉽지 않았습니다. 나중에 이해를 한 뒤에는 사람이 학습하는 방식과 크게 다를 바가 없다는 것을 알게 되었습니다. 그리고 데이터셋을 어떻게 설계할 것인 지, 어떻게 검증을 해야될 것인지도 중요한 요소입니다. 학생이 어떤 학습지로 공부를 해야할 지 어떤 기준으로 평가를 해야할지가 중요한 것 처럼 말입니다. 공부를 잘하는 비법 책도 많은 것 처럼 딥러닝 모델도 학습 방법에 대해서 연구가 많이 되고 있습니다.

---

### 같이 보기

* [강좌 목차](https://tykimos.github.io/Keras/2017/01/27/Keras_Lecture_Plan/)
* 이전 : [딥러닝 이야기/케라스 이야기](https://tykimos.github.io/Keras/2017/01/27/Keras_Talk/)
* 다음 : [딥러닝 이야기/오프라인 설치](https://tykimos.github.io/Keras/2017/03/15/Keras_Offline_Install/)
