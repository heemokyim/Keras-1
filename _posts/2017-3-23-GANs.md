---
layout: post
title:  "GAN"
author: Taeyoung, Kim
date:   2017-03-08 23:00:00
categories: Lecture
comments: true
image: http://tykimos.github.com/Keras/warehouse/2017-3-8_CNN_Getting_Started_4.png
---

```python
# Build Generative model ...
nch = 200
g_input = Input(shape=[100])
H = Dense(nch*14*14, init='glorot_normal')(g_input)
H = BatchNormalization(mode=2)(H)
H = Activation('relu')(H)
H = Reshape( [nch, 14, 14] )(H)
H = UpSampling2D(size=(2, 2))(H)
H = Convolution2D(nch/2, 3, 3, border_mode='same', init='glorot_uniform')(H)
H = BatchNormalization(mode=2)(H)
H = Activation('relu')(H)
H = Convolution2D(nch/4, 3, 3, border_mode='same', init='glorot_uniform')(H)
H = BatchNormalization(mode=2)(H)
H = Activation('relu')(H)
H = Convolution2D(1, 1, 1, border_mode='same', init='glorot_uniform')(H)
g_V = Activation('sigmoid')(H)

generator = Model(g_input,g_V)
generator.compile(loss='binary_crossentropy', optimizer=opt)
generator.summary()
```


```python
# Build Discriminative model ...
d_input = Input(shape=shp)
H = Convolution2D(256, 5, 5, subsample=(2, 2), border_mode = 'same', activation='relu')(d_input)
H = LeakyReLU(0.2)(H)
H = Dropout(dropout_rate)(H)
H = Convolution2D(512, 5, 5, subsample=(2, 2), border_mode = 'same', activation='relu')(H)
H = LeakyReLU(0.2)(H)
H = Dropout(dropout_rate)(H)
H = Flatten()(H)
H = Dense(256)(H)
H = LeakyReLU(0.2)(H)
H = Dropout(dropout_rate)(H)
d_V = Dense(2,activation='softmax')(H)

discriminator = Model(d_input,d_V)
discriminator.compile(loss='categorical_crossentropy', optimizer=dopt)
discriminator.summary()
```


```python
# Freeze weights in the discriminator for stacked training
def make_trainable(net, val):
    net.trainable = val
    for l in net.layers:
       l.trainable = val
make_trainable(discriminator, False)

# Build stacked GAN model
gan_input = Input(shape=[100])
H = generator(gan_input)
gan_V = discriminator(H)

GAN = Model(gan_input, gan_V)
GAN.compile(loss='categorical_crossentropy', optimizer=opt)
GAN.summary()
```


```python

```


```python

```


```python

```


```python

We pre-train the discriminative model by generating a handful of random images using the untrained generative model, concatenating them with an equal number of real images of digits, labeling them appropriately, and then fitting until we reach a relatively stable loss value which takes 1 epoch over 20,000 examples.  This is an important step which should not be skipped — pre-training accelerates the GAN massively and I was not able to achieve convergence without it (possibly due to impatience).

Generative Adversarial Model
Now that we have both the generative and adversarial models, we can combine them to make a GAN quite easily in Keras.  Using the functional API, we can simply re-use the same network objects we have already instantiated and they will conveniently maintain the same shared weights with the previously compiled models.  Since we want to freeze the weights in the adversarial half of the network during back-propagation of the joint model, we first run through and set the keras trainable flag to False for each element in this part of the network.  For now, this seems to need to be applied at the primitive layer level rather than on the high level network so we introduce a simple function to do this.

 # Freeze weights in the discriminator for stacked training
def make_trainable(net, val):
    net.trainable = val
    for l in net.layers:
       l.trainable = val
make_trainable(discriminator, False)

# Build stacked GAN model
gan_input = Input(shape=[100])
H = generator(gan_input)
gan_V = discriminator(H)
GAN = Model(gan_input, gan_V)
GAN.compile(loss='categorical_crossentropy', optimizer=opt)
GAN.summary()
At this point, we now have a randomly initialized generator, a (poorly) trained discriminator, and a GAN which can be trained across the stacked model of both networks.  The core of training routine for a GAN looks something like this.

Generate images using G and random noise (forward pass only).
Perform a Batch update of weights in A given generated images, real images, and labels.
Perform a Batch update of weights in G given noise and forced “real” labels in the full GAN.
Repeat…
Running this process for a number of epochs, we can plot the loss of the GAN and Adversarial loss functions over time to get our GAN loss plots during training.

mnist_gan_loss4
GAN Training Loss
And finally, we can plot some samples from the trained generative model which look relatively like the original MNIST digits, and some examples from the original dataset for comparison.

mnist_gan7
GAN Generated Random Digits
mnist_real
Examples Digits from Real MNIST Set
https://github.com/osh/KerasGAN

Posted in Uncategorized
Post navigation
← Reducing 1D Convolution to a Single (Big) Matrix MultiplicationLearning to Communicate with Unsupervised Channel Autoencoders →
3 thoughts on “MNIST Generative Adversarial Model in Keras”

Haichun Li says:
October 14, 2016 at 7:41 am
Hello，I am a postgraduate of USTC majoring in machine learning. I have run your code as tutorials. There is a problem when I run your code in line 147 of mnist_gan.py:
X = np.concatenate((XT, generated_images))
The error says that the dimensions of XT and generated_images must be same while the shape of XT is (10000,1,28,28) and the shape of generated_images is (10000,400,28,1), I think there may be some problems in the generator,so can you please help me for that , thank you very much

Reply
Drakensberge says:
November 15, 2016 at 12:43 pm
Is there a straightforward way to make the generator conditional? For example, could it take parameter to generate only digits of a certain class?

Something like generator.predict(noise, class=’7′)?

Reply
dgunash says:
January 19, 2017 at 11:06 pm
K.set_image_dim_ordering(‘th’) should work. since keras takes tf as default for image_dim_ordering.

Reply
Leave a Reply
Your email address will not be published. Required fields are marked *

Comment 

Name * 

Email * 

Website 

Post Comment

Search for:
```
