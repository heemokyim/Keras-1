{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title:  \"학습 조기종료 시키기\"\n",
    "author: 김태영\n",
    "date:   2017-07-09 10:00:00\n",
    "categories: Lecture\n",
    "comments: true\n",
    "image: http://tykimos.github.com/Keras/warehouse/2017-7-9-Early_Stopping_4.png\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 ['학습과정과 데이터셋 이야기'](https://tykimos.github.io/Keras/2017/03/25/Dataset_and_Fit_Talk/)에서 과적합이라는 것을 살펴보았고, 이를 방지하기 위해 조기 종료하는 시점에 대해서 알아보았습니다. 본 절에서는 케라스에서 제공하는 기능을 이용하여 학습 중에 어떻게 조기 종료를 시킬 수 있는 지 알아보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 과적합되는 모델 살펴보기\n",
    "\n",
    "먼저 과적합되는 모델을 만들고 어떻게 학습이 되었는 지 살펴보겠습니다. 아래 코드에서 사용된 데이터수, 배치사이즈, 뉴런 수 등은 과적합 현상을 재현하기 하기 위해 설정된 것으로 실제 최적화된 수치는 아닙니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "700/700 [==============================] - 0s - loss: 2.2596 - acc: 0.1514 - val_loss: 2.2248 - val_acc: 0.1567\n",
      "Epoch 2/1000\n",
      "700/700 [==============================] - 0s - loss: 2.1993 - acc: 0.1929 - val_loss: 2.1812 - val_acc: 0.1867\n",
      "Epoch 3/1000\n",
      "700/700 [==============================] - 0s - loss: 2.1578 - acc: 0.2057 - val_loss: 2.1529 - val_acc: 0.1800\n",
      "Epoch 4/1000\n",
      "700/700 [==============================] - 0s - loss: 2.1236 - acc: 0.2171 - val_loss: 2.1235 - val_acc: 0.2133\n",
      "Epoch 5/1000\n",
      "700/700 [==============================] - 0s - loss: 2.0861 - acc: 0.2457 - val_loss: 2.0852 - val_acc: 0.2300\n",
      "Epoch 6/1000\n",
      "700/700 [==============================] - 0s - loss: 2.0473 - acc: 0.2743 - val_loss: 2.0525 - val_acc: 0.2233\n",
      "Epoch 7/1000\n",
      "700/700 [==============================] - 0s - loss: 2.0114 - acc: 0.2871 - val_loss: 2.0293 - val_acc: 0.2467\n",
      "Epoch 8/1000\n",
      "700/700 [==============================] - 0s - loss: 1.9795 - acc: 0.3343 - val_loss: 2.0096 - val_acc: 0.2800\n",
      "Epoch 9/1000\n",
      "700/700 [==============================] - 0s - loss: 1.9519 - acc: 0.3371 - val_loss: 1.9779 - val_acc: 0.3200\n",
      "Epoch 10/1000\n",
      "700/700 [==============================] - 0s - loss: 1.9253 - acc: 0.3557 - val_loss: 1.9560 - val_acc: 0.3200\n",
      "Epoch 11/1000\n",
      "700/700 [==============================] - 0s - loss: 1.8994 - acc: 0.3586 - val_loss: 1.9349 - val_acc: 0.3367\n",
      "Epoch 12/1000\n",
      "700/700 [==============================] - 0s - loss: 1.8755 - acc: 0.3557 - val_loss: 1.9155 - val_acc: 0.3467\n",
      "Epoch 13/1000\n",
      "700/700 [==============================] - 0s - loss: 1.8526 - acc: 0.3671 - val_loss: 1.8927 - val_acc: 0.3667\n",
      "Epoch 14/1000\n",
      "700/700 [==============================] - 0s - loss: 1.8319 - acc: 0.3771 - val_loss: 1.8794 - val_acc: 0.3733\n",
      "Epoch 15/1000\n",
      "700/700 [==============================] - 0s - loss: 1.8107 - acc: 0.3786 - val_loss: 1.8686 - val_acc: 0.3733\n",
      "Epoch 16/1000\n",
      "700/700 [==============================] - 0s - loss: 1.7911 - acc: 0.3914 - val_loss: 1.8523 - val_acc: 0.3800\n",
      "Epoch 17/1000\n",
      "700/700 [==============================] - 0s - loss: 1.7729 - acc: 0.3986 - val_loss: 1.8427 - val_acc: 0.3800\n",
      "Epoch 18/1000\n",
      "700/700 [==============================] - 0s - loss: 1.7549 - acc: 0.4071 - val_loss: 1.8249 - val_acc: 0.3933\n",
      "Epoch 19/1000\n",
      "700/700 [==============================] - 0s - loss: 1.7391 - acc: 0.4086 - val_loss: 1.8164 - val_acc: 0.4000\n",
      "Epoch 20/1000\n",
      "700/700 [==============================] - 0s - loss: 1.7221 - acc: 0.4186 - val_loss: 1.8102 - val_acc: 0.3967\n",
      "Epoch 21/1000\n",
      "700/700 [==============================] - 0s - loss: 1.7067 - acc: 0.4257 - val_loss: 1.8023 - val_acc: 0.4000\n",
      "Epoch 22/1000\n",
      "700/700 [==============================] - 0s - loss: 1.6917 - acc: 0.4371 - val_loss: 1.7889 - val_acc: 0.3933\n",
      "Epoch 23/1000\n",
      "700/700 [==============================] - 0s - loss: 1.6768 - acc: 0.4429 - val_loss: 1.7758 - val_acc: 0.4133\n",
      "Epoch 24/1000\n",
      "700/700 [==============================] - 0s - loss: 1.6617 - acc: 0.4414 - val_loss: 1.7639 - val_acc: 0.4233\n",
      "Epoch 25/1000\n",
      "700/700 [==============================] - 0s - loss: 1.6492 - acc: 0.4457 - val_loss: 1.7555 - val_acc: 0.4233\n",
      "Epoch 26/1000\n",
      "700/700 [==============================] - 0s - loss: 1.6348 - acc: 0.4457 - val_loss: 1.7605 - val_acc: 0.4067\n",
      "Epoch 27/1000\n",
      "700/700 [==============================] - 0s - loss: 1.6222 - acc: 0.4557 - val_loss: 1.7478 - val_acc: 0.4000\n",
      "Epoch 28/1000\n",
      "700/700 [==============================] - 0s - loss: 1.6106 - acc: 0.4529 - val_loss: 1.7313 - val_acc: 0.4200\n",
      "Epoch 29/1000\n",
      "700/700 [==============================] - 0s - loss: 1.5984 - acc: 0.4557 - val_loss: 1.7293 - val_acc: 0.4200\n",
      "Epoch 30/1000\n",
      "700/700 [==============================] - 0s - loss: 1.5871 - acc: 0.4600 - val_loss: 1.7165 - val_acc: 0.4200\n",
      "Epoch 31/1000\n",
      "700/700 [==============================] - 0s - loss: 1.5751 - acc: 0.4643 - val_loss: 1.7104 - val_acc: 0.4267\n",
      "Epoch 32/1000\n",
      "700/700 [==============================] - 0s - loss: 1.5648 - acc: 0.4600 - val_loss: 1.7061 - val_acc: 0.4267\n",
      "Epoch 33/1000\n",
      "700/700 [==============================] - 0s - loss: 1.5515 - acc: 0.4671 - val_loss: 1.6971 - val_acc: 0.4267\n",
      "Epoch 34/1000\n",
      "700/700 [==============================] - 0s - loss: 1.5415 - acc: 0.4614 - val_loss: 1.6860 - val_acc: 0.4300\n",
      "Epoch 35/1000\n",
      "700/700 [==============================] - 0s - loss: 1.5323 - acc: 0.4714 - val_loss: 1.6765 - val_acc: 0.4267\n",
      "Epoch 36/1000\n",
      "700/700 [==============================] - 0s - loss: 1.5223 - acc: 0.4771 - val_loss: 1.6798 - val_acc: 0.4100\n",
      "Epoch 37/1000\n",
      "700/700 [==============================] - 0s - loss: 1.5122 - acc: 0.4814 - val_loss: 1.6711 - val_acc: 0.4300\n",
      "Epoch 38/1000\n",
      "700/700 [==============================] - 0s - loss: 1.5027 - acc: 0.4857 - val_loss: 1.6705 - val_acc: 0.4267\n",
      "Epoch 39/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4933 - acc: 0.4900 - val_loss: 1.6573 - val_acc: 0.4333\n",
      "Epoch 40/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4835 - acc: 0.4900 - val_loss: 1.6454 - val_acc: 0.4333\n",
      "Epoch 41/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4740 - acc: 0.4971 - val_loss: 1.6519 - val_acc: 0.4300\n",
      "Epoch 42/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4663 - acc: 0.4900 - val_loss: 1.6358 - val_acc: 0.4367\n",
      "Epoch 43/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4569 - acc: 0.4914 - val_loss: 1.6280 - val_acc: 0.4367\n",
      "Epoch 44/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4493 - acc: 0.4857 - val_loss: 1.6267 - val_acc: 0.4367\n",
      "Epoch 45/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4405 - acc: 0.5014 - val_loss: 1.6185 - val_acc: 0.4367\n",
      "Epoch 46/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4329 - acc: 0.4900 - val_loss: 1.6151 - val_acc: 0.4367\n",
      "Epoch 47/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4249 - acc: 0.4986 - val_loss: 1.6087 - val_acc: 0.4367\n",
      "Epoch 48/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4168 - acc: 0.4929 - val_loss: 1.6113 - val_acc: 0.4400\n",
      "Epoch 49/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4099 - acc: 0.5043 - val_loss: 1.6047 - val_acc: 0.4367\n",
      "Epoch 50/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4024 - acc: 0.5043 - val_loss: 1.5940 - val_acc: 0.4300\n",
      "Epoch 51/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3951 - acc: 0.5014 - val_loss: 1.6025 - val_acc: 0.4433\n",
      "Epoch 52/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3886 - acc: 0.5000 - val_loss: 1.5917 - val_acc: 0.4400\n",
      "Epoch 53/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3822 - acc: 0.5057 - val_loss: 1.5847 - val_acc: 0.4333\n",
      "Epoch 54/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3762 - acc: 0.4971 - val_loss: 1.5790 - val_acc: 0.4333\n",
      "Epoch 55/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3683 - acc: 0.4957 - val_loss: 1.5748 - val_acc: 0.4267\n",
      "Epoch 56/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3631 - acc: 0.5014 - val_loss: 1.5716 - val_acc: 0.4233\n",
      "Epoch 57/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3566 - acc: 0.5029 - val_loss: 1.5682 - val_acc: 0.4367\n",
      "Epoch 58/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3498 - acc: 0.5000 - val_loss: 1.5624 - val_acc: 0.4367\n",
      "Epoch 59/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3449 - acc: 0.5086 - val_loss: 1.5622 - val_acc: 0.4400\n",
      "Epoch 60/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3385 - acc: 0.5086 - val_loss: 1.5555 - val_acc: 0.4433\n",
      "Epoch 61/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3310 - acc: 0.5057 - val_loss: 1.5426 - val_acc: 0.4333\n",
      "Epoch 62/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3277 - acc: 0.5014 - val_loss: 1.5538 - val_acc: 0.4333\n",
      "Epoch 63/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3213 - acc: 0.5100 - val_loss: 1.5458 - val_acc: 0.4467\n",
      "Epoch 64/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3153 - acc: 0.5143 - val_loss: 1.5539 - val_acc: 0.4500\n",
      "Epoch 65/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3107 - acc: 0.5129 - val_loss: 1.5456 - val_acc: 0.4467\n",
      "Epoch 66/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3054 - acc: 0.5143 - val_loss: 1.5418 - val_acc: 0.4533\n",
      "Epoch 67/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3005 - acc: 0.5143 - val_loss: 1.5376 - val_acc: 0.4500\n",
      "Epoch 68/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2959 - acc: 0.5114 - val_loss: 1.5349 - val_acc: 0.4533\n",
      "Epoch 69/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2891 - acc: 0.5171 - val_loss: 1.5254 - val_acc: 0.4333\n",
      "Epoch 70/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2850 - acc: 0.5086 - val_loss: 1.5445 - val_acc: 0.4567\n",
      "Epoch 71/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2815 - acc: 0.5200 - val_loss: 1.5234 - val_acc: 0.4467\n",
      "Epoch 72/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2774 - acc: 0.5200 - val_loss: 1.5236 - val_acc: 0.4467\n",
      "Epoch 73/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2723 - acc: 0.5086 - val_loss: 1.5199 - val_acc: 0.4467\n",
      "Epoch 74/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2675 - acc: 0.5071 - val_loss: 1.5196 - val_acc: 0.4433\n",
      "Epoch 75/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2650 - acc: 0.5171 - val_loss: 1.5097 - val_acc: 0.4333\n",
      "Epoch 76/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2604 - acc: 0.5171 - val_loss: 1.5128 - val_acc: 0.4467\n",
      "Epoch 77/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2557 - acc: 0.5171 - val_loss: 1.5107 - val_acc: 0.4400\n",
      "Epoch 78/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2527 - acc: 0.5257 - val_loss: 1.5119 - val_acc: 0.4433\n",
      "Epoch 79/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2493 - acc: 0.5171 - val_loss: 1.5076 - val_acc: 0.4367\n",
      "Epoch 80/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2445 - acc: 0.5257 - val_loss: 1.5100 - val_acc: 0.4500\n",
      "Epoch 81/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2419 - acc: 0.5157 - val_loss: 1.4973 - val_acc: 0.4467\n",
      "Epoch 82/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2391 - acc: 0.5300 - val_loss: 1.5017 - val_acc: 0.4467\n",
      "Epoch 83/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2359 - acc: 0.5257 - val_loss: 1.5034 - val_acc: 0.4400\n",
      "Epoch 84/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2327 - acc: 0.5300 - val_loss: 1.5079 - val_acc: 0.4467\n",
      "Epoch 85/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2295 - acc: 0.5229 - val_loss: 1.5011 - val_acc: 0.4333\n",
      "Epoch 86/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2250 - acc: 0.5214 - val_loss: 1.4915 - val_acc: 0.4467\n",
      "Epoch 87/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2233 - acc: 0.5257 - val_loss: 1.4934 - val_acc: 0.4467\n",
      "Epoch 88/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2206 - acc: 0.5400 - val_loss: 1.4922 - val_acc: 0.4500\n",
      "Epoch 89/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2176 - acc: 0.5314 - val_loss: 1.4944 - val_acc: 0.4367\n",
      "Epoch 90/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2148 - acc: 0.5286 - val_loss: 1.4898 - val_acc: 0.4433\n",
      "Epoch 91/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2121 - acc: 0.5400 - val_loss: 1.4920 - val_acc: 0.4600\n",
      "Epoch 92/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2090 - acc: 0.5386 - val_loss: 1.5000 - val_acc: 0.4500\n",
      "Epoch 93/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2066 - acc: 0.5386 - val_loss: 1.4868 - val_acc: 0.4500\n",
      "Epoch 94/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2036 - acc: 0.5329 - val_loss: 1.4964 - val_acc: 0.4567\n",
      "Epoch 95/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2009 - acc: 0.5357 - val_loss: 1.4930 - val_acc: 0.4533\n",
      "Epoch 96/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1983 - acc: 0.5343 - val_loss: 1.4991 - val_acc: 0.4533\n",
      "Epoch 97/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1950 - acc: 0.5414 - val_loss: 1.4836 - val_acc: 0.4433\n",
      "Epoch 98/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1937 - acc: 0.5443 - val_loss: 1.4915 - val_acc: 0.4633\n",
      "Epoch 99/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1910 - acc: 0.5471 - val_loss: 1.4792 - val_acc: 0.4433\n",
      "Epoch 100/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1878 - acc: 0.5486 - val_loss: 1.4863 - val_acc: 0.4500\n",
      "Epoch 101/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1858 - acc: 0.5371 - val_loss: 1.4983 - val_acc: 0.4467\n",
      "Epoch 102/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1831 - acc: 0.5429 - val_loss: 1.4886 - val_acc: 0.4533\n",
      "Epoch 103/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1804 - acc: 0.5400 - val_loss: 1.4789 - val_acc: 0.4367\n",
      "Epoch 104/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1779 - acc: 0.5500 - val_loss: 1.4819 - val_acc: 0.4400\n",
      "Epoch 105/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1757 - acc: 0.5471 - val_loss: 1.4907 - val_acc: 0.4500\n",
      "Epoch 106/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1743 - acc: 0.5457 - val_loss: 1.4816 - val_acc: 0.4500\n",
      "Epoch 107/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1717 - acc: 0.5500 - val_loss: 1.4831 - val_acc: 0.4533\n",
      "Epoch 108/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1679 - acc: 0.5629 - val_loss: 1.4881 - val_acc: 0.4400\n",
      "Epoch 109/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1685 - acc: 0.5514 - val_loss: 1.4846 - val_acc: 0.4467\n",
      "Epoch 110/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1658 - acc: 0.5457 - val_loss: 1.4827 - val_acc: 0.4533\n",
      "Epoch 111/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1629 - acc: 0.5486 - val_loss: 1.4896 - val_acc: 0.4567\n",
      "Epoch 112/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1624 - acc: 0.5443 - val_loss: 1.4880 - val_acc: 0.4567\n",
      "Epoch 113/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1593 - acc: 0.5471 - val_loss: 1.4861 - val_acc: 0.4533\n",
      "Epoch 114/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1566 - acc: 0.5443 - val_loss: 1.4935 - val_acc: 0.4533\n",
      "Epoch 115/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1550 - acc: 0.5414 - val_loss: 1.4865 - val_acc: 0.4567\n",
      "Epoch 116/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1527 - acc: 0.5543 - val_loss: 1.4792 - val_acc: 0.4467\n",
      "Epoch 117/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1502 - acc: 0.5514 - val_loss: 1.4934 - val_acc: 0.4433\n",
      "Epoch 118/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1472 - acc: 0.5571 - val_loss: 1.5036 - val_acc: 0.4600\n",
      "Epoch 119/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1448 - acc: 0.5457 - val_loss: 1.5046 - val_acc: 0.4600\n",
      "Epoch 120/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1450 - acc: 0.5514 - val_loss: 1.4987 - val_acc: 0.4600\n",
      "Epoch 121/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1405 - acc: 0.5500 - val_loss: 1.4758 - val_acc: 0.4433\n",
      "Epoch 122/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1389 - acc: 0.5457 - val_loss: 1.4775 - val_acc: 0.4467\n",
      "Epoch 123/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1363 - acc: 0.5486 - val_loss: 1.4887 - val_acc: 0.4567\n",
      "Epoch 124/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1341 - acc: 0.5614 - val_loss: 1.4935 - val_acc: 0.4633\n",
      "Epoch 125/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1319 - acc: 0.5529 - val_loss: 1.4844 - val_acc: 0.4567\n",
      "Epoch 126/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1289 - acc: 0.5471 - val_loss: 1.4810 - val_acc: 0.4633\n",
      "Epoch 127/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1269 - acc: 0.5586 - val_loss: 1.4845 - val_acc: 0.4567\n",
      "Epoch 128/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1240 - acc: 0.5629 - val_loss: 1.4898 - val_acc: 0.4500\n",
      "Epoch 129/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1219 - acc: 0.5643 - val_loss: 1.4757 - val_acc: 0.4567\n",
      "Epoch 130/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1194 - acc: 0.5614 - val_loss: 1.4791 - val_acc: 0.4467\n",
      "Epoch 131/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1174 - acc: 0.5643 - val_loss: 1.4831 - val_acc: 0.4567\n",
      "Epoch 132/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1156 - acc: 0.5614 - val_loss: 1.4807 - val_acc: 0.4567\n",
      "Epoch 133/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1121 - acc: 0.5743 - val_loss: 1.4857 - val_acc: 0.4567\n",
      "Epoch 134/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1107 - acc: 0.5729 - val_loss: 1.4862 - val_acc: 0.4567\n",
      "Epoch 135/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1083 - acc: 0.5686 - val_loss: 1.4800 - val_acc: 0.4567\n",
      "Epoch 136/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1064 - acc: 0.5714 - val_loss: 1.4878 - val_acc: 0.4533\n",
      "Epoch 137/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1035 - acc: 0.5643 - val_loss: 1.4841 - val_acc: 0.4600\n",
      "Epoch 138/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1016 - acc: 0.5671 - val_loss: 1.4796 - val_acc: 0.4567\n",
      "Epoch 139/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1002 - acc: 0.5757 - val_loss: 1.4804 - val_acc: 0.4500\n",
      "Epoch 140/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0981 - acc: 0.5686 - val_loss: 1.4808 - val_acc: 0.4567\n",
      "Epoch 141/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0961 - acc: 0.5771 - val_loss: 1.4845 - val_acc: 0.4500\n",
      "Epoch 142/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0925 - acc: 0.5843 - val_loss: 1.4955 - val_acc: 0.4567\n",
      "Epoch 143/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0933 - acc: 0.5686 - val_loss: 1.4838 - val_acc: 0.4467\n",
      "Epoch 144/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0904 - acc: 0.5786 - val_loss: 1.4780 - val_acc: 0.4500\n",
      "Epoch 145/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0884 - acc: 0.5800 - val_loss: 1.4840 - val_acc: 0.4433\n",
      "Epoch 146/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0858 - acc: 0.5857 - val_loss: 1.4855 - val_acc: 0.4467\n",
      "Epoch 147/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0839 - acc: 0.5743 - val_loss: 1.4848 - val_acc: 0.4467\n",
      "Epoch 148/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0836 - acc: 0.5786 - val_loss: 1.4843 - val_acc: 0.4533\n",
      "Epoch 149/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0805 - acc: 0.5857 - val_loss: 1.4863 - val_acc: 0.4567\n",
      "Epoch 150/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0794 - acc: 0.5771 - val_loss: 1.4880 - val_acc: 0.4533\n",
      "Epoch 151/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0776 - acc: 0.5871 - val_loss: 1.4875 - val_acc: 0.4567\n",
      "Epoch 152/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0755 - acc: 0.5886 - val_loss: 1.4824 - val_acc: 0.4500\n",
      "Epoch 153/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0723 - acc: 0.5829 - val_loss: 1.4845 - val_acc: 0.4533\n",
      "Epoch 154/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0713 - acc: 0.5871 - val_loss: 1.4894 - val_acc: 0.4700\n",
      "Epoch 155/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0701 - acc: 0.5914 - val_loss: 1.4939 - val_acc: 0.4733\n",
      "Epoch 156/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0673 - acc: 0.5871 - val_loss: 1.4835 - val_acc: 0.4567\n",
      "Epoch 157/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0659 - acc: 0.5871 - val_loss: 1.4924 - val_acc: 0.4667\n",
      "Epoch 158/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0645 - acc: 0.5857 - val_loss: 1.4807 - val_acc: 0.4533\n",
      "Epoch 159/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0630 - acc: 0.5929 - val_loss: 1.4855 - val_acc: 0.4567\n",
      "Epoch 160/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0607 - acc: 0.5871 - val_loss: 1.4899 - val_acc: 0.4700\n",
      "Epoch 161/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0580 - acc: 0.5886 - val_loss: 1.4846 - val_acc: 0.4567\n",
      "Epoch 162/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0580 - acc: 0.5886 - val_loss: 1.4933 - val_acc: 0.4667\n",
      "Epoch 163/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0552 - acc: 0.5929 - val_loss: 1.4861 - val_acc: 0.4433\n",
      "Epoch 164/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0526 - acc: 0.5971 - val_loss: 1.4954 - val_acc: 0.4667\n",
      "Epoch 165/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0526 - acc: 0.6014 - val_loss: 1.4874 - val_acc: 0.4500\n",
      "Epoch 166/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0507 - acc: 0.5986 - val_loss: 1.4848 - val_acc: 0.4533\n",
      "Epoch 167/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0483 - acc: 0.6000 - val_loss: 1.4858 - val_acc: 0.4667\n",
      "Epoch 168/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0473 - acc: 0.5986 - val_loss: 1.4860 - val_acc: 0.4600\n",
      "Epoch 169/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0459 - acc: 0.6043 - val_loss: 1.4867 - val_acc: 0.4633\n",
      "Epoch 170/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0435 - acc: 0.6000 - val_loss: 1.4816 - val_acc: 0.4500\n",
      "Epoch 171/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0425 - acc: 0.6086 - val_loss: 1.4942 - val_acc: 0.4667\n",
      "Epoch 172/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0404 - acc: 0.5971 - val_loss: 1.4901 - val_acc: 0.4633\n",
      "Epoch 173/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0394 - acc: 0.5986 - val_loss: 1.4888 - val_acc: 0.4533\n",
      "Epoch 174/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0380 - acc: 0.5971 - val_loss: 1.4894 - val_acc: 0.4667\n",
      "Epoch 175/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0363 - acc: 0.6029 - val_loss: 1.4879 - val_acc: 0.4633\n",
      "Epoch 176/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0340 - acc: 0.6129 - val_loss: 1.4911 - val_acc: 0.4667\n",
      "Epoch 177/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0329 - acc: 0.6086 - val_loss: 1.4965 - val_acc: 0.4733\n",
      "Epoch 178/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0309 - acc: 0.6014 - val_loss: 1.4913 - val_acc: 0.4667\n",
      "Epoch 179/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0302 - acc: 0.6043 - val_loss: 1.4987 - val_acc: 0.4700\n",
      "Epoch 180/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0270 - acc: 0.6157 - val_loss: 1.4986 - val_acc: 0.4667\n",
      "Epoch 181/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0273 - acc: 0.6171 - val_loss: 1.4975 - val_acc: 0.4600\n",
      "Epoch 182/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0260 - acc: 0.6057 - val_loss: 1.4939 - val_acc: 0.4700\n",
      "Epoch 183/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0239 - acc: 0.6086 - val_loss: 1.5000 - val_acc: 0.4700\n",
      "Epoch 184/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0218 - acc: 0.6114 - val_loss: 1.5000 - val_acc: 0.4533\n",
      "Epoch 185/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0216 - acc: 0.6143 - val_loss: 1.5021 - val_acc: 0.4667\n",
      "Epoch 186/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0195 - acc: 0.6100 - val_loss: 1.4935 - val_acc: 0.4567\n",
      "Epoch 187/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0181 - acc: 0.6143 - val_loss: 1.5024 - val_acc: 0.4667\n",
      "Epoch 188/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0164 - acc: 0.6157 - val_loss: 1.4938 - val_acc: 0.4467\n",
      "Epoch 189/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0155 - acc: 0.6129 - val_loss: 1.4952 - val_acc: 0.4467\n",
      "Epoch 190/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0137 - acc: 0.6171 - val_loss: 1.5017 - val_acc: 0.4567\n",
      "Epoch 191/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0119 - acc: 0.6086 - val_loss: 1.5017 - val_acc: 0.4633\n",
      "Epoch 192/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0111 - acc: 0.6114 - val_loss: 1.4993 - val_acc: 0.4600\n",
      "Epoch 193/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0089 - acc: 0.6100 - val_loss: 1.5066 - val_acc: 0.4567\n",
      "Epoch 194/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0078 - acc: 0.6200 - val_loss: 1.5006 - val_acc: 0.4567\n",
      "Epoch 195/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0065 - acc: 0.6186 - val_loss: 1.5033 - val_acc: 0.4633\n",
      "Epoch 196/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0017 - acc: 0.6243 - val_loss: 1.5103 - val_acc: 0.4533\n",
      "Epoch 197/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0032 - acc: 0.6229 - val_loss: 1.5036 - val_acc: 0.4567\n",
      "Epoch 198/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0024 - acc: 0.6214 - val_loss: 1.5036 - val_acc: 0.4567\n",
      "Epoch 199/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0018 - acc: 0.6243 - val_loss: 1.5064 - val_acc: 0.4633\n",
      "Epoch 200/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9989 - acc: 0.6200 - val_loss: 1.5009 - val_acc: 0.4533\n",
      "Epoch 201/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9985 - acc: 0.6271 - val_loss: 1.5047 - val_acc: 0.4533\n",
      "Epoch 202/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9965 - acc: 0.6229 - val_loss: 1.5045 - val_acc: 0.4500\n",
      "Epoch 203/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9951 - acc: 0.6200 - val_loss: 1.5073 - val_acc: 0.4533\n",
      "Epoch 204/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9942 - acc: 0.6271 - val_loss: 1.5045 - val_acc: 0.4700\n",
      "Epoch 205/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9936 - acc: 0.6243 - val_loss: 1.5025 - val_acc: 0.4600\n",
      "Epoch 206/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9914 - acc: 0.6329 - val_loss: 1.5056 - val_acc: 0.4700\n",
      "Epoch 207/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9906 - acc: 0.6300 - val_loss: 1.5046 - val_acc: 0.4600\n",
      "Epoch 208/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9887 - acc: 0.6286 - val_loss: 1.5033 - val_acc: 0.4467\n",
      "Epoch 209/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9877 - acc: 0.6271 - val_loss: 1.5070 - val_acc: 0.4533\n",
      "Epoch 210/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9855 - acc: 0.6314 - val_loss: 1.5165 - val_acc: 0.4667\n",
      "Epoch 211/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9842 - acc: 0.6257 - val_loss: 1.5097 - val_acc: 0.4567\n",
      "Epoch 212/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9835 - acc: 0.6300 - val_loss: 1.5100 - val_acc: 0.4567\n",
      "Epoch 213/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9819 - acc: 0.6300 - val_loss: 1.5079 - val_acc: 0.4600\n",
      "Epoch 214/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9812 - acc: 0.6343 - val_loss: 1.5111 - val_acc: 0.4567\n",
      "Epoch 215/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9797 - acc: 0.6357 - val_loss: 1.5162 - val_acc: 0.4667\n",
      "Epoch 216/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9770 - acc: 0.6357 - val_loss: 1.5128 - val_acc: 0.4567\n",
      "Epoch 217/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9762 - acc: 0.6314 - val_loss: 1.5155 - val_acc: 0.4533\n",
      "Epoch 218/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9758 - acc: 0.6329 - val_loss: 1.5118 - val_acc: 0.4567\n",
      "Epoch 219/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9739 - acc: 0.6314 - val_loss: 1.5177 - val_acc: 0.4667\n",
      "Epoch 220/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9728 - acc: 0.6200 - val_loss: 1.5156 - val_acc: 0.4633\n",
      "Epoch 221/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9712 - acc: 0.6314 - val_loss: 1.5216 - val_acc: 0.4667\n",
      "Epoch 222/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9712 - acc: 0.6371 - val_loss: 1.5190 - val_acc: 0.4533\n",
      "Epoch 223/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9691 - acc: 0.6329 - val_loss: 1.5160 - val_acc: 0.4600\n",
      "Epoch 224/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9689 - acc: 0.6314 - val_loss: 1.5199 - val_acc: 0.4700\n",
      "Epoch 225/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9662 - acc: 0.6429 - val_loss: 1.5247 - val_acc: 0.4733\n",
      "Epoch 226/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9639 - acc: 0.6357 - val_loss: 1.5176 - val_acc: 0.4400\n",
      "Epoch 227/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9648 - acc: 0.6400 - val_loss: 1.5241 - val_acc: 0.4767\n",
      "Epoch 228/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9628 - acc: 0.6200 - val_loss: 1.5278 - val_acc: 0.4700\n",
      "Epoch 229/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9621 - acc: 0.6457 - val_loss: 1.5275 - val_acc: 0.4733\n",
      "Epoch 230/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9613 - acc: 0.6600 - val_loss: 1.5263 - val_acc: 0.4600\n",
      "Epoch 231/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9596 - acc: 0.6314 - val_loss: 1.5266 - val_acc: 0.4667\n",
      "Epoch 232/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9591 - acc: 0.6514 - val_loss: 1.5310 - val_acc: 0.4867\n",
      "Epoch 233/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9575 - acc: 0.6500 - val_loss: 1.5262 - val_acc: 0.4667\n",
      "Epoch 234/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9554 - acc: 0.6443 - val_loss: 1.5253 - val_acc: 0.4600\n",
      "Epoch 235/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9550 - acc: 0.6500 - val_loss: 1.5229 - val_acc: 0.4533\n",
      "Epoch 236/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9539 - acc: 0.6486 - val_loss: 1.5247 - val_acc: 0.4633\n",
      "Epoch 237/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9517 - acc: 0.6700 - val_loss: 1.5308 - val_acc: 0.4667\n",
      "Epoch 238/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9512 - acc: 0.6571 - val_loss: 1.5342 - val_acc: 0.4833\n",
      "Epoch 239/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9500 - acc: 0.6600 - val_loss: 1.5324 - val_acc: 0.4700\n",
      "Epoch 240/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9488 - acc: 0.6629 - val_loss: 1.5288 - val_acc: 0.4667\n",
      "Epoch 241/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9482 - acc: 0.6457 - val_loss: 1.5333 - val_acc: 0.4600\n",
      "Epoch 242/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9466 - acc: 0.6586 - val_loss: 1.5377 - val_acc: 0.4700\n",
      "Epoch 243/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9450 - acc: 0.6657 - val_loss: 1.5337 - val_acc: 0.4700\n",
      "Epoch 244/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9443 - acc: 0.6614 - val_loss: 1.5470 - val_acc: 0.4800\n",
      "Epoch 245/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9451 - acc: 0.6586 - val_loss: 1.5386 - val_acc: 0.4700\n",
      "Epoch 246/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9426 - acc: 0.6600 - val_loss: 1.5419 - val_acc: 0.4567\n",
      "Epoch 247/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9422 - acc: 0.6543 - val_loss: 1.5343 - val_acc: 0.4733\n",
      "Epoch 248/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9393 - acc: 0.6729 - val_loss: 1.5405 - val_acc: 0.4800\n",
      "Epoch 249/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9405 - acc: 0.6614 - val_loss: 1.5413 - val_acc: 0.4567\n",
      "Epoch 250/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9385 - acc: 0.6629 - val_loss: 1.5404 - val_acc: 0.4633\n",
      "Epoch 251/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9369 - acc: 0.6671 - val_loss: 1.5377 - val_acc: 0.4467\n",
      "Epoch 252/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9358 - acc: 0.6671 - val_loss: 1.5391 - val_acc: 0.4533\n",
      "Epoch 253/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9338 - acc: 0.6671 - val_loss: 1.5445 - val_acc: 0.4667\n",
      "Epoch 254/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9334 - acc: 0.6757 - val_loss: 1.5508 - val_acc: 0.4700\n",
      "Epoch 255/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9332 - acc: 0.6643 - val_loss: 1.5506 - val_acc: 0.4633\n",
      "Epoch 256/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9335 - acc: 0.6614 - val_loss: 1.5476 - val_acc: 0.4700\n",
      "Epoch 257/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9299 - acc: 0.6643 - val_loss: 1.5549 - val_acc: 0.4567\n",
      "Epoch 258/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9313 - acc: 0.6657 - val_loss: 1.5479 - val_acc: 0.4633\n",
      "Epoch 259/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9290 - acc: 0.6643 - val_loss: 1.5469 - val_acc: 0.4533\n",
      "Epoch 260/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9274 - acc: 0.6714 - val_loss: 1.5560 - val_acc: 0.4633\n",
      "Epoch 261/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9271 - acc: 0.6657 - val_loss: 1.5629 - val_acc: 0.4533\n",
      "Epoch 262/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9266 - acc: 0.6686 - val_loss: 1.5471 - val_acc: 0.4600\n",
      "Epoch 263/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9251 - acc: 0.6700 - val_loss: 1.5485 - val_acc: 0.4567\n",
      "Epoch 264/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9248 - acc: 0.6786 - val_loss: 1.5521 - val_acc: 0.4633\n",
      "Epoch 265/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9245 - acc: 0.6643 - val_loss: 1.5524 - val_acc: 0.4700\n",
      "Epoch 266/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9219 - acc: 0.6743 - val_loss: 1.5557 - val_acc: 0.4633\n",
      "Epoch 267/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9212 - acc: 0.6757 - val_loss: 1.5691 - val_acc: 0.4767\n",
      "Epoch 268/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9211 - acc: 0.6657 - val_loss: 1.5641 - val_acc: 0.4800\n",
      "Epoch 269/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9190 - acc: 0.6786 - val_loss: 1.5602 - val_acc: 0.4667\n",
      "Epoch 270/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9191 - acc: 0.6786 - val_loss: 1.5575 - val_acc: 0.4600\n",
      "Epoch 271/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9168 - acc: 0.6829 - val_loss: 1.5637 - val_acc: 0.4633\n",
      "Epoch 272/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9159 - acc: 0.6786 - val_loss: 1.5654 - val_acc: 0.4667\n",
      "Epoch 273/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9142 - acc: 0.6771 - val_loss: 1.5653 - val_acc: 0.4633\n",
      "Epoch 274/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9143 - acc: 0.6771 - val_loss: 1.5619 - val_acc: 0.4567\n",
      "Epoch 275/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9136 - acc: 0.6757 - val_loss: 1.5647 - val_acc: 0.4633\n",
      "Epoch 276/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9125 - acc: 0.6771 - val_loss: 1.5655 - val_acc: 0.4600\n",
      "Epoch 277/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9119 - acc: 0.6743 - val_loss: 1.5747 - val_acc: 0.4733\n",
      "Epoch 278/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9107 - acc: 0.6800 - val_loss: 1.5733 - val_acc: 0.4600\n",
      "Epoch 279/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9097 - acc: 0.6857 - val_loss: 1.5713 - val_acc: 0.4700\n",
      "Epoch 280/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9088 - acc: 0.6900 - val_loss: 1.5691 - val_acc: 0.4500\n",
      "Epoch 281/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9080 - acc: 0.6900 - val_loss: 1.5740 - val_acc: 0.4467\n",
      "Epoch 282/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9066 - acc: 0.6814 - val_loss: 1.5815 - val_acc: 0.4467\n",
      "Epoch 283/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9065 - acc: 0.6657 - val_loss: 1.5741 - val_acc: 0.4600\n",
      "Epoch 284/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9044 - acc: 0.6786 - val_loss: 1.5792 - val_acc: 0.4633\n",
      "Epoch 285/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9044 - acc: 0.6800 - val_loss: 1.5743 - val_acc: 0.4667\n",
      "Epoch 286/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9034 - acc: 0.6914 - val_loss: 1.5769 - val_acc: 0.4567\n",
      "Epoch 287/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9032 - acc: 0.6800 - val_loss: 1.5772 - val_acc: 0.4633\n",
      "Epoch 288/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9012 - acc: 0.6814 - val_loss: 1.5740 - val_acc: 0.4400\n",
      "Epoch 289/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9017 - acc: 0.6843 - val_loss: 1.5803 - val_acc: 0.4433\n",
      "Epoch 290/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9009 - acc: 0.6843 - val_loss: 1.5851 - val_acc: 0.4600\n",
      "Epoch 291/1000\n",
      "700/700 [==============================] - 0s - loss: 0.9001 - acc: 0.6929 - val_loss: 1.5817 - val_acc: 0.4567\n",
      "Epoch 292/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8970 - acc: 0.6843 - val_loss: 1.5924 - val_acc: 0.4467\n",
      "Epoch 293/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8984 - acc: 0.6829 - val_loss: 1.5899 - val_acc: 0.4533\n",
      "Epoch 294/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8966 - acc: 0.6914 - val_loss: 1.5872 - val_acc: 0.4500\n",
      "Epoch 295/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8961 - acc: 0.6986 - val_loss: 1.5853 - val_acc: 0.4567\n",
      "Epoch 296/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8951 - acc: 0.6900 - val_loss: 1.5905 - val_acc: 0.4533\n",
      "Epoch 297/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8946 - acc: 0.6943 - val_loss: 1.5925 - val_acc: 0.4633\n",
      "Epoch 298/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8932 - acc: 0.6871 - val_loss: 1.5900 - val_acc: 0.4500\n",
      "Epoch 299/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8928 - acc: 0.6929 - val_loss: 1.5962 - val_acc: 0.4600\n",
      "Epoch 300/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8915 - acc: 0.6843 - val_loss: 1.5935 - val_acc: 0.4567\n",
      "Epoch 301/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8903 - acc: 0.6871 - val_loss: 1.5912 - val_acc: 0.4533\n",
      "Epoch 302/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8902 - acc: 0.6957 - val_loss: 1.5935 - val_acc: 0.4567\n",
      "Epoch 303/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8886 - acc: 0.6900 - val_loss: 1.5945 - val_acc: 0.4567\n",
      "Epoch 304/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8885 - acc: 0.6957 - val_loss: 1.5918 - val_acc: 0.4533\n",
      "Epoch 305/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8873 - acc: 0.6871 - val_loss: 1.5923 - val_acc: 0.4533\n",
      "Epoch 306/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8875 - acc: 0.6900 - val_loss: 1.5984 - val_acc: 0.4467\n",
      "Epoch 307/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8856 - acc: 0.6886 - val_loss: 1.6037 - val_acc: 0.4633\n",
      "Epoch 308/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8865 - acc: 0.6914 - val_loss: 1.6008 - val_acc: 0.4533\n",
      "Epoch 309/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8843 - acc: 0.6871 - val_loss: 1.5955 - val_acc: 0.4500\n",
      "Epoch 310/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8824 - acc: 0.7000 - val_loss: 1.6081 - val_acc: 0.4467\n",
      "Epoch 311/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8818 - acc: 0.6929 - val_loss: 1.6005 - val_acc: 0.4500\n",
      "Epoch 312/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8816 - acc: 0.6914 - val_loss: 1.6018 - val_acc: 0.4533\n",
      "Epoch 313/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8821 - acc: 0.6943 - val_loss: 1.6064 - val_acc: 0.4500\n",
      "Epoch 314/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8806 - acc: 0.6943 - val_loss: 1.6119 - val_acc: 0.4533\n",
      "Epoch 315/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8793 - acc: 0.6871 - val_loss: 1.5976 - val_acc: 0.4433\n",
      "Epoch 316/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8792 - acc: 0.6971 - val_loss: 1.6138 - val_acc: 0.4533\n",
      "Epoch 317/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8773 - acc: 0.6957 - val_loss: 1.6086 - val_acc: 0.4500\n",
      "Epoch 318/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8777 - acc: 0.7043 - val_loss: 1.6120 - val_acc: 0.4500\n",
      "Epoch 319/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8769 - acc: 0.6900 - val_loss: 1.6081 - val_acc: 0.4600\n",
      "Epoch 320/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8753 - acc: 0.6914 - val_loss: 1.6192 - val_acc: 0.4567\n",
      "Epoch 321/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8756 - acc: 0.6929 - val_loss: 1.6156 - val_acc: 0.4533\n",
      "Epoch 322/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8738 - acc: 0.6986 - val_loss: 1.6215 - val_acc: 0.4467\n",
      "Epoch 323/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8734 - acc: 0.6929 - val_loss: 1.6174 - val_acc: 0.4533\n",
      "Epoch 324/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8730 - acc: 0.6957 - val_loss: 1.6199 - val_acc: 0.4533\n",
      "Epoch 325/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8722 - acc: 0.6986 - val_loss: 1.6178 - val_acc: 0.4533\n",
      "Epoch 326/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8719 - acc: 0.6957 - val_loss: 1.6242 - val_acc: 0.4533\n",
      "Epoch 327/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8699 - acc: 0.6929 - val_loss: 1.6286 - val_acc: 0.4500\n",
      "Epoch 328/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8691 - acc: 0.7000 - val_loss: 1.6240 - val_acc: 0.4533\n",
      "Epoch 329/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8682 - acc: 0.6929 - val_loss: 1.6235 - val_acc: 0.4567\n",
      "Epoch 330/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8679 - acc: 0.7000 - val_loss: 1.6323 - val_acc: 0.4467\n",
      "Epoch 331/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8681 - acc: 0.6943 - val_loss: 1.6291 - val_acc: 0.4500\n",
      "Epoch 332/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8662 - acc: 0.6971 - val_loss: 1.6295 - val_acc: 0.4467\n",
      "Epoch 333/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8654 - acc: 0.7029 - val_loss: 1.6241 - val_acc: 0.4533\n",
      "Epoch 334/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8657 - acc: 0.7000 - val_loss: 1.6318 - val_acc: 0.4567\n",
      "Epoch 335/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8644 - acc: 0.7000 - val_loss: 1.6215 - val_acc: 0.4500\n",
      "Epoch 336/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8646 - acc: 0.7043 - val_loss: 1.6294 - val_acc: 0.4500\n",
      "Epoch 337/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8638 - acc: 0.7029 - val_loss: 1.6309 - val_acc: 0.4533\n",
      "Epoch 338/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8630 - acc: 0.7014 - val_loss: 1.6350 - val_acc: 0.4600\n",
      "Epoch 339/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8617 - acc: 0.7043 - val_loss: 1.6312 - val_acc: 0.4467\n",
      "Epoch 340/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8600 - acc: 0.7071 - val_loss: 1.6398 - val_acc: 0.4467\n",
      "Epoch 341/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8597 - acc: 0.6986 - val_loss: 1.6334 - val_acc: 0.4567\n",
      "Epoch 342/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8596 - acc: 0.7029 - val_loss: 1.6462 - val_acc: 0.4433\n",
      "Epoch 343/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8591 - acc: 0.6914 - val_loss: 1.6331 - val_acc: 0.4467\n",
      "Epoch 344/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8571 - acc: 0.7029 - val_loss: 1.6440 - val_acc: 0.4533\n",
      "Epoch 345/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8567 - acc: 0.7014 - val_loss: 1.6500 - val_acc: 0.4533\n",
      "Epoch 346/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8567 - acc: 0.7043 - val_loss: 1.6460 - val_acc: 0.4500\n",
      "Epoch 347/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8557 - acc: 0.7071 - val_loss: 1.6450 - val_acc: 0.4633\n",
      "Epoch 348/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8556 - acc: 0.7057 - val_loss: 1.6445 - val_acc: 0.4633\n",
      "Epoch 349/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8540 - acc: 0.7043 - val_loss: 1.6439 - val_acc: 0.4600\n",
      "Epoch 350/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8536 - acc: 0.7014 - val_loss: 1.6433 - val_acc: 0.4567\n",
      "Epoch 351/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8526 - acc: 0.7057 - val_loss: 1.6416 - val_acc: 0.4567\n",
      "Epoch 352/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8540 - acc: 0.7086 - val_loss: 1.6533 - val_acc: 0.4533\n",
      "Epoch 353/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8522 - acc: 0.7057 - val_loss: 1.6579 - val_acc: 0.4567\n",
      "Epoch 354/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8504 - acc: 0.7100 - val_loss: 1.6646 - val_acc: 0.4600\n",
      "Epoch 355/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8512 - acc: 0.7043 - val_loss: 1.6574 - val_acc: 0.4600\n",
      "Epoch 356/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8497 - acc: 0.7071 - val_loss: 1.6506 - val_acc: 0.4600\n",
      "Epoch 357/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8488 - acc: 0.7029 - val_loss: 1.6524 - val_acc: 0.4533\n",
      "Epoch 358/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8485 - acc: 0.7100 - val_loss: 1.6605 - val_acc: 0.4600\n",
      "Epoch 359/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8480 - acc: 0.7086 - val_loss: 1.6645 - val_acc: 0.4467\n",
      "Epoch 360/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8480 - acc: 0.7014 - val_loss: 1.6519 - val_acc: 0.4600\n",
      "Epoch 361/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8465 - acc: 0.7043 - val_loss: 1.6597 - val_acc: 0.4667\n",
      "Epoch 362/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8450 - acc: 0.7114 - val_loss: 1.6558 - val_acc: 0.4400\n",
      "Epoch 363/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8456 - acc: 0.7129 - val_loss: 1.6606 - val_acc: 0.4667\n",
      "Epoch 364/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8447 - acc: 0.7043 - val_loss: 1.6696 - val_acc: 0.4500\n",
      "Epoch 365/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8435 - acc: 0.7114 - val_loss: 1.6662 - val_acc: 0.4600\n",
      "Epoch 366/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8425 - acc: 0.7086 - val_loss: 1.6577 - val_acc: 0.4600\n",
      "Epoch 367/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8428 - acc: 0.7086 - val_loss: 1.6692 - val_acc: 0.4567\n",
      "Epoch 368/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8411 - acc: 0.7071 - val_loss: 1.6669 - val_acc: 0.4567\n",
      "Epoch 369/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8410 - acc: 0.7100 - val_loss: 1.6701 - val_acc: 0.4433\n",
      "Epoch 370/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8398 - acc: 0.7057 - val_loss: 1.6761 - val_acc: 0.4633\n",
      "Epoch 371/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8396 - acc: 0.7043 - val_loss: 1.6753 - val_acc: 0.4633\n",
      "Epoch 372/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8386 - acc: 0.7086 - val_loss: 1.6716 - val_acc: 0.4467\n",
      "Epoch 373/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8385 - acc: 0.7100 - val_loss: 1.6771 - val_acc: 0.4567\n",
      "Epoch 374/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8373 - acc: 0.7100 - val_loss: 1.6714 - val_acc: 0.4500\n",
      "Epoch 375/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8369 - acc: 0.7143 - val_loss: 1.6750 - val_acc: 0.4533\n",
      "Epoch 376/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8362 - acc: 0.7114 - val_loss: 1.6739 - val_acc: 0.4567\n",
      "Epoch 377/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8361 - acc: 0.7086 - val_loss: 1.6874 - val_acc: 0.4600\n",
      "Epoch 378/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8343 - acc: 0.7171 - val_loss: 1.6801 - val_acc: 0.4600\n",
      "Epoch 379/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8340 - acc: 0.7143 - val_loss: 1.6834 - val_acc: 0.4533\n",
      "Epoch 380/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8336 - acc: 0.7171 - val_loss: 1.6843 - val_acc: 0.4567\n",
      "Epoch 381/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8325 - acc: 0.7100 - val_loss: 1.6879 - val_acc: 0.4567\n",
      "Epoch 382/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8323 - acc: 0.7143 - val_loss: 1.6954 - val_acc: 0.4567\n",
      "Epoch 383/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8315 - acc: 0.7157 - val_loss: 1.6907 - val_acc: 0.4467\n",
      "Epoch 384/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8304 - acc: 0.7143 - val_loss: 1.6776 - val_acc: 0.4500\n",
      "Epoch 385/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8309 - acc: 0.7157 - val_loss: 1.6751 - val_acc: 0.4567\n",
      "Epoch 386/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8306 - acc: 0.7171 - val_loss: 1.6897 - val_acc: 0.4533\n",
      "Epoch 387/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8283 - acc: 0.7157 - val_loss: 1.6874 - val_acc: 0.4567\n",
      "Epoch 388/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8285 - acc: 0.7143 - val_loss: 1.6834 - val_acc: 0.4533\n",
      "Epoch 389/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8275 - acc: 0.7171 - val_loss: 1.6945 - val_acc: 0.4567\n",
      "Epoch 390/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8274 - acc: 0.7071 - val_loss: 1.6927 - val_acc: 0.4433\n",
      "Epoch 391/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8264 - acc: 0.7143 - val_loss: 1.7004 - val_acc: 0.4533\n",
      "Epoch 392/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8261 - acc: 0.7157 - val_loss: 1.6977 - val_acc: 0.4567\n",
      "Epoch 393/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8245 - acc: 0.7229 - val_loss: 1.7050 - val_acc: 0.4567\n",
      "Epoch 394/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8250 - acc: 0.7114 - val_loss: 1.6993 - val_acc: 0.4567\n",
      "Epoch 395/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8248 - acc: 0.7200 - val_loss: 1.7081 - val_acc: 0.4567\n",
      "Epoch 396/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8243 - acc: 0.7157 - val_loss: 1.7067 - val_acc: 0.4567\n",
      "Epoch 397/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8227 - acc: 0.7157 - val_loss: 1.7060 - val_acc: 0.4467\n",
      "Epoch 398/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8222 - acc: 0.7186 - val_loss: 1.7110 - val_acc: 0.4567\n",
      "Epoch 399/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8219 - acc: 0.7200 - val_loss: 1.7064 - val_acc: 0.4433\n",
      "Epoch 400/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8225 - acc: 0.7171 - val_loss: 1.7095 - val_acc: 0.4567\n",
      "Epoch 401/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8209 - acc: 0.7171 - val_loss: 1.7141 - val_acc: 0.4567\n",
      "Epoch 402/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8198 - acc: 0.7200 - val_loss: 1.7138 - val_acc: 0.4600\n",
      "Epoch 403/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8195 - acc: 0.7200 - val_loss: 1.7214 - val_acc: 0.4467\n",
      "Epoch 404/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8201 - acc: 0.7186 - val_loss: 1.7212 - val_acc: 0.4433\n",
      "Epoch 405/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8178 - acc: 0.7214 - val_loss: 1.7152 - val_acc: 0.4533\n",
      "Epoch 406/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8180 - acc: 0.7171 - val_loss: 1.7120 - val_acc: 0.4533\n",
      "Epoch 407/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8174 - acc: 0.7243 - val_loss: 1.7139 - val_acc: 0.4533\n",
      "Epoch 408/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8171 - acc: 0.7214 - val_loss: 1.7353 - val_acc: 0.4467\n",
      "Epoch 409/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8163 - acc: 0.7229 - val_loss: 1.7208 - val_acc: 0.4500\n",
      "Epoch 410/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8158 - acc: 0.7214 - val_loss: 1.7144 - val_acc: 0.4567\n",
      "Epoch 411/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8154 - acc: 0.7214 - val_loss: 1.7288 - val_acc: 0.4567\n",
      "Epoch 412/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8145 - acc: 0.7229 - val_loss: 1.7202 - val_acc: 0.4400\n",
      "Epoch 413/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8139 - acc: 0.7214 - val_loss: 1.7333 - val_acc: 0.4467\n",
      "Epoch 414/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8131 - acc: 0.7186 - val_loss: 1.7266 - val_acc: 0.4533\n",
      "Epoch 415/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8129 - acc: 0.7271 - val_loss: 1.7392 - val_acc: 0.4533\n",
      "Epoch 416/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8122 - acc: 0.7171 - val_loss: 1.7281 - val_acc: 0.4500\n",
      "Epoch 417/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8119 - acc: 0.7243 - val_loss: 1.7261 - val_acc: 0.4533\n",
      "Epoch 418/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8113 - acc: 0.7214 - val_loss: 1.7248 - val_acc: 0.4567\n",
      "Epoch 419/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8105 - acc: 0.7257 - val_loss: 1.7404 - val_acc: 0.4433\n",
      "Epoch 420/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8104 - acc: 0.7243 - val_loss: 1.7261 - val_acc: 0.4467\n",
      "Epoch 421/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8096 - acc: 0.7243 - val_loss: 1.7206 - val_acc: 0.4500\n",
      "Epoch 422/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8096 - acc: 0.7257 - val_loss: 1.7240 - val_acc: 0.4467\n",
      "Epoch 423/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8086 - acc: 0.7300 - val_loss: 1.7342 - val_acc: 0.4500\n",
      "Epoch 424/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8088 - acc: 0.7200 - val_loss: 1.7367 - val_acc: 0.4367\n",
      "Epoch 425/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8079 - acc: 0.7271 - val_loss: 1.7388 - val_acc: 0.4433\n",
      "Epoch 426/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8073 - acc: 0.7243 - val_loss: 1.7468 - val_acc: 0.4467\n",
      "Epoch 427/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8067 - acc: 0.7257 - val_loss: 1.7261 - val_acc: 0.4567\n",
      "Epoch 428/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8065 - acc: 0.7229 - val_loss: 1.7372 - val_acc: 0.4467\n",
      "Epoch 429/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8049 - acc: 0.7257 - val_loss: 1.7416 - val_acc: 0.4433\n",
      "Epoch 430/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8049 - acc: 0.7257 - val_loss: 1.7398 - val_acc: 0.4500\n",
      "Epoch 431/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8032 - acc: 0.7314 - val_loss: 1.7556 - val_acc: 0.4467\n",
      "Epoch 432/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8039 - acc: 0.7243 - val_loss: 1.7373 - val_acc: 0.4433\n",
      "Epoch 433/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8032 - acc: 0.7243 - val_loss: 1.7452 - val_acc: 0.4400\n",
      "Epoch 434/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8036 - acc: 0.7200 - val_loss: 1.7442 - val_acc: 0.4433\n",
      "Epoch 435/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8025 - acc: 0.7186 - val_loss: 1.7478 - val_acc: 0.4467\n",
      "Epoch 436/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8025 - acc: 0.7243 - val_loss: 1.7441 - val_acc: 0.4433\n",
      "Epoch 437/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8012 - acc: 0.7329 - val_loss: 1.7526 - val_acc: 0.4467\n",
      "Epoch 438/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8006 - acc: 0.7243 - val_loss: 1.7515 - val_acc: 0.4467\n",
      "Epoch 439/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8011 - acc: 0.7243 - val_loss: 1.7517 - val_acc: 0.4433\n",
      "Epoch 440/1000\n",
      "700/700 [==============================] - 0s - loss: 0.8004 - acc: 0.7257 - val_loss: 1.7487 - val_acc: 0.4500\n",
      "Epoch 441/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7997 - acc: 0.7357 - val_loss: 1.7575 - val_acc: 0.4467\n",
      "Epoch 442/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7992 - acc: 0.7271 - val_loss: 1.7501 - val_acc: 0.4467\n",
      "Epoch 443/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7986 - acc: 0.7257 - val_loss: 1.7606 - val_acc: 0.4533\n",
      "Epoch 444/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7985 - acc: 0.7257 - val_loss: 1.7688 - val_acc: 0.4533\n",
      "Epoch 445/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7979 - acc: 0.7243 - val_loss: 1.7519 - val_acc: 0.4500\n",
      "Epoch 446/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7975 - acc: 0.7157 - val_loss: 1.7576 - val_acc: 0.4433\n",
      "Epoch 447/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7969 - acc: 0.7229 - val_loss: 1.7707 - val_acc: 0.4467\n",
      "Epoch 448/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7959 - acc: 0.7286 - val_loss: 1.7545 - val_acc: 0.4500\n",
      "Epoch 449/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7966 - acc: 0.7257 - val_loss: 1.7635 - val_acc: 0.4467\n",
      "Epoch 450/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7950 - acc: 0.7314 - val_loss: 1.7751 - val_acc: 0.4400\n",
      "Epoch 451/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7946 - acc: 0.7300 - val_loss: 1.7775 - val_acc: 0.4433\n",
      "Epoch 452/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7950 - acc: 0.7214 - val_loss: 1.7696 - val_acc: 0.4433\n",
      "Epoch 453/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7946 - acc: 0.7286 - val_loss: 1.7634 - val_acc: 0.4400\n",
      "Epoch 454/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7931 - acc: 0.7300 - val_loss: 1.7722 - val_acc: 0.4367\n",
      "Epoch 455/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7935 - acc: 0.7271 - val_loss: 1.7649 - val_acc: 0.4467\n",
      "Epoch 456/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7931 - acc: 0.7243 - val_loss: 1.7684 - val_acc: 0.4400\n",
      "Epoch 457/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7922 - acc: 0.7329 - val_loss: 1.7721 - val_acc: 0.4367\n",
      "Epoch 458/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7915 - acc: 0.7286 - val_loss: 1.7684 - val_acc: 0.4467\n",
      "Epoch 459/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7909 - acc: 0.7271 - val_loss: 1.7830 - val_acc: 0.4400\n",
      "Epoch 460/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7910 - acc: 0.7243 - val_loss: 1.7757 - val_acc: 0.4400\n",
      "Epoch 461/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7899 - acc: 0.7314 - val_loss: 1.7805 - val_acc: 0.4400\n",
      "Epoch 462/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7897 - acc: 0.7300 - val_loss: 1.7732 - val_acc: 0.4400\n",
      "Epoch 463/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7900 - acc: 0.7371 - val_loss: 1.7785 - val_acc: 0.4400\n",
      "Epoch 464/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7900 - acc: 0.7314 - val_loss: 1.7729 - val_acc: 0.4400\n",
      "Epoch 465/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7883 - acc: 0.7329 - val_loss: 1.7786 - val_acc: 0.4333\n",
      "Epoch 466/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7878 - acc: 0.7343 - val_loss: 1.7867 - val_acc: 0.4367\n",
      "Epoch 467/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7881 - acc: 0.7300 - val_loss: 1.7796 - val_acc: 0.4367\n",
      "Epoch 468/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7872 - acc: 0.7271 - val_loss: 1.7946 - val_acc: 0.4333\n",
      "Epoch 469/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7865 - acc: 0.7257 - val_loss: 1.7714 - val_acc: 0.4333\n",
      "Epoch 470/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7868 - acc: 0.7314 - val_loss: 1.7880 - val_acc: 0.4367\n",
      "Epoch 471/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7859 - acc: 0.7314 - val_loss: 1.7760 - val_acc: 0.4400\n",
      "Epoch 472/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7858 - acc: 0.7329 - val_loss: 1.7877 - val_acc: 0.4333\n",
      "Epoch 473/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7846 - acc: 0.7343 - val_loss: 1.7804 - val_acc: 0.4367\n",
      "Epoch 474/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7849 - acc: 0.7286 - val_loss: 1.7867 - val_acc: 0.4367\n",
      "Epoch 475/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7843 - acc: 0.7314 - val_loss: 1.7817 - val_acc: 0.4433\n",
      "Epoch 476/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7838 - acc: 0.7329 - val_loss: 1.7923 - val_acc: 0.4433\n",
      "Epoch 477/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7840 - acc: 0.7314 - val_loss: 1.7870 - val_acc: 0.4367\n",
      "Epoch 478/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7826 - acc: 0.7357 - val_loss: 1.7848 - val_acc: 0.4300\n",
      "Epoch 479/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7825 - acc: 0.7300 - val_loss: 1.7997 - val_acc: 0.4367\n",
      "Epoch 480/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7818 - acc: 0.7329 - val_loss: 1.7936 - val_acc: 0.4400\n",
      "Epoch 481/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7819 - acc: 0.7343 - val_loss: 1.8047 - val_acc: 0.4333\n",
      "Epoch 482/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7814 - acc: 0.7257 - val_loss: 1.7962 - val_acc: 0.4367\n",
      "Epoch 483/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7808 - acc: 0.7343 - val_loss: 1.7977 - val_acc: 0.4367\n",
      "Epoch 484/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7803 - acc: 0.7357 - val_loss: 1.7913 - val_acc: 0.4333\n",
      "Epoch 485/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7801 - acc: 0.7357 - val_loss: 1.7960 - val_acc: 0.4333\n",
      "Epoch 486/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7790 - acc: 0.7357 - val_loss: 1.7953 - val_acc: 0.4367\n",
      "Epoch 487/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7796 - acc: 0.7286 - val_loss: 1.8014 - val_acc: 0.4333\n",
      "Epoch 488/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7791 - acc: 0.7286 - val_loss: 1.7982 - val_acc: 0.4300\n",
      "Epoch 489/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7777 - acc: 0.7329 - val_loss: 1.7912 - val_acc: 0.4300\n",
      "Epoch 490/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7766 - acc: 0.7314 - val_loss: 1.7956 - val_acc: 0.4333\n",
      "Epoch 491/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7769 - acc: 0.7343 - val_loss: 1.8039 - val_acc: 0.4333\n",
      "Epoch 492/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7773 - acc: 0.7343 - val_loss: 1.7964 - val_acc: 0.4300\n",
      "Epoch 493/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7770 - acc: 0.7329 - val_loss: 1.8028 - val_acc: 0.4367\n",
      "Epoch 494/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7763 - acc: 0.7357 - val_loss: 1.7991 - val_acc: 0.4367\n",
      "Epoch 495/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7755 - acc: 0.7371 - val_loss: 1.8037 - val_acc: 0.4367\n",
      "Epoch 496/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7750 - acc: 0.7386 - val_loss: 1.8205 - val_acc: 0.4367\n",
      "Epoch 497/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7755 - acc: 0.7300 - val_loss: 1.8078 - val_acc: 0.4333\n",
      "Epoch 498/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7752 - acc: 0.7329 - val_loss: 1.8169 - val_acc: 0.4300\n",
      "Epoch 499/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7743 - acc: 0.7329 - val_loss: 1.8048 - val_acc: 0.4333\n",
      "Epoch 500/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7736 - acc: 0.7400 - val_loss: 1.8172 - val_acc: 0.4367\n",
      "Epoch 501/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7738 - acc: 0.7343 - val_loss: 1.8127 - val_acc: 0.4333\n",
      "Epoch 502/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7732 - acc: 0.7329 - val_loss: 1.8121 - val_acc: 0.4333\n",
      "Epoch 503/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7728 - acc: 0.7400 - val_loss: 1.8140 - val_acc: 0.4367\n",
      "Epoch 504/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7728 - acc: 0.7343 - val_loss: 1.8159 - val_acc: 0.4367\n",
      "Epoch 505/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7722 - acc: 0.7329 - val_loss: 1.8189 - val_acc: 0.4300\n",
      "Epoch 506/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7722 - acc: 0.7371 - val_loss: 1.8183 - val_acc: 0.4300\n",
      "Epoch 507/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7711 - acc: 0.7300 - val_loss: 1.8169 - val_acc: 0.4300\n",
      "Epoch 508/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7709 - acc: 0.7357 - val_loss: 1.8166 - val_acc: 0.4267\n",
      "Epoch 509/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7704 - acc: 0.7329 - val_loss: 1.8241 - val_acc: 0.4267\n",
      "Epoch 510/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7701 - acc: 0.7357 - val_loss: 1.8235 - val_acc: 0.4333\n",
      "Epoch 511/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7702 - acc: 0.7329 - val_loss: 1.8243 - val_acc: 0.4267\n",
      "Epoch 512/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7694 - acc: 0.7386 - val_loss: 1.8230 - val_acc: 0.4233\n",
      "Epoch 513/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7694 - acc: 0.7343 - val_loss: 1.8205 - val_acc: 0.4300\n",
      "Epoch 514/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7688 - acc: 0.7357 - val_loss: 1.8239 - val_acc: 0.4333\n",
      "Epoch 515/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7683 - acc: 0.7300 - val_loss: 1.8213 - val_acc: 0.4300\n",
      "Epoch 516/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7676 - acc: 0.7386 - val_loss: 1.8281 - val_acc: 0.4300\n",
      "Epoch 517/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7672 - acc: 0.7386 - val_loss: 1.8444 - val_acc: 0.4300\n",
      "Epoch 518/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7672 - acc: 0.7343 - val_loss: 1.8275 - val_acc: 0.4267\n",
      "Epoch 519/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7675 - acc: 0.7371 - val_loss: 1.8306 - val_acc: 0.4267\n",
      "Epoch 520/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7660 - acc: 0.7371 - val_loss: 1.8331 - val_acc: 0.4267\n",
      "Epoch 521/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7668 - acc: 0.7414 - val_loss: 1.8387 - val_acc: 0.4300\n",
      "Epoch 522/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7660 - acc: 0.7343 - val_loss: 1.8278 - val_acc: 0.4267\n",
      "Epoch 523/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7652 - acc: 0.7386 - val_loss: 1.8289 - val_acc: 0.4300\n",
      "Epoch 524/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7653 - acc: 0.7429 - val_loss: 1.8324 - val_acc: 0.4267\n",
      "Epoch 525/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7654 - acc: 0.7414 - val_loss: 1.8374 - val_acc: 0.4300\n",
      "Epoch 526/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7634 - acc: 0.7386 - val_loss: 1.8430 - val_acc: 0.4300\n",
      "Epoch 527/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7643 - acc: 0.7386 - val_loss: 1.8366 - val_acc: 0.4267\n",
      "Epoch 528/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7632 - acc: 0.7400 - val_loss: 1.8308 - val_acc: 0.4267\n",
      "Epoch 529/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7635 - acc: 0.7386 - val_loss: 1.8462 - val_acc: 0.4300\n",
      "Epoch 530/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7632 - acc: 0.7371 - val_loss: 1.8376 - val_acc: 0.4333\n",
      "Epoch 531/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7625 - acc: 0.7457 - val_loss: 1.8538 - val_acc: 0.4267\n",
      "Epoch 532/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7627 - acc: 0.7414 - val_loss: 1.8459 - val_acc: 0.4233\n",
      "Epoch 533/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7620 - acc: 0.7386 - val_loss: 1.8387 - val_acc: 0.4267\n",
      "Epoch 534/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7618 - acc: 0.7371 - val_loss: 1.8463 - val_acc: 0.4233\n",
      "Epoch 535/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7612 - acc: 0.7386 - val_loss: 1.8421 - val_acc: 0.4233\n",
      "Epoch 536/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7599 - acc: 0.7357 - val_loss: 1.8451 - val_acc: 0.4267\n",
      "Epoch 537/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7606 - acc: 0.7386 - val_loss: 1.8399 - val_acc: 0.4233\n",
      "Epoch 538/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7597 - acc: 0.7457 - val_loss: 1.8475 - val_acc: 0.4300\n",
      "Epoch 539/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7597 - acc: 0.7414 - val_loss: 1.8547 - val_acc: 0.4300\n",
      "Epoch 540/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7593 - acc: 0.7400 - val_loss: 1.8566 - val_acc: 0.4200\n",
      "Epoch 541/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7590 - acc: 0.7329 - val_loss: 1.8628 - val_acc: 0.4267\n",
      "Epoch 542/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7587 - acc: 0.7400 - val_loss: 1.8586 - val_acc: 0.4300\n",
      "Epoch 543/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7581 - acc: 0.7429 - val_loss: 1.8567 - val_acc: 0.4200\n",
      "Epoch 544/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7573 - acc: 0.7386 - val_loss: 1.8487 - val_acc: 0.4200\n",
      "Epoch 545/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7582 - acc: 0.7400 - val_loss: 1.8594 - val_acc: 0.4167\n",
      "Epoch 546/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7578 - acc: 0.7386 - val_loss: 1.8644 - val_acc: 0.4167\n",
      "Epoch 547/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7572 - acc: 0.7443 - val_loss: 1.8672 - val_acc: 0.4267\n",
      "Epoch 548/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7566 - acc: 0.7371 - val_loss: 1.8567 - val_acc: 0.4200\n",
      "Epoch 549/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7564 - acc: 0.7400 - val_loss: 1.8649 - val_acc: 0.4200\n",
      "Epoch 550/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7566 - acc: 0.7414 - val_loss: 1.8604 - val_acc: 0.4233\n",
      "Epoch 551/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7554 - acc: 0.7429 - val_loss: 1.8774 - val_acc: 0.4233\n",
      "Epoch 552/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7555 - acc: 0.7429 - val_loss: 1.8626 - val_acc: 0.4200\n",
      "Epoch 553/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7550 - acc: 0.7414 - val_loss: 1.8600 - val_acc: 0.4233\n",
      "Epoch 554/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7548 - acc: 0.7443 - val_loss: 1.8827 - val_acc: 0.4200\n",
      "Epoch 555/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7546 - acc: 0.7443 - val_loss: 1.8606 - val_acc: 0.4200\n",
      "Epoch 556/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7542 - acc: 0.7429 - val_loss: 1.8656 - val_acc: 0.4267\n",
      "Epoch 557/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7538 - acc: 0.7443 - val_loss: 1.8757 - val_acc: 0.4233\n",
      "Epoch 558/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7533 - acc: 0.7400 - val_loss: 1.8690 - val_acc: 0.4200\n",
      "Epoch 559/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7533 - acc: 0.7414 - val_loss: 1.8726 - val_acc: 0.4300\n",
      "Epoch 560/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7530 - acc: 0.7443 - val_loss: 1.8764 - val_acc: 0.4267\n",
      "Epoch 561/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7523 - acc: 0.7443 - val_loss: 1.8749 - val_acc: 0.4233\n",
      "Epoch 562/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7524 - acc: 0.7400 - val_loss: 1.8887 - val_acc: 0.4167\n",
      "Epoch 563/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7521 - acc: 0.7429 - val_loss: 1.8734 - val_acc: 0.4233\n",
      "Epoch 564/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7521 - acc: 0.7471 - val_loss: 1.8775 - val_acc: 0.4200\n",
      "Epoch 565/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7516 - acc: 0.7400 - val_loss: 1.8809 - val_acc: 0.4267\n",
      "Epoch 566/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7509 - acc: 0.7414 - val_loss: 1.8825 - val_acc: 0.4267\n",
      "Epoch 567/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7505 - acc: 0.7400 - val_loss: 1.8820 - val_acc: 0.4267\n",
      "Epoch 568/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7505 - acc: 0.7457 - val_loss: 1.8817 - val_acc: 0.4267\n",
      "Epoch 569/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7492 - acc: 0.7486 - val_loss: 1.8956 - val_acc: 0.4233\n",
      "Epoch 570/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7495 - acc: 0.7443 - val_loss: 1.8883 - val_acc: 0.4267\n",
      "Epoch 571/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7498 - acc: 0.7457 - val_loss: 1.8936 - val_acc: 0.4267\n",
      "Epoch 572/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7494 - acc: 0.7443 - val_loss: 1.8840 - val_acc: 0.4233\n",
      "Epoch 573/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7482 - acc: 0.7471 - val_loss: 1.8956 - val_acc: 0.4267\n",
      "Epoch 574/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7490 - acc: 0.7414 - val_loss: 1.8880 - val_acc: 0.4300\n",
      "Epoch 575/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7483 - acc: 0.7471 - val_loss: 1.8868 - val_acc: 0.4233\n",
      "Epoch 576/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7485 - acc: 0.7400 - val_loss: 1.8896 - val_acc: 0.4200\n",
      "Epoch 577/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7475 - acc: 0.7443 - val_loss: 1.8983 - val_acc: 0.4167\n",
      "Epoch 578/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7479 - acc: 0.7471 - val_loss: 1.8840 - val_acc: 0.4200\n",
      "Epoch 579/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7471 - acc: 0.7471 - val_loss: 1.8978 - val_acc: 0.4233\n",
      "Epoch 580/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7468 - acc: 0.7414 - val_loss: 1.9035 - val_acc: 0.4133\n",
      "Epoch 581/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7468 - acc: 0.7486 - val_loss: 1.8969 - val_acc: 0.4200\n",
      "Epoch 582/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7464 - acc: 0.7471 - val_loss: 1.8960 - val_acc: 0.4133\n",
      "Epoch 583/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7459 - acc: 0.7429 - val_loss: 1.8986 - val_acc: 0.4300\n",
      "Epoch 584/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7452 - acc: 0.7500 - val_loss: 1.8955 - val_acc: 0.4133\n",
      "Epoch 585/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7454 - acc: 0.7443 - val_loss: 1.8994 - val_acc: 0.4267\n",
      "Epoch 586/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7448 - acc: 0.7429 - val_loss: 1.8953 - val_acc: 0.4233\n",
      "Epoch 587/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7453 - acc: 0.7471 - val_loss: 1.9094 - val_acc: 0.4233\n",
      "Epoch 588/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7444 - acc: 0.7443 - val_loss: 1.9076 - val_acc: 0.4233\n",
      "Epoch 589/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7437 - acc: 0.7486 - val_loss: 1.8910 - val_acc: 0.4233\n",
      "Epoch 590/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7433 - acc: 0.7443 - val_loss: 1.8994 - val_acc: 0.4267\n",
      "Epoch 591/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7434 - acc: 0.7443 - val_loss: 1.9104 - val_acc: 0.4167\n",
      "Epoch 592/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7429 - acc: 0.7429 - val_loss: 1.9049 - val_acc: 0.4233\n",
      "Epoch 593/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7431 - acc: 0.7471 - val_loss: 1.9054 - val_acc: 0.4300\n",
      "Epoch 594/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7434 - acc: 0.7471 - val_loss: 1.9105 - val_acc: 0.4267\n",
      "Epoch 595/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7424 - acc: 0.7457 - val_loss: 1.9078 - val_acc: 0.4233\n",
      "Epoch 596/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7420 - acc: 0.7414 - val_loss: 1.9114 - val_acc: 0.4200\n",
      "Epoch 597/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7427 - acc: 0.7471 - val_loss: 1.9182 - val_acc: 0.4200\n",
      "Epoch 598/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7415 - acc: 0.7486 - val_loss: 1.9136 - val_acc: 0.4233\n",
      "Epoch 599/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7413 - acc: 0.7514 - val_loss: 1.9104 - val_acc: 0.4267\n",
      "Epoch 600/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7407 - acc: 0.7443 - val_loss: 1.9066 - val_acc: 0.4233\n",
      "Epoch 601/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7407 - acc: 0.7457 - val_loss: 1.9143 - val_acc: 0.4267\n",
      "Epoch 602/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7410 - acc: 0.7500 - val_loss: 1.9167 - val_acc: 0.4233\n",
      "Epoch 603/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7404 - acc: 0.7471 - val_loss: 1.9194 - val_acc: 0.4233\n",
      "Epoch 604/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7400 - acc: 0.7471 - val_loss: 1.9229 - val_acc: 0.4167\n",
      "Epoch 605/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7397 - acc: 0.7443 - val_loss: 1.9259 - val_acc: 0.4233\n",
      "Epoch 606/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7392 - acc: 0.7514 - val_loss: 1.9334 - val_acc: 0.4267\n",
      "Epoch 607/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7390 - acc: 0.7457 - val_loss: 1.9057 - val_acc: 0.4100\n",
      "Epoch 608/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7392 - acc: 0.7471 - val_loss: 1.9201 - val_acc: 0.4233\n",
      "Epoch 609/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7386 - acc: 0.7429 - val_loss: 1.9290 - val_acc: 0.4233\n",
      "Epoch 610/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7385 - acc: 0.7471 - val_loss: 1.9194 - val_acc: 0.4300\n",
      "Epoch 611/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7382 - acc: 0.7500 - val_loss: 1.9305 - val_acc: 0.4167\n",
      "Epoch 612/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7376 - acc: 0.7457 - val_loss: 1.9261 - val_acc: 0.4200\n",
      "Epoch 613/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7378 - acc: 0.7471 - val_loss: 1.9320 - val_acc: 0.4167\n",
      "Epoch 614/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7365 - acc: 0.7457 - val_loss: 1.9323 - val_acc: 0.4133\n",
      "Epoch 615/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7368 - acc: 0.7471 - val_loss: 1.9123 - val_acc: 0.4200\n",
      "Epoch 616/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7358 - acc: 0.7500 - val_loss: 1.9435 - val_acc: 0.4200\n",
      "Epoch 617/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7366 - acc: 0.7457 - val_loss: 1.9387 - val_acc: 0.4233\n",
      "Epoch 618/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7359 - acc: 0.7529 - val_loss: 1.9284 - val_acc: 0.4133\n",
      "Epoch 619/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7364 - acc: 0.7457 - val_loss: 1.9302 - val_acc: 0.4233\n",
      "Epoch 620/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7356 - acc: 0.7486 - val_loss: 1.9405 - val_acc: 0.4133\n",
      "Epoch 621/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7358 - acc: 0.7514 - val_loss: 1.9330 - val_acc: 0.4167\n",
      "Epoch 622/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7355 - acc: 0.7486 - val_loss: 1.9367 - val_acc: 0.4200\n",
      "Epoch 623/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7350 - acc: 0.7457 - val_loss: 1.9552 - val_acc: 0.4333\n",
      "Epoch 624/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7347 - acc: 0.7471 - val_loss: 1.9301 - val_acc: 0.4267\n",
      "Epoch 625/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7340 - acc: 0.7471 - val_loss: 1.9472 - val_acc: 0.4200\n",
      "Epoch 626/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7344 - acc: 0.7486 - val_loss: 1.9506 - val_acc: 0.4200\n",
      "Epoch 627/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7339 - acc: 0.7486 - val_loss: 1.9500 - val_acc: 0.4233\n",
      "Epoch 628/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7334 - acc: 0.7500 - val_loss: 1.9408 - val_acc: 0.4267\n",
      "Epoch 629/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7331 - acc: 0.7486 - val_loss: 1.9291 - val_acc: 0.4233\n",
      "Epoch 630/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7328 - acc: 0.7486 - val_loss: 1.9396 - val_acc: 0.4200\n",
      "Epoch 631/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7329 - acc: 0.7486 - val_loss: 1.9323 - val_acc: 0.4167\n",
      "Epoch 632/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7328 - acc: 0.7457 - val_loss: 1.9342 - val_acc: 0.4267\n",
      "Epoch 633/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7325 - acc: 0.7500 - val_loss: 1.9513 - val_acc: 0.4133\n",
      "Epoch 634/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7319 - acc: 0.7471 - val_loss: 1.9645 - val_acc: 0.4267\n",
      "Epoch 635/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7318 - acc: 0.7471 - val_loss: 1.9380 - val_acc: 0.4267\n",
      "Epoch 636/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7319 - acc: 0.7529 - val_loss: 1.9495 - val_acc: 0.4167\n",
      "Epoch 637/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7313 - acc: 0.7500 - val_loss: 1.9496 - val_acc: 0.4167\n",
      "Epoch 638/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7310 - acc: 0.7443 - val_loss: 1.9549 - val_acc: 0.4200\n",
      "Epoch 639/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7316 - acc: 0.7500 - val_loss: 1.9510 - val_acc: 0.4167\n",
      "Epoch 640/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7305 - acc: 0.7486 - val_loss: 1.9546 - val_acc: 0.4200\n",
      "Epoch 641/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7303 - acc: 0.7500 - val_loss: 1.9480 - val_acc: 0.4200\n",
      "Epoch 642/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7303 - acc: 0.7486 - val_loss: 1.9553 - val_acc: 0.4200\n",
      "Epoch 643/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7298 - acc: 0.7500 - val_loss: 1.9625 - val_acc: 0.4167\n",
      "Epoch 644/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7297 - acc: 0.7514 - val_loss: 1.9732 - val_acc: 0.4167\n",
      "Epoch 645/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7292 - acc: 0.7471 - val_loss: 1.9530 - val_acc: 0.4167\n",
      "Epoch 646/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7296 - acc: 0.7471 - val_loss: 1.9521 - val_acc: 0.4200\n",
      "Epoch 647/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7290 - acc: 0.7471 - val_loss: 1.9647 - val_acc: 0.4167\n",
      "Epoch 648/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7288 - acc: 0.7486 - val_loss: 1.9617 - val_acc: 0.4200\n",
      "Epoch 649/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7285 - acc: 0.7471 - val_loss: 1.9706 - val_acc: 0.4200\n",
      "Epoch 650/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7283 - acc: 0.7514 - val_loss: 1.9711 - val_acc: 0.4200\n",
      "Epoch 651/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7282 - acc: 0.7457 - val_loss: 1.9770 - val_acc: 0.4267\n",
      "Epoch 652/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7274 - acc: 0.7529 - val_loss: 1.9723 - val_acc: 0.4167\n",
      "Epoch 653/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7277 - acc: 0.7471 - val_loss: 1.9760 - val_acc: 0.4133\n",
      "Epoch 654/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7270 - acc: 0.7471 - val_loss: 1.9727 - val_acc: 0.4133\n",
      "Epoch 655/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7278 - acc: 0.7486 - val_loss: 1.9732 - val_acc: 0.4200\n",
      "Epoch 656/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7267 - acc: 0.7471 - val_loss: 1.9591 - val_acc: 0.4200\n",
      "Epoch 657/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7264 - acc: 0.7514 - val_loss: 1.9697 - val_acc: 0.4167\n",
      "Epoch 658/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7261 - acc: 0.7514 - val_loss: 1.9739 - val_acc: 0.4200\n",
      "Epoch 659/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7260 - acc: 0.7514 - val_loss: 1.9723 - val_acc: 0.4200\n",
      "Epoch 660/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7255 - acc: 0.7514 - val_loss: 1.9786 - val_acc: 0.4167\n",
      "Epoch 661/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7260 - acc: 0.7500 - val_loss: 1.9788 - val_acc: 0.4200\n",
      "Epoch 662/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7248 - acc: 0.7514 - val_loss: 1.9894 - val_acc: 0.4167\n",
      "Epoch 663/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7254 - acc: 0.7514 - val_loss: 1.9841 - val_acc: 0.4167\n",
      "Epoch 664/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7251 - acc: 0.7529 - val_loss: 1.9746 - val_acc: 0.4167\n",
      "Epoch 665/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7247 - acc: 0.7557 - val_loss: 1.9721 - val_acc: 0.4133\n",
      "Epoch 666/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7240 - acc: 0.7500 - val_loss: 1.9767 - val_acc: 0.4167\n",
      "Epoch 667/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7241 - acc: 0.7557 - val_loss: 1.9826 - val_acc: 0.4167\n",
      "Epoch 668/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7240 - acc: 0.7514 - val_loss: 1.9824 - val_acc: 0.4167\n",
      "Epoch 669/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7238 - acc: 0.7500 - val_loss: 1.9869 - val_acc: 0.4167\n",
      "Epoch 670/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7234 - acc: 0.7486 - val_loss: 1.9774 - val_acc: 0.4233\n",
      "Epoch 671/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7232 - acc: 0.7514 - val_loss: 1.9893 - val_acc: 0.4167\n",
      "Epoch 672/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7228 - acc: 0.7457 - val_loss: 1.9869 - val_acc: 0.4133\n",
      "Epoch 673/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7229 - acc: 0.7543 - val_loss: 1.9846 - val_acc: 0.4167\n",
      "Epoch 674/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7226 - acc: 0.7557 - val_loss: 1.9771 - val_acc: 0.4067\n",
      "Epoch 675/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7228 - acc: 0.7543 - val_loss: 1.9939 - val_acc: 0.4167\n",
      "Epoch 676/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7223 - acc: 0.7514 - val_loss: 1.9889 - val_acc: 0.4133\n",
      "Epoch 677/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7225 - acc: 0.7514 - val_loss: 1.9883 - val_acc: 0.4167\n",
      "Epoch 678/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7218 - acc: 0.7557 - val_loss: 1.9949 - val_acc: 0.4133\n",
      "Epoch 679/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7215 - acc: 0.7571 - val_loss: 1.9902 - val_acc: 0.4200\n",
      "Epoch 680/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7206 - acc: 0.7500 - val_loss: 2.0009 - val_acc: 0.4233\n",
      "Epoch 681/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7215 - acc: 0.7529 - val_loss: 1.9959 - val_acc: 0.4200\n",
      "Epoch 682/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7211 - acc: 0.7529 - val_loss: 1.9988 - val_acc: 0.4133\n",
      "Epoch 683/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7206 - acc: 0.7557 - val_loss: 1.9969 - val_acc: 0.4200\n",
      "Epoch 684/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7203 - acc: 0.7557 - val_loss: 2.0003 - val_acc: 0.4133\n",
      "Epoch 685/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7201 - acc: 0.7557 - val_loss: 2.0083 - val_acc: 0.4200\n",
      "Epoch 686/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7201 - acc: 0.7529 - val_loss: 1.9920 - val_acc: 0.4133\n",
      "Epoch 687/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7201 - acc: 0.7514 - val_loss: 2.0123 - val_acc: 0.4200\n",
      "Epoch 688/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7201 - acc: 0.7500 - val_loss: 1.9977 - val_acc: 0.4133\n",
      "Epoch 689/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7193 - acc: 0.7557 - val_loss: 2.0048 - val_acc: 0.4133\n",
      "Epoch 690/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7189 - acc: 0.7557 - val_loss: 1.9999 - val_acc: 0.4167\n",
      "Epoch 691/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7191 - acc: 0.7514 - val_loss: 1.9988 - val_acc: 0.4133\n",
      "Epoch 692/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7183 - acc: 0.7529 - val_loss: 1.9967 - val_acc: 0.4100\n",
      "Epoch 693/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7186 - acc: 0.7514 - val_loss: 2.0057 - val_acc: 0.4033\n",
      "Epoch 694/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7180 - acc: 0.7600 - val_loss: 2.0099 - val_acc: 0.4233\n",
      "Epoch 695/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7184 - acc: 0.7529 - val_loss: 2.0022 - val_acc: 0.4133\n",
      "Epoch 696/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7178 - acc: 0.7571 - val_loss: 2.0063 - val_acc: 0.4133\n",
      "Epoch 697/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7178 - acc: 0.7571 - val_loss: 2.0174 - val_acc: 0.4200\n",
      "Epoch 698/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7177 - acc: 0.7557 - val_loss: 2.0125 - val_acc: 0.4133\n",
      "Epoch 699/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7173 - acc: 0.7486 - val_loss: 2.0141 - val_acc: 0.4133\n",
      "Epoch 700/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7173 - acc: 0.7543 - val_loss: 2.0024 - val_acc: 0.4133\n",
      "Epoch 701/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7172 - acc: 0.7557 - val_loss: 2.0161 - val_acc: 0.4133\n",
      "Epoch 702/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7168 - acc: 0.7600 - val_loss: 2.0211 - val_acc: 0.4233\n",
      "Epoch 703/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7161 - acc: 0.7529 - val_loss: 2.0077 - val_acc: 0.4133\n",
      "Epoch 704/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7163 - acc: 0.7543 - val_loss: 2.0174 - val_acc: 0.4133\n",
      "Epoch 705/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7162 - acc: 0.7586 - val_loss: 2.0201 - val_acc: 0.4167\n",
      "Epoch 706/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7158 - acc: 0.7529 - val_loss: 2.0176 - val_acc: 0.4067\n",
      "Epoch 707/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7159 - acc: 0.7586 - val_loss: 2.0194 - val_acc: 0.4067\n",
      "Epoch 708/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7153 - acc: 0.7586 - val_loss: 2.0175 - val_acc: 0.4100\n",
      "Epoch 709/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7153 - acc: 0.7557 - val_loss: 2.0175 - val_acc: 0.4000\n",
      "Epoch 710/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7154 - acc: 0.7614 - val_loss: 2.0263 - val_acc: 0.4167\n",
      "Epoch 711/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7153 - acc: 0.7529 - val_loss: 2.0239 - val_acc: 0.4033\n",
      "Epoch 712/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7143 - acc: 0.7571 - val_loss: 2.0214 - val_acc: 0.4067\n",
      "Epoch 713/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7144 - acc: 0.7600 - val_loss: 2.0252 - val_acc: 0.4100\n",
      "Epoch 714/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7140 - acc: 0.7543 - val_loss: 2.0317 - val_acc: 0.4033\n",
      "Epoch 715/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7136 - acc: 0.7557 - val_loss: 2.0134 - val_acc: 0.4200\n",
      "Epoch 716/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7139 - acc: 0.7600 - val_loss: 2.0376 - val_acc: 0.4100\n",
      "Epoch 717/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7139 - acc: 0.7543 - val_loss: 2.0365 - val_acc: 0.4167\n",
      "Epoch 718/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7134 - acc: 0.7557 - val_loss: 2.0271 - val_acc: 0.4167\n",
      "Epoch 719/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7132 - acc: 0.7543 - val_loss: 2.0292 - val_acc: 0.4133\n",
      "Epoch 720/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7130 - acc: 0.7586 - val_loss: 2.0278 - val_acc: 0.4200\n",
      "Epoch 721/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7130 - acc: 0.7586 - val_loss: 2.0351 - val_acc: 0.4200\n",
      "Epoch 722/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7124 - acc: 0.7614 - val_loss: 2.0499 - val_acc: 0.4233\n",
      "Epoch 723/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7128 - acc: 0.7614 - val_loss: 2.0317 - val_acc: 0.4100\n",
      "Epoch 724/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7119 - acc: 0.7571 - val_loss: 2.0461 - val_acc: 0.4200\n",
      "Epoch 725/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7119 - acc: 0.7557 - val_loss: 2.0422 - val_acc: 0.4167\n",
      "Epoch 726/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7121 - acc: 0.7543 - val_loss: 2.0338 - val_acc: 0.4100\n",
      "Epoch 727/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7118 - acc: 0.7557 - val_loss: 2.0298 - val_acc: 0.4167\n",
      "Epoch 728/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7112 - acc: 0.7571 - val_loss: 2.0352 - val_acc: 0.4133\n",
      "Epoch 729/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7112 - acc: 0.7600 - val_loss: 2.0351 - val_acc: 0.4100\n",
      "Epoch 730/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7114 - acc: 0.7586 - val_loss: 2.0435 - val_acc: 0.4167\n",
      "Epoch 731/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7108 - acc: 0.7571 - val_loss: 2.0486 - val_acc: 0.4133\n",
      "Epoch 732/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7105 - acc: 0.7529 - val_loss: 2.0384 - val_acc: 0.4133\n",
      "Epoch 733/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7109 - acc: 0.7571 - val_loss: 2.0372 - val_acc: 0.4100\n",
      "Epoch 734/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7102 - acc: 0.7629 - val_loss: 2.0543 - val_acc: 0.4233\n",
      "Epoch 735/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7103 - acc: 0.7629 - val_loss: 2.0500 - val_acc: 0.4133\n",
      "Epoch 736/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7098 - acc: 0.7600 - val_loss: 2.0450 - val_acc: 0.4133\n",
      "Epoch 737/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7095 - acc: 0.7514 - val_loss: 2.0410 - val_acc: 0.4200\n",
      "Epoch 738/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7095 - acc: 0.7586 - val_loss: 2.0441 - val_acc: 0.4167\n",
      "Epoch 739/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7097 - acc: 0.7557 - val_loss: 2.0474 - val_acc: 0.4167\n",
      "Epoch 740/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7091 - acc: 0.7529 - val_loss: 2.0498 - val_acc: 0.4167\n",
      "Epoch 741/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7089 - acc: 0.7629 - val_loss: 2.0467 - val_acc: 0.4167\n",
      "Epoch 742/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7091 - acc: 0.7571 - val_loss: 2.0506 - val_acc: 0.4200\n",
      "Epoch 743/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7089 - acc: 0.7600 - val_loss: 2.0622 - val_acc: 0.4200\n",
      "Epoch 744/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7085 - acc: 0.7529 - val_loss: 2.0498 - val_acc: 0.4167\n",
      "Epoch 745/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7084 - acc: 0.7614 - val_loss: 2.0573 - val_acc: 0.4133\n",
      "Epoch 746/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7076 - acc: 0.7586 - val_loss: 2.0583 - val_acc: 0.4167\n",
      "Epoch 747/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7078 - acc: 0.7586 - val_loss: 2.0548 - val_acc: 0.4133\n",
      "Epoch 748/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7078 - acc: 0.7600 - val_loss: 2.0598 - val_acc: 0.4133\n",
      "Epoch 749/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7073 - acc: 0.7600 - val_loss: 2.0652 - val_acc: 0.4100\n",
      "Epoch 750/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7076 - acc: 0.7629 - val_loss: 2.0687 - val_acc: 0.4100\n",
      "Epoch 751/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7076 - acc: 0.7629 - val_loss: 2.0672 - val_acc: 0.4167\n",
      "Epoch 752/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7067 - acc: 0.7600 - val_loss: 2.0608 - val_acc: 0.4133\n",
      "Epoch 753/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7069 - acc: 0.7600 - val_loss: 2.0614 - val_acc: 0.4133\n",
      "Epoch 754/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7068 - acc: 0.7600 - val_loss: 2.0644 - val_acc: 0.4167\n",
      "Epoch 755/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7067 - acc: 0.7571 - val_loss: 2.0627 - val_acc: 0.4167\n",
      "Epoch 756/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7065 - acc: 0.7571 - val_loss: 2.0588 - val_acc: 0.4133\n",
      "Epoch 757/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7068 - acc: 0.7586 - val_loss: 2.0657 - val_acc: 0.4167\n",
      "Epoch 758/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7063 - acc: 0.7600 - val_loss: 2.0514 - val_acc: 0.4133\n",
      "Epoch 759/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7059 - acc: 0.7657 - val_loss: 2.0710 - val_acc: 0.4200\n",
      "Epoch 760/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7061 - acc: 0.7629 - val_loss: 2.0699 - val_acc: 0.4133\n",
      "Epoch 761/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7055 - acc: 0.7614 - val_loss: 2.0800 - val_acc: 0.4200\n",
      "Epoch 762/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7053 - acc: 0.7643 - val_loss: 2.0817 - val_acc: 0.4267\n",
      "Epoch 763/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7051 - acc: 0.7629 - val_loss: 2.0760 - val_acc: 0.4200\n",
      "Epoch 764/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7044 - acc: 0.7614 - val_loss: 2.0666 - val_acc: 0.4233\n",
      "Epoch 765/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7049 - acc: 0.7600 - val_loss: 2.0698 - val_acc: 0.4100\n",
      "Epoch 766/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7043 - acc: 0.7643 - val_loss: 2.0655 - val_acc: 0.4100\n",
      "Epoch 767/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7041 - acc: 0.7600 - val_loss: 2.0728 - val_acc: 0.4233\n",
      "Epoch 768/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7043 - acc: 0.7629 - val_loss: 2.0821 - val_acc: 0.4200\n",
      "Epoch 769/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7043 - acc: 0.7571 - val_loss: 2.0778 - val_acc: 0.4167\n",
      "Epoch 770/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7037 - acc: 0.7657 - val_loss: 2.0759 - val_acc: 0.4100\n",
      "Epoch 771/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7034 - acc: 0.7614 - val_loss: 2.0725 - val_acc: 0.4167\n",
      "Epoch 772/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7039 - acc: 0.7643 - val_loss: 2.0886 - val_acc: 0.4133\n",
      "Epoch 773/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7034 - acc: 0.7614 - val_loss: 2.0878 - val_acc: 0.4200\n",
      "Epoch 774/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7031 - acc: 0.7614 - val_loss: 2.0823 - val_acc: 0.4167\n",
      "Epoch 775/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7032 - acc: 0.7586 - val_loss: 2.0843 - val_acc: 0.4167\n",
      "Epoch 776/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7031 - acc: 0.7657 - val_loss: 2.0804 - val_acc: 0.4200\n",
      "Epoch 777/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7023 - acc: 0.7629 - val_loss: 2.0998 - val_acc: 0.4167\n",
      "Epoch 778/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7029 - acc: 0.7614 - val_loss: 2.0882 - val_acc: 0.4167\n",
      "Epoch 779/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7025 - acc: 0.7643 - val_loss: 2.0767 - val_acc: 0.4200\n",
      "Epoch 780/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7024 - acc: 0.7629 - val_loss: 2.0938 - val_acc: 0.4167\n",
      "Epoch 781/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7022 - acc: 0.7614 - val_loss: 2.0899 - val_acc: 0.4233\n",
      "Epoch 782/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7018 - acc: 0.7657 - val_loss: 2.0909 - val_acc: 0.4200\n",
      "Epoch 783/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7017 - acc: 0.7671 - val_loss: 2.0888 - val_acc: 0.4200\n",
      "Epoch 784/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7015 - acc: 0.7571 - val_loss: 2.0913 - val_acc: 0.4133\n",
      "Epoch 785/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7018 - acc: 0.7586 - val_loss: 2.0854 - val_acc: 0.4200\n",
      "Epoch 786/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7011 - acc: 0.7671 - val_loss: 2.0812 - val_acc: 0.4133\n",
      "Epoch 787/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7011 - acc: 0.7614 - val_loss: 2.0827 - val_acc: 0.4100\n",
      "Epoch 788/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7008 - acc: 0.7686 - val_loss: 2.0932 - val_acc: 0.4100\n",
      "Epoch 789/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7008 - acc: 0.7614 - val_loss: 2.0888 - val_acc: 0.4167\n",
      "Epoch 790/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7005 - acc: 0.7643 - val_loss: 2.1029 - val_acc: 0.4233\n",
      "Epoch 791/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7002 - acc: 0.7643 - val_loss: 2.0975 - val_acc: 0.4200\n",
      "Epoch 792/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7000 - acc: 0.7643 - val_loss: 2.0997 - val_acc: 0.4167\n",
      "Epoch 793/1000\n",
      "700/700 [==============================] - 0s - loss: 0.7002 - acc: 0.7671 - val_loss: 2.0926 - val_acc: 0.4167\n",
      "Epoch 794/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6999 - acc: 0.7614 - val_loss: 2.0929 - val_acc: 0.4100\n",
      "Epoch 795/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6996 - acc: 0.7614 - val_loss: 2.0982 - val_acc: 0.4167\n",
      "Epoch 796/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6996 - acc: 0.7643 - val_loss: 2.1010 - val_acc: 0.4200\n",
      "Epoch 797/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6995 - acc: 0.7600 - val_loss: 2.0954 - val_acc: 0.4167\n",
      "Epoch 798/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6992 - acc: 0.7643 - val_loss: 2.1000 - val_acc: 0.4167\n",
      "Epoch 799/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6990 - acc: 0.7629 - val_loss: 2.1031 - val_acc: 0.4100\n",
      "Epoch 800/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6989 - acc: 0.7614 - val_loss: 2.1008 - val_acc: 0.4167\n",
      "Epoch 801/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6986 - acc: 0.7614 - val_loss: 2.1058 - val_acc: 0.4167\n",
      "Epoch 802/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6983 - acc: 0.7657 - val_loss: 2.1005 - val_acc: 0.4200\n",
      "Epoch 803/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6980 - acc: 0.7700 - val_loss: 2.1055 - val_acc: 0.4133\n",
      "Epoch 804/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6981 - acc: 0.7643 - val_loss: 2.1129 - val_acc: 0.4200\n",
      "Epoch 805/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6977 - acc: 0.7714 - val_loss: 2.1081 - val_acc: 0.4133\n",
      "Epoch 806/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6980 - acc: 0.7671 - val_loss: 2.1088 - val_acc: 0.4200\n",
      "Epoch 807/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6980 - acc: 0.7686 - val_loss: 2.1100 - val_acc: 0.4133\n",
      "Epoch 808/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6977 - acc: 0.7629 - val_loss: 2.1087 - val_acc: 0.4200\n",
      "Epoch 809/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6978 - acc: 0.7629 - val_loss: 2.1096 - val_acc: 0.4133\n",
      "Epoch 810/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6974 - acc: 0.7671 - val_loss: 2.1181 - val_acc: 0.4200\n",
      "Epoch 811/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6973 - acc: 0.7657 - val_loss: 2.1110 - val_acc: 0.4233\n",
      "Epoch 812/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6970 - acc: 0.7657 - val_loss: 2.1183 - val_acc: 0.4133\n",
      "Epoch 813/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6968 - acc: 0.7657 - val_loss: 2.1286 - val_acc: 0.4300\n",
      "Epoch 814/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6965 - acc: 0.7686 - val_loss: 2.1246 - val_acc: 0.4167\n",
      "Epoch 815/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6966 - acc: 0.7614 - val_loss: 2.1154 - val_acc: 0.4100\n",
      "Epoch 816/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6963 - acc: 0.7686 - val_loss: 2.1322 - val_acc: 0.4167\n",
      "Epoch 817/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6963 - acc: 0.7643 - val_loss: 2.1203 - val_acc: 0.4167\n",
      "Epoch 818/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6961 - acc: 0.7671 - val_loss: 2.1200 - val_acc: 0.4167\n",
      "Epoch 819/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6962 - acc: 0.7643 - val_loss: 2.1223 - val_acc: 0.4133\n",
      "Epoch 820/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6958 - acc: 0.7671 - val_loss: 2.1224 - val_acc: 0.4167\n",
      "Epoch 821/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6955 - acc: 0.7671 - val_loss: 2.1261 - val_acc: 0.4167\n",
      "Epoch 822/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6957 - acc: 0.7671 - val_loss: 2.1163 - val_acc: 0.4100\n",
      "Epoch 823/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6951 - acc: 0.7671 - val_loss: 2.1283 - val_acc: 0.4133\n",
      "Epoch 824/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6951 - acc: 0.7671 - val_loss: 2.1272 - val_acc: 0.4200\n",
      "Epoch 825/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6953 - acc: 0.7586 - val_loss: 2.1284 - val_acc: 0.4133\n",
      "Epoch 826/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6946 - acc: 0.7729 - val_loss: 2.1224 - val_acc: 0.4133\n",
      "Epoch 827/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6948 - acc: 0.7700 - val_loss: 2.1259 - val_acc: 0.4067\n",
      "Epoch 828/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6945 - acc: 0.7671 - val_loss: 2.1235 - val_acc: 0.4067\n",
      "Epoch 829/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6945 - acc: 0.7657 - val_loss: 2.1340 - val_acc: 0.4167\n",
      "Epoch 830/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6942 - acc: 0.7643 - val_loss: 2.1414 - val_acc: 0.4300\n",
      "Epoch 831/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6944 - acc: 0.7671 - val_loss: 2.1342 - val_acc: 0.4100\n",
      "Epoch 832/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6942 - acc: 0.7671 - val_loss: 2.1263 - val_acc: 0.4067\n",
      "Epoch 833/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6941 - acc: 0.7671 - val_loss: 2.1332 - val_acc: 0.4067\n",
      "Epoch 834/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6938 - acc: 0.7686 - val_loss: 2.1350 - val_acc: 0.4067\n",
      "Epoch 835/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6932 - acc: 0.7657 - val_loss: 2.1386 - val_acc: 0.4167\n",
      "Epoch 836/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6935 - acc: 0.7686 - val_loss: 2.1393 - val_acc: 0.4100\n",
      "Epoch 837/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6934 - acc: 0.7643 - val_loss: 2.1432 - val_acc: 0.4167\n",
      "Epoch 838/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6935 - acc: 0.7700 - val_loss: 2.1343 - val_acc: 0.4167\n",
      "Epoch 839/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6931 - acc: 0.7671 - val_loss: 2.1419 - val_acc: 0.4167\n",
      "Epoch 840/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6927 - acc: 0.7671 - val_loss: 2.1415 - val_acc: 0.4167\n",
      "Epoch 841/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6931 - acc: 0.7643 - val_loss: 2.1429 - val_acc: 0.4100\n",
      "Epoch 842/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6925 - acc: 0.7686 - val_loss: 2.1522 - val_acc: 0.4167\n",
      "Epoch 843/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6925 - acc: 0.7614 - val_loss: 2.1448 - val_acc: 0.4133\n",
      "Epoch 844/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6923 - acc: 0.7657 - val_loss: 2.1424 - val_acc: 0.4200\n",
      "Epoch 845/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6917 - acc: 0.7671 - val_loss: 2.1476 - val_acc: 0.4100\n",
      "Epoch 846/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6918 - acc: 0.7657 - val_loss: 2.1538 - val_acc: 0.4233\n",
      "Epoch 847/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6925 - acc: 0.7643 - val_loss: 2.1487 - val_acc: 0.4133\n",
      "Epoch 848/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6918 - acc: 0.7629 - val_loss: 2.1444 - val_acc: 0.4133\n",
      "Epoch 849/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6917 - acc: 0.7671 - val_loss: 2.1496 - val_acc: 0.4167\n",
      "Epoch 850/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6913 - acc: 0.7700 - val_loss: 2.1500 - val_acc: 0.4133\n",
      "Epoch 851/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6914 - acc: 0.7700 - val_loss: 2.1475 - val_acc: 0.4233\n",
      "Epoch 852/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6907 - acc: 0.7714 - val_loss: 2.1542 - val_acc: 0.4100\n",
      "Epoch 853/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6915 - acc: 0.7686 - val_loss: 2.1525 - val_acc: 0.4167\n",
      "Epoch 854/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6906 - acc: 0.7686 - val_loss: 2.1497 - val_acc: 0.4167\n",
      "Epoch 855/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6909 - acc: 0.7700 - val_loss: 2.1532 - val_acc: 0.4133\n",
      "Epoch 856/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6908 - acc: 0.7671 - val_loss: 2.1520 - val_acc: 0.4167\n",
      "Epoch 857/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6905 - acc: 0.7686 - val_loss: 2.1507 - val_acc: 0.4067\n",
      "Epoch 858/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6906 - acc: 0.7686 - val_loss: 2.1563 - val_acc: 0.4133\n",
      "Epoch 859/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6903 - acc: 0.7671 - val_loss: 2.1555 - val_acc: 0.4100\n",
      "Epoch 860/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6900 - acc: 0.7714 - val_loss: 2.1592 - val_acc: 0.4133\n",
      "Epoch 861/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6899 - acc: 0.7686 - val_loss: 2.1735 - val_acc: 0.4167\n",
      "Epoch 862/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6897 - acc: 0.7671 - val_loss: 2.1709 - val_acc: 0.4233\n",
      "Epoch 863/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6898 - acc: 0.7643 - val_loss: 2.1632 - val_acc: 0.4200\n",
      "Epoch 864/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6892 - acc: 0.7657 - val_loss: 2.1569 - val_acc: 0.4200\n",
      "Epoch 865/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6894 - acc: 0.7657 - val_loss: 2.1570 - val_acc: 0.4167\n",
      "Epoch 866/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6892 - acc: 0.7686 - val_loss: 2.1661 - val_acc: 0.4167\n",
      "Epoch 867/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6888 - acc: 0.7657 - val_loss: 2.1632 - val_acc: 0.4200\n",
      "Epoch 868/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6893 - acc: 0.7671 - val_loss: 2.1664 - val_acc: 0.4167\n",
      "Epoch 869/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6886 - acc: 0.7657 - val_loss: 2.1735 - val_acc: 0.4133\n",
      "Epoch 870/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6889 - acc: 0.7686 - val_loss: 2.1631 - val_acc: 0.4067\n",
      "Epoch 871/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6884 - acc: 0.7657 - val_loss: 2.1735 - val_acc: 0.4100\n",
      "Epoch 872/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6885 - acc: 0.7700 - val_loss: 2.1661 - val_acc: 0.4133\n",
      "Epoch 873/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6883 - acc: 0.7657 - val_loss: 2.1692 - val_acc: 0.4133\n",
      "Epoch 874/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6883 - acc: 0.7671 - val_loss: 2.1761 - val_acc: 0.4133\n",
      "Epoch 875/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6878 - acc: 0.7700 - val_loss: 2.1881 - val_acc: 0.4200\n",
      "Epoch 876/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6878 - acc: 0.7686 - val_loss: 2.1740 - val_acc: 0.4167\n",
      "Epoch 877/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6879 - acc: 0.7671 - val_loss: 2.1779 - val_acc: 0.4167\n",
      "Epoch 878/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6876 - acc: 0.7671 - val_loss: 2.1861 - val_acc: 0.4233\n",
      "Epoch 879/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6876 - acc: 0.7700 - val_loss: 2.1831 - val_acc: 0.4200\n",
      "Epoch 880/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6877 - acc: 0.7657 - val_loss: 2.1691 - val_acc: 0.4133\n",
      "Epoch 881/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6870 - acc: 0.7629 - val_loss: 2.1764 - val_acc: 0.4133\n",
      "Epoch 882/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6871 - acc: 0.7657 - val_loss: 2.1727 - val_acc: 0.4100\n",
      "Epoch 883/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6868 - acc: 0.7657 - val_loss: 2.1644 - val_acc: 0.4133\n",
      "Epoch 884/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6867 - acc: 0.7686 - val_loss: 2.1730 - val_acc: 0.4133\n",
      "Epoch 885/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6868 - acc: 0.7686 - val_loss: 2.1763 - val_acc: 0.4200\n",
      "Epoch 886/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6868 - acc: 0.7729 - val_loss: 2.1815 - val_acc: 0.4133\n",
      "Epoch 887/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6869 - acc: 0.7671 - val_loss: 2.1804 - val_acc: 0.4167\n",
      "Epoch 888/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6863 - acc: 0.7714 - val_loss: 2.1815 - val_acc: 0.4167\n",
      "Epoch 889/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6863 - acc: 0.7700 - val_loss: 2.1735 - val_acc: 0.4100\n",
      "Epoch 890/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6864 - acc: 0.7686 - val_loss: 2.1793 - val_acc: 0.4100\n",
      "Epoch 891/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6862 - acc: 0.7686 - val_loss: 2.1871 - val_acc: 0.4167\n",
      "Epoch 892/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6859 - acc: 0.7686 - val_loss: 2.1861 - val_acc: 0.4133\n",
      "Epoch 893/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6855 - acc: 0.7671 - val_loss: 2.1844 - val_acc: 0.4133\n",
      "Epoch 894/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6853 - acc: 0.7686 - val_loss: 2.1920 - val_acc: 0.4167\n",
      "Epoch 895/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6852 - acc: 0.7743 - val_loss: 2.1980 - val_acc: 0.4233\n",
      "Epoch 896/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6851 - acc: 0.7700 - val_loss: 2.1920 - val_acc: 0.4133\n",
      "Epoch 897/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6853 - acc: 0.7700 - val_loss: 2.1802 - val_acc: 0.4033\n",
      "Epoch 898/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6848 - acc: 0.7700 - val_loss: 2.1924 - val_acc: 0.4200\n",
      "Epoch 899/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6847 - acc: 0.7657 - val_loss: 2.1830 - val_acc: 0.4133\n",
      "Epoch 900/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6852 - acc: 0.7700 - val_loss: 2.1873 - val_acc: 0.4100\n",
      "Epoch 901/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6847 - acc: 0.7671 - val_loss: 2.1952 - val_acc: 0.4133\n",
      "Epoch 902/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6842 - acc: 0.7686 - val_loss: 2.2131 - val_acc: 0.4167\n",
      "Epoch 903/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6847 - acc: 0.7700 - val_loss: 2.1947 - val_acc: 0.4133\n",
      "Epoch 904/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6840 - acc: 0.7714 - val_loss: 2.1942 - val_acc: 0.4100\n",
      "Epoch 905/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6842 - acc: 0.7729 - val_loss: 2.2077 - val_acc: 0.4200\n",
      "Epoch 906/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6841 - acc: 0.7643 - val_loss: 2.2068 - val_acc: 0.4133\n",
      "Epoch 907/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6840 - acc: 0.7686 - val_loss: 2.1986 - val_acc: 0.4167\n",
      "Epoch 908/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6840 - acc: 0.7686 - val_loss: 2.2086 - val_acc: 0.4167\n",
      "Epoch 909/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6837 - acc: 0.7700 - val_loss: 2.1992 - val_acc: 0.4133\n",
      "Epoch 910/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6836 - acc: 0.7729 - val_loss: 2.1988 - val_acc: 0.4133\n",
      "Epoch 911/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6834 - acc: 0.7714 - val_loss: 2.1984 - val_acc: 0.4100\n",
      "Epoch 912/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6835 - acc: 0.7743 - val_loss: 2.1968 - val_acc: 0.4100\n",
      "Epoch 913/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6833 - acc: 0.7686 - val_loss: 2.2065 - val_acc: 0.4133\n",
      "Epoch 914/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6832 - acc: 0.7743 - val_loss: 2.2099 - val_acc: 0.4100\n",
      "Epoch 915/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6828 - acc: 0.7686 - val_loss: 2.2087 - val_acc: 0.4167\n",
      "Epoch 916/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6827 - acc: 0.7714 - val_loss: 2.2015 - val_acc: 0.4133\n",
      "Epoch 917/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6825 - acc: 0.7714 - val_loss: 2.2169 - val_acc: 0.4167\n",
      "Epoch 918/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6824 - acc: 0.7714 - val_loss: 2.2269 - val_acc: 0.4167\n",
      "Epoch 919/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6825 - acc: 0.7729 - val_loss: 2.2210 - val_acc: 0.4133\n",
      "Epoch 920/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6822 - acc: 0.7686 - val_loss: 2.2180 - val_acc: 0.4167\n",
      "Epoch 921/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6822 - acc: 0.7700 - val_loss: 2.2052 - val_acc: 0.4100\n",
      "Epoch 922/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6823 - acc: 0.7729 - val_loss: 2.2071 - val_acc: 0.4100\n",
      "Epoch 923/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6817 - acc: 0.7729 - val_loss: 2.2088 - val_acc: 0.4067\n",
      "Epoch 924/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6818 - acc: 0.7700 - val_loss: 2.2135 - val_acc: 0.4167\n",
      "Epoch 925/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6815 - acc: 0.7700 - val_loss: 2.2157 - val_acc: 0.4167\n",
      "Epoch 926/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6816 - acc: 0.7700 - val_loss: 2.2155 - val_acc: 0.4133\n",
      "Epoch 927/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6816 - acc: 0.7700 - val_loss: 2.2108 - val_acc: 0.4100\n",
      "Epoch 928/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6813 - acc: 0.7714 - val_loss: 2.2143 - val_acc: 0.4167\n",
      "Epoch 929/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6814 - acc: 0.7700 - val_loss: 2.2111 - val_acc: 0.4100\n",
      "Epoch 930/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6812 - acc: 0.7700 - val_loss: 2.2320 - val_acc: 0.4100\n",
      "Epoch 931/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6815 - acc: 0.7671 - val_loss: 2.2190 - val_acc: 0.4167\n",
      "Epoch 932/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6808 - acc: 0.7757 - val_loss: 2.2155 - val_acc: 0.4067\n",
      "Epoch 933/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6809 - acc: 0.7671 - val_loss: 2.2124 - val_acc: 0.4067\n",
      "Epoch 934/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6809 - acc: 0.7700 - val_loss: 2.2226 - val_acc: 0.4067\n",
      "Epoch 935/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6808 - acc: 0.7686 - val_loss: 2.2156 - val_acc: 0.4133\n",
      "Epoch 936/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6805 - acc: 0.7743 - val_loss: 2.2203 - val_acc: 0.4100\n",
      "Epoch 937/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6799 - acc: 0.7714 - val_loss: 2.2377 - val_acc: 0.4167\n",
      "Epoch 938/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6802 - acc: 0.7700 - val_loss: 2.2247 - val_acc: 0.4133\n",
      "Epoch 939/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6798 - acc: 0.7700 - val_loss: 2.2244 - val_acc: 0.4133\n",
      "Epoch 940/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6800 - acc: 0.7686 - val_loss: 2.2194 - val_acc: 0.4133\n",
      "Epoch 941/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6799 - acc: 0.7729 - val_loss: 2.2230 - val_acc: 0.4167\n",
      "Epoch 942/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6796 - acc: 0.7757 - val_loss: 2.2261 - val_acc: 0.4100\n",
      "Epoch 943/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6795 - acc: 0.7686 - val_loss: 2.2217 - val_acc: 0.4100\n",
      "Epoch 944/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6796 - acc: 0.7729 - val_loss: 2.2357 - val_acc: 0.4167\n",
      "Epoch 945/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6795 - acc: 0.7757 - val_loss: 2.2305 - val_acc: 0.4167\n",
      "Epoch 946/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6793 - acc: 0.7714 - val_loss: 2.2392 - val_acc: 0.4200\n",
      "Epoch 947/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6792 - acc: 0.7671 - val_loss: 2.2403 - val_acc: 0.4167\n",
      "Epoch 948/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6794 - acc: 0.7714 - val_loss: 2.2323 - val_acc: 0.4167\n",
      "Epoch 949/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6787 - acc: 0.7714 - val_loss: 2.2323 - val_acc: 0.4167\n",
      "Epoch 950/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6785 - acc: 0.7743 - val_loss: 2.2292 - val_acc: 0.4167\n",
      "Epoch 951/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6790 - acc: 0.7714 - val_loss: 2.2309 - val_acc: 0.4167\n",
      "Epoch 952/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6787 - acc: 0.7743 - val_loss: 2.2415 - val_acc: 0.4133\n",
      "Epoch 953/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6788 - acc: 0.7714 - val_loss: 2.2414 - val_acc: 0.4167\n",
      "Epoch 954/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6783 - acc: 0.7714 - val_loss: 2.2412 - val_acc: 0.4133\n",
      "Epoch 955/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6785 - acc: 0.7714 - val_loss: 2.2411 - val_acc: 0.4233\n",
      "Epoch 956/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6782 - acc: 0.7700 - val_loss: 2.2295 - val_acc: 0.4067\n",
      "Epoch 957/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6779 - acc: 0.7757 - val_loss: 2.2355 - val_acc: 0.4133\n",
      "Epoch 958/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6780 - acc: 0.7700 - val_loss: 2.2363 - val_acc: 0.4133\n",
      "Epoch 959/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6780 - acc: 0.7729 - val_loss: 2.2513 - val_acc: 0.4167\n",
      "Epoch 960/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6776 - acc: 0.7729 - val_loss: 2.2386 - val_acc: 0.4100\n",
      "Epoch 961/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6777 - acc: 0.7743 - val_loss: 2.2446 - val_acc: 0.4133\n",
      "Epoch 962/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6778 - acc: 0.7729 - val_loss: 2.2476 - val_acc: 0.4167\n",
      "Epoch 963/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6774 - acc: 0.7771 - val_loss: 2.2597 - val_acc: 0.4133\n",
      "Epoch 964/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6774 - acc: 0.7700 - val_loss: 2.2539 - val_acc: 0.4100\n",
      "Epoch 965/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6768 - acc: 0.7714 - val_loss: 2.2511 - val_acc: 0.4100\n",
      "Epoch 966/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6769 - acc: 0.7714 - val_loss: 2.2559 - val_acc: 0.4133\n",
      "Epoch 967/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6768 - acc: 0.7729 - val_loss: 2.2504 - val_acc: 0.4100\n",
      "Epoch 968/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6770 - acc: 0.7757 - val_loss: 2.2554 - val_acc: 0.4167\n",
      "Epoch 969/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6767 - acc: 0.7714 - val_loss: 2.2529 - val_acc: 0.4100\n",
      "Epoch 970/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6767 - acc: 0.7743 - val_loss: 2.2524 - val_acc: 0.4167\n",
      "Epoch 971/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6766 - acc: 0.7743 - val_loss: 2.2481 - val_acc: 0.4100\n",
      "Epoch 972/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6765 - acc: 0.7743 - val_loss: 2.2418 - val_acc: 0.4100\n",
      "Epoch 973/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6763 - acc: 0.7771 - val_loss: 2.2556 - val_acc: 0.4100\n",
      "Epoch 974/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6760 - acc: 0.7714 - val_loss: 2.2475 - val_acc: 0.4100\n",
      "Epoch 975/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6760 - acc: 0.7743 - val_loss: 2.2487 - val_acc: 0.4100\n",
      "Epoch 976/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6762 - acc: 0.7714 - val_loss: 2.2510 - val_acc: 0.4133\n",
      "Epoch 977/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6760 - acc: 0.7743 - val_loss: 2.2686 - val_acc: 0.4167\n",
      "Epoch 978/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6758 - acc: 0.7771 - val_loss: 2.2634 - val_acc: 0.4133\n",
      "Epoch 979/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6755 - acc: 0.7757 - val_loss: 2.2637 - val_acc: 0.4167\n",
      "Epoch 980/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6756 - acc: 0.7729 - val_loss: 2.2689 - val_acc: 0.4133\n",
      "Epoch 981/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6755 - acc: 0.7743 - val_loss: 2.2624 - val_acc: 0.4167\n",
      "Epoch 982/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6755 - acc: 0.7729 - val_loss: 2.2609 - val_acc: 0.4133\n",
      "Epoch 983/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6754 - acc: 0.7729 - val_loss: 2.2578 - val_acc: 0.4133\n",
      "Epoch 984/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6753 - acc: 0.7757 - val_loss: 2.2609 - val_acc: 0.4100\n",
      "Epoch 985/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6751 - acc: 0.7729 - val_loss: 2.2674 - val_acc: 0.4167\n",
      "Epoch 986/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6752 - acc: 0.7729 - val_loss: 2.2645 - val_acc: 0.4167\n",
      "Epoch 987/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6750 - acc: 0.7743 - val_loss: 2.2542 - val_acc: 0.4100\n",
      "Epoch 988/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6750 - acc: 0.7757 - val_loss: 2.2582 - val_acc: 0.4167\n",
      "Epoch 989/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6747 - acc: 0.7729 - val_loss: 2.2635 - val_acc: 0.4133\n",
      "Epoch 990/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6743 - acc: 0.7814 - val_loss: 2.2702 - val_acc: 0.4067\n",
      "Epoch 991/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6743 - acc: 0.7743 - val_loss: 2.2645 - val_acc: 0.4133\n",
      "Epoch 992/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6742 - acc: 0.7757 - val_loss: 2.2691 - val_acc: 0.4167\n",
      "Epoch 993/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6741 - acc: 0.7729 - val_loss: 2.2652 - val_acc: 0.4167\n",
      "Epoch 994/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6745 - acc: 0.7743 - val_loss: 2.2827 - val_acc: 0.4133\n",
      "Epoch 995/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6737 - acc: 0.7757 - val_loss: 2.2604 - val_acc: 0.4133\n",
      "Epoch 996/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6739 - acc: 0.7757 - val_loss: 2.2726 - val_acc: 0.4133\n",
      "Epoch 997/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6737 - acc: 0.7757 - val_loss: 2.2723 - val_acc: 0.4100\n",
      "Epoch 998/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6732 - acc: 0.7714 - val_loss: 2.2893 - val_acc: 0.4167\n",
      "Epoch 999/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6735 - acc: 0.7729 - val_loss: 2.2732 - val_acc: 0.4100\n",
      "Epoch 1000/1000\n",
      "700/700 [==============================] - 0s - loss: 0.6735 - acc: 0.7743 - val_loss: 2.2751 - val_acc: 0.4100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "# 1. 데이터셋 준비하기\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000, 784).astype('float32') / 255.0\n",
    "\n",
    "train_rand_idxs = np.random.choice(60000, 700)\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "test_rand_idxs = np.random.choice(10000, 300)\n",
    "X_test = X_test[test_rand_idxs]\n",
    "Y_test = Y_test[test_rand_idxs]\n",
    "\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5. 모델 학습 과정 표시하기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'g', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'g--', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'b--', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss', color='g')\n",
    "acc_ax.set_ylabel('accuray', color='b')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](http://tykimos.github.com/Keras/warehouse/2017-7-9-Early_Stopping_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val_loss를 보면 에포크 횟수가 많아질 수록 감소하다가 150 에포크 근처에서 다시 증가됨을 알 수 있습니다. 이때 과적합이 발생한 것 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/300 [==>...........................] - ETA: 0s\n",
      "loss_and_metrics : [2.2750992266337078, 0.40999999999999998]\n"
     ]
    }
   ],
   "source": [
    "# 6. 모델 사용하기\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "\n",
    "print('')\n",
    "print('loss_and_metrics : ' + str(loss_and_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 조기 종료 시키기\n",
    "\n",
    "학습 조기 종료를 위해서는 ‘EarlyStopping’이라는 함수를 사용하며 더 이상 개선의 여지가 없을 때 학습을 종료시키는 콜백함수입니다.  콜백함수라는 것 어떤 함수를 수행 시 그 함수에서 내가 지정한 함수를 호출하는 것을 말하며, 여기서는 fit 함수에서 EarlyStopping이라는 콜백함수가 학습 과정 중에 매번 호출됩니다. 먼저 fit 함수에서 EarlyStopping 콜백함수를 지정하는 방법은 다음과 같습니다.\n",
    "\n",
    "\tearly_stopping = EarlyStopping()\n",
    "\tmodel.fit(X_train, Y_train, nb_epoch= 1000, callbacks=[early_stopping])\n",
    "\n",
    "에포크가 1000으로 지정했더라도 학습 과정에서 EarlyStopping 콜백함수를 호출하여 해당 조건이 되면 학습을 조기 종료시킵니다. EarlyStopping 콜백함수에서 설정할 수 있는 인자는 다음과 같습니다.\n",
    "\n",
    "\tkeras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')\n",
    "\n",
    "* monitor : 관찰하고자 하는 항목입니다. ‘val_loss’나 ‘val_acc’가 주로 사용됩니다. \n",
    "* min_delta : 개선되고 있다고 판단하기 위한 최소 변화량을 나타냅니다. 만약 변화량이 min_delta보다 적은 경우에는 개선이 없다고 판단합니다.\n",
    "* patience : 개선이 없다고 바로 종료하지 않고 개선이 없는 에포크를 얼마나 기다려 줄 것인 가를 지정합니다. 만약 10이라고 지정하면 개선이 없는 에포크가 10번째 지속될 경우 학습일 종료합니다. \n",
    "* verbose : 얼마나 자세하게 정보를 표시할 것인가를 지정합니다. (0, 1, 2)\n",
    "* mode : 관찰 항목에 대해 개선이 없다고 판단하기 위한 기준을 지정합니다. 예를 들어 관찰 항목이 ‘val_loss’인 경우에는 감소되는 것이 멈출 때 종료되어야 하므로, ‘min’으로 설정됩니다.\n",
    "\t- auto : 관찰하는 이름에 따라 자동으로 지정합니다. \n",
    "\t- min : 관찰하고 있는 항목이 감소되는 것을 멈출 때 종료합니다.\n",
    "\t- max : 관찰하고 있는 항목이 증가되는 것을 멈출 때 종료합니다.\n",
    "    \n",
    "조기 종료 콜백함수를 적용한 코드는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "700/700 [==============================] - 0s - loss: 2.2596 - acc: 0.1514 - val_loss: 2.2248 - val_acc: 0.1567\n",
      "Epoch 2/1000\n",
      "700/700 [==============================] - 0s - loss: 2.1993 - acc: 0.1929 - val_loss: 2.1812 - val_acc: 0.1867\n",
      "Epoch 3/1000\n",
      "700/700 [==============================] - 0s - loss: 2.1578 - acc: 0.2057 - val_loss: 2.1529 - val_acc: 0.1800\n",
      "Epoch 4/1000\n",
      "700/700 [==============================] - 0s - loss: 2.1236 - acc: 0.2171 - val_loss: 2.1235 - val_acc: 0.2133\n",
      "Epoch 5/1000\n",
      "700/700 [==============================] - 0s - loss: 2.0861 - acc: 0.2457 - val_loss: 2.0852 - val_acc: 0.2300\n",
      "Epoch 6/1000\n",
      "700/700 [==============================] - 0s - loss: 2.0473 - acc: 0.2743 - val_loss: 2.0525 - val_acc: 0.2233\n",
      "Epoch 7/1000\n",
      "700/700 [==============================] - 0s - loss: 2.0114 - acc: 0.2871 - val_loss: 2.0293 - val_acc: 0.2467\n",
      "Epoch 8/1000\n",
      "700/700 [==============================] - 0s - loss: 1.9795 - acc: 0.3343 - val_loss: 2.0096 - val_acc: 0.2800\n",
      "Epoch 9/1000\n",
      "700/700 [==============================] - 0s - loss: 1.9519 - acc: 0.3371 - val_loss: 1.9779 - val_acc: 0.3200\n",
      "Epoch 10/1000\n",
      "700/700 [==============================] - 0s - loss: 1.9253 - acc: 0.3557 - val_loss: 1.9560 - val_acc: 0.3200\n",
      "Epoch 11/1000\n",
      "700/700 [==============================] - 0s - loss: 1.8994 - acc: 0.3586 - val_loss: 1.9349 - val_acc: 0.3367\n",
      "Epoch 12/1000\n",
      "700/700 [==============================] - 0s - loss: 1.8755 - acc: 0.3557 - val_loss: 1.9155 - val_acc: 0.3467\n",
      "Epoch 13/1000\n",
      "700/700 [==============================] - 0s - loss: 1.8526 - acc: 0.3671 - val_loss: 1.8927 - val_acc: 0.3667\n",
      "Epoch 14/1000\n",
      "700/700 [==============================] - 0s - loss: 1.8319 - acc: 0.3771 - val_loss: 1.8794 - val_acc: 0.3733\n",
      "Epoch 15/1000\n",
      "700/700 [==============================] - 0s - loss: 1.8107 - acc: 0.3786 - val_loss: 1.8686 - val_acc: 0.3733\n",
      "Epoch 16/1000\n",
      "700/700 [==============================] - 0s - loss: 1.7911 - acc: 0.3914 - val_loss: 1.8523 - val_acc: 0.3800\n",
      "Epoch 17/1000\n",
      "700/700 [==============================] - 0s - loss: 1.7729 - acc: 0.3986 - val_loss: 1.8427 - val_acc: 0.3800\n",
      "Epoch 18/1000\n",
      "700/700 [==============================] - 0s - loss: 1.7549 - acc: 0.4071 - val_loss: 1.8249 - val_acc: 0.3933\n",
      "Epoch 19/1000\n",
      "700/700 [==============================] - 0s - loss: 1.7391 - acc: 0.4086 - val_loss: 1.8164 - val_acc: 0.4000\n",
      "Epoch 20/1000\n",
      "700/700 [==============================] - 0s - loss: 1.7221 - acc: 0.4186 - val_loss: 1.8102 - val_acc: 0.3967\n",
      "Epoch 21/1000\n",
      "700/700 [==============================] - 0s - loss: 1.7067 - acc: 0.4257 - val_loss: 1.8023 - val_acc: 0.4000\n",
      "Epoch 22/1000\n",
      "700/700 [==============================] - 0s - loss: 1.6917 - acc: 0.4371 - val_loss: 1.7889 - val_acc: 0.3933\n",
      "Epoch 23/1000\n",
      "700/700 [==============================] - 0s - loss: 1.6768 - acc: 0.4429 - val_loss: 1.7758 - val_acc: 0.4133\n",
      "Epoch 24/1000\n",
      "700/700 [==============================] - 0s - loss: 1.6617 - acc: 0.4414 - val_loss: 1.7639 - val_acc: 0.4233\n",
      "Epoch 25/1000\n",
      "700/700 [==============================] - 0s - loss: 1.6492 - acc: 0.4457 - val_loss: 1.7555 - val_acc: 0.4233\n",
      "Epoch 26/1000\n",
      "700/700 [==============================] - 0s - loss: 1.6348 - acc: 0.4457 - val_loss: 1.7605 - val_acc: 0.4067\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAEKCAYAAAChTwphAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1109cd5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "# 1. 데이터셋 준비하기\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000, 784).astype('float32') / 255.0\n",
    "\n",
    "train_rand_idxs = np.random.choice(60000, 700)\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "test_rand_idxs = np.random.choice(10000, 300)\n",
    "X_test = X_test[test_rand_idxs]\n",
    "Y_test = Y_test[test_rand_idxs]\n",
    "\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "early_stopping = EarlyStopping() # 조기종료 콜백함수 정의\n",
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_test, Y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 5. 모델 학습 과정 표시하기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'g', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'g--', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'b--', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss', color='g')\n",
    "acc_ax.set_ylabel('accuray', color='b')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](http://tykimos.github.com/Keras/warehouse/2017-7-9-Early_Stopping_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/300 [==>...........................] - ETA: 0s\n",
      "loss_and_metrics : [1.760471485455831, 0.40666666666666668]\n"
     ]
    }
   ],
   "source": [
    "# 6. 모델 사용하기\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "\n",
    "print('')\n",
    "print('loss_and_metrics : ' + str(loss_and_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val_loss 값이 감소되다가 증가되자마자 학습이 종료되었습니다. 하지만 이 모델은 좀 더 학습이 될 수 있는 모델임을 이미 알고 있습니다. val_loss 특성 상 증가/감소를 반복하므로 val_loss가 증가되는 시점에 바로 종료하지말고 지속적으로 증가되는 시점에서 종료해보겠습니다. 이를 위해 EarlyStopping 콜백함수에서 patience 인자를 사용합니다.\n",
    "\n",
    "    early_stopping = EarlyStopping(patience = 20)\n",
    "    \n",
    "즉 증가가 되었더라도 20 에포크 동안은 기다려보도록 지정했습니다. 이를 적용한 코드는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "700/700 [==============================] - 0s - loss: 2.2596 - acc: 0.1514 - val_loss: 2.2248 - val_acc: 0.1567\n",
      "Epoch 2/1000\n",
      "700/700 [==============================] - 0s - loss: 2.1993 - acc: 0.1929 - val_loss: 2.1812 - val_acc: 0.1867\n",
      "Epoch 3/1000\n",
      "700/700 [==============================] - 0s - loss: 2.1578 - acc: 0.2057 - val_loss: 2.1529 - val_acc: 0.1800\n",
      "Epoch 4/1000\n",
      "700/700 [==============================] - 0s - loss: 2.1236 - acc: 0.2171 - val_loss: 2.1235 - val_acc: 0.2133\n",
      "Epoch 5/1000\n",
      "700/700 [==============================] - 0s - loss: 2.0861 - acc: 0.2457 - val_loss: 2.0852 - val_acc: 0.2300\n",
      "Epoch 6/1000\n",
      "700/700 [==============================] - 0s - loss: 2.0473 - acc: 0.2743 - val_loss: 2.0525 - val_acc: 0.2233\n",
      "Epoch 7/1000\n",
      "700/700 [==============================] - 0s - loss: 2.0114 - acc: 0.2871 - val_loss: 2.0293 - val_acc: 0.2467\n",
      "Epoch 8/1000\n",
      "700/700 [==============================] - 0s - loss: 1.9795 - acc: 0.3343 - val_loss: 2.0096 - val_acc: 0.2800\n",
      "Epoch 9/1000\n",
      "700/700 [==============================] - 0s - loss: 1.9519 - acc: 0.3371 - val_loss: 1.9779 - val_acc: 0.3200\n",
      "Epoch 10/1000\n",
      "700/700 [==============================] - 0s - loss: 1.9253 - acc: 0.3557 - val_loss: 1.9560 - val_acc: 0.3200\n",
      "Epoch 11/1000\n",
      "700/700 [==============================] - 0s - loss: 1.8994 - acc: 0.3586 - val_loss: 1.9349 - val_acc: 0.3367\n",
      "Epoch 12/1000\n",
      "700/700 [==============================] - 0s - loss: 1.8755 - acc: 0.3557 - val_loss: 1.9155 - val_acc: 0.3467\n",
      "Epoch 13/1000\n",
      "700/700 [==============================] - 0s - loss: 1.8526 - acc: 0.3671 - val_loss: 1.8927 - val_acc: 0.3667\n",
      "Epoch 14/1000\n",
      "700/700 [==============================] - 0s - loss: 1.8319 - acc: 0.3771 - val_loss: 1.8794 - val_acc: 0.3733\n",
      "Epoch 15/1000\n",
      "700/700 [==============================] - 0s - loss: 1.8107 - acc: 0.3786 - val_loss: 1.8686 - val_acc: 0.3733\n",
      "Epoch 16/1000\n",
      "700/700 [==============================] - 0s - loss: 1.7911 - acc: 0.3914 - val_loss: 1.8523 - val_acc: 0.3800\n",
      "Epoch 17/1000\n",
      "700/700 [==============================] - 0s - loss: 1.7729 - acc: 0.3986 - val_loss: 1.8427 - val_acc: 0.3800\n",
      "Epoch 18/1000\n",
      "700/700 [==============================] - 0s - loss: 1.7549 - acc: 0.4071 - val_loss: 1.8249 - val_acc: 0.3933\n",
      "Epoch 19/1000\n",
      "700/700 [==============================] - 0s - loss: 1.7391 - acc: 0.4086 - val_loss: 1.8164 - val_acc: 0.4000\n",
      "Epoch 20/1000\n",
      "700/700 [==============================] - 0s - loss: 1.7221 - acc: 0.4186 - val_loss: 1.8102 - val_acc: 0.3967\n",
      "Epoch 21/1000\n",
      "700/700 [==============================] - 0s - loss: 1.7067 - acc: 0.4257 - val_loss: 1.8023 - val_acc: 0.4000\n",
      "Epoch 22/1000\n",
      "700/700 [==============================] - 0s - loss: 1.6917 - acc: 0.4371 - val_loss: 1.7889 - val_acc: 0.3933\n",
      "Epoch 23/1000\n",
      "700/700 [==============================] - 0s - loss: 1.6768 - acc: 0.4429 - val_loss: 1.7758 - val_acc: 0.4133\n",
      "Epoch 24/1000\n",
      "700/700 [==============================] - 0s - loss: 1.6617 - acc: 0.4414 - val_loss: 1.7639 - val_acc: 0.4233\n",
      "Epoch 25/1000\n",
      "700/700 [==============================] - 0s - loss: 1.6492 - acc: 0.4457 - val_loss: 1.7555 - val_acc: 0.4233\n",
      "Epoch 26/1000\n",
      "700/700 [==============================] - 0s - loss: 1.6348 - acc: 0.4457 - val_loss: 1.7605 - val_acc: 0.4067\n",
      "Epoch 27/1000\n",
      "700/700 [==============================] - 0s - loss: 1.6222 - acc: 0.4557 - val_loss: 1.7478 - val_acc: 0.4000\n",
      "Epoch 28/1000\n",
      "700/700 [==============================] - 0s - loss: 1.6106 - acc: 0.4529 - val_loss: 1.7313 - val_acc: 0.4200\n",
      "Epoch 29/1000\n",
      "700/700 [==============================] - 0s - loss: 1.5984 - acc: 0.4557 - val_loss: 1.7293 - val_acc: 0.4200\n",
      "Epoch 30/1000\n",
      "700/700 [==============================] - 0s - loss: 1.5871 - acc: 0.4600 - val_loss: 1.7165 - val_acc: 0.4200\n",
      "Epoch 31/1000\n",
      "700/700 [==============================] - 0s - loss: 1.5751 - acc: 0.4643 - val_loss: 1.7104 - val_acc: 0.4267\n",
      "Epoch 32/1000\n",
      "700/700 [==============================] - 0s - loss: 1.5648 - acc: 0.4600 - val_loss: 1.7061 - val_acc: 0.4267\n",
      "Epoch 33/1000\n",
      "700/700 [==============================] - 0s - loss: 1.5515 - acc: 0.4671 - val_loss: 1.6971 - val_acc: 0.4267\n",
      "Epoch 34/1000\n",
      "700/700 [==============================] - 0s - loss: 1.5415 - acc: 0.4614 - val_loss: 1.6860 - val_acc: 0.4300\n",
      "Epoch 35/1000\n",
      "700/700 [==============================] - 0s - loss: 1.5323 - acc: 0.4714 - val_loss: 1.6765 - val_acc: 0.4267\n",
      "Epoch 36/1000\n",
      "700/700 [==============================] - 0s - loss: 1.5223 - acc: 0.4771 - val_loss: 1.6798 - val_acc: 0.4100\n",
      "Epoch 37/1000\n",
      "700/700 [==============================] - 0s - loss: 1.5122 - acc: 0.4814 - val_loss: 1.6711 - val_acc: 0.4300\n",
      "Epoch 38/1000\n",
      "700/700 [==============================] - 0s - loss: 1.5027 - acc: 0.4857 - val_loss: 1.6705 - val_acc: 0.4267\n",
      "Epoch 39/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4933 - acc: 0.4900 - val_loss: 1.6573 - val_acc: 0.4333\n",
      "Epoch 40/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4835 - acc: 0.4900 - val_loss: 1.6454 - val_acc: 0.4333\n",
      "Epoch 41/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4740 - acc: 0.4971 - val_loss: 1.6519 - val_acc: 0.4300\n",
      "Epoch 42/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4663 - acc: 0.4900 - val_loss: 1.6358 - val_acc: 0.4367\n",
      "Epoch 43/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4569 - acc: 0.4914 - val_loss: 1.6280 - val_acc: 0.4367\n",
      "Epoch 44/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4493 - acc: 0.4857 - val_loss: 1.6267 - val_acc: 0.4367\n",
      "Epoch 45/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4405 - acc: 0.5014 - val_loss: 1.6185 - val_acc: 0.4367\n",
      "Epoch 46/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4329 - acc: 0.4900 - val_loss: 1.6151 - val_acc: 0.4367\n",
      "Epoch 47/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4249 - acc: 0.4986 - val_loss: 1.6087 - val_acc: 0.4367\n",
      "Epoch 48/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4168 - acc: 0.4929 - val_loss: 1.6113 - val_acc: 0.4400\n",
      "Epoch 49/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4099 - acc: 0.5043 - val_loss: 1.6047 - val_acc: 0.4367\n",
      "Epoch 50/1000\n",
      "700/700 [==============================] - 0s - loss: 1.4024 - acc: 0.5043 - val_loss: 1.5940 - val_acc: 0.4300\n",
      "Epoch 51/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3951 - acc: 0.5014 - val_loss: 1.6025 - val_acc: 0.4433\n",
      "Epoch 52/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3886 - acc: 0.5000 - val_loss: 1.5917 - val_acc: 0.4400\n",
      "Epoch 53/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3822 - acc: 0.5057 - val_loss: 1.5847 - val_acc: 0.4333\n",
      "Epoch 54/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3762 - acc: 0.4971 - val_loss: 1.5790 - val_acc: 0.4333\n",
      "Epoch 55/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3683 - acc: 0.4957 - val_loss: 1.5748 - val_acc: 0.4267\n",
      "Epoch 56/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3631 - acc: 0.5014 - val_loss: 1.5716 - val_acc: 0.4233\n",
      "Epoch 57/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3566 - acc: 0.5029 - val_loss: 1.5682 - val_acc: 0.4367\n",
      "Epoch 58/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3498 - acc: 0.5000 - val_loss: 1.5624 - val_acc: 0.4367\n",
      "Epoch 59/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3449 - acc: 0.5086 - val_loss: 1.5622 - val_acc: 0.4400\n",
      "Epoch 60/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3385 - acc: 0.5086 - val_loss: 1.5555 - val_acc: 0.4433\n",
      "Epoch 61/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3310 - acc: 0.5057 - val_loss: 1.5426 - val_acc: 0.4333\n",
      "Epoch 62/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3277 - acc: 0.5014 - val_loss: 1.5538 - val_acc: 0.4333\n",
      "Epoch 63/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3213 - acc: 0.5100 - val_loss: 1.5458 - val_acc: 0.4467\n",
      "Epoch 64/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3153 - acc: 0.5143 - val_loss: 1.5539 - val_acc: 0.4500\n",
      "Epoch 65/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3107 - acc: 0.5129 - val_loss: 1.5456 - val_acc: 0.4467\n",
      "Epoch 66/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3054 - acc: 0.5143 - val_loss: 1.5418 - val_acc: 0.4533\n",
      "Epoch 67/1000\n",
      "700/700 [==============================] - 0s - loss: 1.3005 - acc: 0.5143 - val_loss: 1.5376 - val_acc: 0.4500\n",
      "Epoch 68/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2959 - acc: 0.5114 - val_loss: 1.5349 - val_acc: 0.4533\n",
      "Epoch 69/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2891 - acc: 0.5171 - val_loss: 1.5254 - val_acc: 0.4333\n",
      "Epoch 70/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2850 - acc: 0.5086 - val_loss: 1.5445 - val_acc: 0.4567\n",
      "Epoch 71/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2815 - acc: 0.5200 - val_loss: 1.5234 - val_acc: 0.4467\n",
      "Epoch 72/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2774 - acc: 0.5200 - val_loss: 1.5236 - val_acc: 0.4467\n",
      "Epoch 73/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2723 - acc: 0.5086 - val_loss: 1.5199 - val_acc: 0.4467\n",
      "Epoch 74/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2675 - acc: 0.5071 - val_loss: 1.5196 - val_acc: 0.4433\n",
      "Epoch 75/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2650 - acc: 0.5171 - val_loss: 1.5097 - val_acc: 0.4333\n",
      "Epoch 76/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2604 - acc: 0.5171 - val_loss: 1.5128 - val_acc: 0.4467\n",
      "Epoch 77/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2557 - acc: 0.5171 - val_loss: 1.5107 - val_acc: 0.4400\n",
      "Epoch 78/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2527 - acc: 0.5257 - val_loss: 1.5119 - val_acc: 0.4433\n",
      "Epoch 79/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2493 - acc: 0.5171 - val_loss: 1.5076 - val_acc: 0.4367\n",
      "Epoch 80/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2445 - acc: 0.5257 - val_loss: 1.5100 - val_acc: 0.4500\n",
      "Epoch 81/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2419 - acc: 0.5157 - val_loss: 1.4973 - val_acc: 0.4467\n",
      "Epoch 82/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2391 - acc: 0.5300 - val_loss: 1.5017 - val_acc: 0.4467\n",
      "Epoch 83/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2359 - acc: 0.5257 - val_loss: 1.5034 - val_acc: 0.4400\n",
      "Epoch 84/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2327 - acc: 0.5300 - val_loss: 1.5079 - val_acc: 0.4467\n",
      "Epoch 85/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2295 - acc: 0.5229 - val_loss: 1.5011 - val_acc: 0.4333\n",
      "Epoch 86/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2250 - acc: 0.5214 - val_loss: 1.4915 - val_acc: 0.4467\n",
      "Epoch 87/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2233 - acc: 0.5257 - val_loss: 1.4934 - val_acc: 0.4467\n",
      "Epoch 88/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2206 - acc: 0.5400 - val_loss: 1.4922 - val_acc: 0.4500\n",
      "Epoch 89/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2176 - acc: 0.5314 - val_loss: 1.4944 - val_acc: 0.4367\n",
      "Epoch 90/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2148 - acc: 0.5286 - val_loss: 1.4898 - val_acc: 0.4433\n",
      "Epoch 91/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2121 - acc: 0.5400 - val_loss: 1.4920 - val_acc: 0.4600\n",
      "Epoch 92/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2090 - acc: 0.5386 - val_loss: 1.5000 - val_acc: 0.4500\n",
      "Epoch 93/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2066 - acc: 0.5386 - val_loss: 1.4868 - val_acc: 0.4500\n",
      "Epoch 94/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2036 - acc: 0.5329 - val_loss: 1.4964 - val_acc: 0.4567\n",
      "Epoch 95/1000\n",
      "700/700 [==============================] - 0s - loss: 1.2009 - acc: 0.5357 - val_loss: 1.4930 - val_acc: 0.4533\n",
      "Epoch 96/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1983 - acc: 0.5343 - val_loss: 1.4991 - val_acc: 0.4533\n",
      "Epoch 97/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1950 - acc: 0.5414 - val_loss: 1.4836 - val_acc: 0.4433\n",
      "Epoch 98/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1937 - acc: 0.5443 - val_loss: 1.4915 - val_acc: 0.4633\n",
      "Epoch 99/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1910 - acc: 0.5471 - val_loss: 1.4792 - val_acc: 0.4433\n",
      "Epoch 100/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1878 - acc: 0.5486 - val_loss: 1.4863 - val_acc: 0.4500\n",
      "Epoch 101/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1858 - acc: 0.5371 - val_loss: 1.4983 - val_acc: 0.4467\n",
      "Epoch 102/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1831 - acc: 0.5429 - val_loss: 1.4886 - val_acc: 0.4533\n",
      "Epoch 103/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1804 - acc: 0.5400 - val_loss: 1.4789 - val_acc: 0.4367\n",
      "Epoch 104/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1779 - acc: 0.5500 - val_loss: 1.4819 - val_acc: 0.4400\n",
      "Epoch 105/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1757 - acc: 0.5471 - val_loss: 1.4907 - val_acc: 0.4500\n",
      "Epoch 106/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1743 - acc: 0.5457 - val_loss: 1.4816 - val_acc: 0.4500\n",
      "Epoch 107/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1717 - acc: 0.5500 - val_loss: 1.4831 - val_acc: 0.4533\n",
      "Epoch 108/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1679 - acc: 0.5629 - val_loss: 1.4881 - val_acc: 0.4400\n",
      "Epoch 109/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1685 - acc: 0.5514 - val_loss: 1.4846 - val_acc: 0.4467\n",
      "Epoch 110/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1658 - acc: 0.5457 - val_loss: 1.4827 - val_acc: 0.4533\n",
      "Epoch 111/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1629 - acc: 0.5486 - val_loss: 1.4896 - val_acc: 0.4567\n",
      "Epoch 112/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1624 - acc: 0.5443 - val_loss: 1.4880 - val_acc: 0.4567\n",
      "Epoch 113/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1593 - acc: 0.5471 - val_loss: 1.4861 - val_acc: 0.4533\n",
      "Epoch 114/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1566 - acc: 0.5443 - val_loss: 1.4935 - val_acc: 0.4533\n",
      "Epoch 115/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1550 - acc: 0.5414 - val_loss: 1.4865 - val_acc: 0.4567\n",
      "Epoch 116/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1527 - acc: 0.5543 - val_loss: 1.4792 - val_acc: 0.4467\n",
      "Epoch 117/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1502 - acc: 0.5514 - val_loss: 1.4934 - val_acc: 0.4433\n",
      "Epoch 118/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1472 - acc: 0.5571 - val_loss: 1.5036 - val_acc: 0.4600\n",
      "Epoch 119/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1448 - acc: 0.5457 - val_loss: 1.5046 - val_acc: 0.4600\n",
      "Epoch 120/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1450 - acc: 0.5514 - val_loss: 1.4987 - val_acc: 0.4600\n",
      "Epoch 121/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1405 - acc: 0.5500 - val_loss: 1.4758 - val_acc: 0.4433\n",
      "Epoch 122/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1389 - acc: 0.5457 - val_loss: 1.4775 - val_acc: 0.4467\n",
      "Epoch 123/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1363 - acc: 0.5486 - val_loss: 1.4887 - val_acc: 0.4567\n",
      "Epoch 124/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1341 - acc: 0.5614 - val_loss: 1.4935 - val_acc: 0.4633\n",
      "Epoch 125/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1319 - acc: 0.5529 - val_loss: 1.4844 - val_acc: 0.4567\n",
      "Epoch 126/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1289 - acc: 0.5471 - val_loss: 1.4810 - val_acc: 0.4633\n",
      "Epoch 127/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1269 - acc: 0.5586 - val_loss: 1.4845 - val_acc: 0.4567\n",
      "Epoch 128/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1240 - acc: 0.5629 - val_loss: 1.4898 - val_acc: 0.4500\n",
      "Epoch 129/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1219 - acc: 0.5643 - val_loss: 1.4757 - val_acc: 0.4567\n",
      "Epoch 130/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1194 - acc: 0.5614 - val_loss: 1.4791 - val_acc: 0.4467\n",
      "Epoch 131/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1174 - acc: 0.5643 - val_loss: 1.4831 - val_acc: 0.4567\n",
      "Epoch 132/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1156 - acc: 0.5614 - val_loss: 1.4807 - val_acc: 0.4567\n",
      "Epoch 133/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1121 - acc: 0.5743 - val_loss: 1.4857 - val_acc: 0.4567\n",
      "Epoch 134/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1107 - acc: 0.5729 - val_loss: 1.4862 - val_acc: 0.4567\n",
      "Epoch 135/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1083 - acc: 0.5686 - val_loss: 1.4800 - val_acc: 0.4567\n",
      "Epoch 136/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1064 - acc: 0.5714 - val_loss: 1.4878 - val_acc: 0.4533\n",
      "Epoch 137/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1035 - acc: 0.5643 - val_loss: 1.4841 - val_acc: 0.4600\n",
      "Epoch 138/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1016 - acc: 0.5671 - val_loss: 1.4796 - val_acc: 0.4567\n",
      "Epoch 139/1000\n",
      "700/700 [==============================] - 0s - loss: 1.1002 - acc: 0.5757 - val_loss: 1.4804 - val_acc: 0.4500\n",
      "Epoch 140/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0981 - acc: 0.5686 - val_loss: 1.4808 - val_acc: 0.4567\n",
      "Epoch 141/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0961 - acc: 0.5771 - val_loss: 1.4845 - val_acc: 0.4500\n",
      "Epoch 142/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0925 - acc: 0.5843 - val_loss: 1.4955 - val_acc: 0.4567\n",
      "Epoch 143/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0933 - acc: 0.5686 - val_loss: 1.4838 - val_acc: 0.4467\n",
      "Epoch 144/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0904 - acc: 0.5786 - val_loss: 1.4780 - val_acc: 0.4500\n",
      "Epoch 145/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0884 - acc: 0.5800 - val_loss: 1.4840 - val_acc: 0.4433\n",
      "Epoch 146/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0858 - acc: 0.5857 - val_loss: 1.4855 - val_acc: 0.4467\n",
      "Epoch 147/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0839 - acc: 0.5743 - val_loss: 1.4848 - val_acc: 0.4467\n",
      "Epoch 148/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0836 - acc: 0.5786 - val_loss: 1.4843 - val_acc: 0.4533\n",
      "Epoch 149/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0805 - acc: 0.5857 - val_loss: 1.4863 - val_acc: 0.4567\n",
      "Epoch 150/1000\n",
      "700/700 [==============================] - 0s - loss: 1.0794 - acc: 0.5771 - val_loss: 1.4880 - val_acc: 0.4533\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEKCAYAAAC2bZqoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyUkppZTL+V/0hYQdDv35fAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1117ceb10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "# 1. 데이터셋 준비하기\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000, 784).astype('float32') / 255.0\n",
    "\n",
    "train_rand_idxs = np.random.choice(60000, 700)\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "test_rand_idxs = np.random.choice(10000, 300)\n",
    "X_test = X_test[test_rand_idxs]\n",
    "Y_test = Y_test[test_rand_idxs]\n",
    "\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "early_stopping = EarlyStopping(patience = 20) # 조기종료 콜백함수 정의\n",
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_test, Y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5. 모델 학습 과정 표시하기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'g', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'g--', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'b--', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss', color='g')\n",
    "acc_ax.set_ylabel('accuray', color='b')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](http://tykimos.github.com/Keras/warehouse/2017-7-9-Early_Stopping_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/300 [==>...........................] - ETA: 0s\n",
      "loss_and_metrics : [1.4880069160461427, 0.45333333293596906]\n"
     ]
    }
   ],
   "source": [
    "# 6. 모델 사용하기\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "\n",
    "print('')\n",
    "print('loss_and_metrics : ' + str(loss_and_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 정확도도 향상됨을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 결론\n",
    "\n",
    "본 절에서는 과적합되는 모델을 만들어보고, 조기종료 시키는 방법에 대해서 알아보았습니다. 케라스에서는 EarlyStopping이라는 콜백함수로 간단하게 적용해볼 수 있습니다.\n",
    "\n",
    "![img](http://tykimos.github.com/Keras/warehouse/2017-7-9-Early_Stopping_4.png)\n",
    "\n",
    "추가 작성.. 중간 중간 모델 값을 저장한 후 선택하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "### 같이 보기\n",
    "\n",
    "* [강좌 목차](https://tykimos.github.io/Keras/lecture/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
