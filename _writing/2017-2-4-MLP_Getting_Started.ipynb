{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title:  \"다층 퍼셉트론 모델 만들어보기\"\n",
    "author: Taeyoung, Kim\n",
    "date:   2017-02-04 01:00:00\n",
    "categories: Lecture\n",
    "comments: true\n",
    "image: http://tykimos.github.com/Keras/warehouse/2017-2-4_MLP_Getting_Started_lego.png\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본 강좌에서는 케라스를 이용하여 간단한 다층 퍼셉트론 모델을 만들어보겠습니다. 다음과 같은 순서로 진행하겠습니다.\n",
    "\n",
    "1. 문제 정의하기\n",
    "1. 데이터셋 준비하기\n",
    "1. 데이터셋 불러오기\n",
    "1. 모델 구성하기\n",
    "1. 모델 엮기\n",
    "1. 모델 학습시키기\n",
    "1. 모델 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 문제 정의하기\n",
    "\n",
    "다층 퍼셉트론 모델은 가장 기본적인 모델이라 대부분 문제에 적용할 수 있습니다. 본 예제에서는 비교적 쉬운 이진 분류 문제를 적용해보고자 합니다. 이진 분류 예제에 적합한 데이터셋은 8개 변수와 당뇨병 발병 유무가 기록된 '피마족 인디언 당뇨병 발병 데이터셋'이 있습니다. 이 데이터셋을 이용하여 8개 변수를 독립변수로 보고 당뇨병 발병 유무를 예측하는 이진 분류 문제로 정의해보겠습니다. \n",
    "\n",
    "데이터셋은 아래 링크에서 다운로드 받으실 수 있습니다.\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes\n",
    "\n",
    "'피마족 인디언 당뇨병 발병 데이터셋'을 선정한 이유는 다음과 같습니다. \n",
    "- 인스턴스 수와 속성 수가 예제로 사용하기에 적당합니다.\n",
    "- 모든 특징이 정수 혹은 실수로 되어 있어서 별도의 전처리 과정이 필요없습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋을 준비하기에 앞서, 매번 실행 시마다 결과가 달라지지 않도록 랜덤 시드를 명시적으로 지정합니다. 이것을 하지 않으면 매번 실행 시 마다 동일 모델인데도 불구하고 다른 결과가 나오기 때문에, 연구개발 단계에서 파라미터 조정이나 데이터셋에 따른 결과 차이를 보려면 랜덤 시드를 지정해주는 것이 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 랜덤시드 고정시키기\n",
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 데이터셋 준비하기\n",
    "\n",
    "위 링크에서 'pima-indians-diabetes.names'을 열어보면 데이터셋에 대한 설명이 포함되어 있습니다. 먼저 몇가지 주요 항목을 살펴보겠습니다.\n",
    "\n",
    "- 인스턴스 수 : 768개\n",
    "- 속성 수 : 8가지\n",
    "- 클래스 수 : 2가지\n",
    "\n",
    "8가지 속성(1번~8번)과 결과(9번)의 상세 내용은 다음과 같습니다. \n",
    "\n",
    "1. 임신 횟수\n",
    "2. 경구 포도당 내성 검사에서 2시간 동안의 혈장 포도당 농도\n",
    "3. 이완기 혈압 (mm Hg)\n",
    "4. 삼두근 피부 두겹 두께 (mm)\n",
    "5. 2 시간 혈청 인슐린 (mu U/ml)\n",
    "6. 체질량 지수\n",
    "7. 당뇨 직계 가족력\n",
    "8. 나이 (세)\n",
    "9. 5년 이내 당뇨병이 발병 여부\n",
    "\n",
    "좀 더 살펴보면, 양성인 경우가 268개(34.9%), 음성인 경우가 500개(65.1%)입니다. 즉 모델이 모두 음성이라고 판별을 한다하더라도 65.1%의 기본 정확도(baseline accuracy)를 달성할 수 있습니다. 즉 우리의 모델이 65.1%보다 낮으면 모두 음성이라고 판별하는 것보다 낮은 정확도를 가진다고 생각하시면 됩니다. 지금까지 개발된 알고리즘의 최대 정확도는 10-fold 교차검증(cross validataion) 했을 때 77.7%이라고 웹사이트에는 표기되어 있습니다.\n",
    "\n",
    "'pima-indians-diabetes.data'이 실제 데이터 파일입니다. 열어보면 CSV 형태로 되었습니다. CSV는 값들이 쉼표로 분리된 텍스트파일이며 메모장이나 엑셀에서 쉽게 확인할 수 있습니다.\n",
    "\n",
    "    6,148,72,35,0,33.6,0.627,50,1\n",
    "    1,85,66,29,0,26.6,0.351,31,0\n",
    "    8,183,64,0,0,23.3,0.672,32,1\n",
    "    1,89,66,23,94,28.1,0.167,21,0\n",
    "    0,137,40,35,168,43.1,2.288,33,1    \n",
    "\n",
    "속성별 간단한 통계 정보는 다음과 같습니다.\n",
    "\n",
    "|No.|속성|평균|표준편차|\n",
    "|-|-|-|-|\n",
    "|1|임신 횟수|3.8|3.4|\n",
    "|2|포도당 내성|120.9|32.0|\n",
    "|3|이완기 혈압|69.1|19.4|\n",
    "|4|삼두근 피부 두겹 두께|20.5|16.0|\n",
    "|5|혈청 인슐린|79.8|115.2|\n",
    "|6|체질량 지수|32.0|7.9|\n",
    "|7|당뇨 직계 가족력|0.5|0.3|\n",
    "|8|나이|33.2|11.8|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 데이터셋 불러오기\n",
    "\n",
    "csv 형식의 파일은 numpy 패키지에서 제공하는 loadtxt() 함수로 직접 불러올 수 있습니다. 데이터셋에는 속성값과 판정결과가 모두 포함되어 있기 때문에 입력(X, 속성값 8개)와 출력(Y, 판정결과 1개) 변수로 분리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 데이터셋 불러오기\n",
    "dataset = np.loadtxt(\"./warehouse/pima-indians-diabetes.data\", delimiter=\",\")\n",
    "\n",
    "# 입력(X)과 출력(Y) 변수로 분리하기\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 모델 구성하기\n",
    "\n",
    "앞 강좌에서 배운 Dense 레이어만을 사용하여 다층 퍼셉트론 모델을 구성할 수 있습니다. 속성이 8개이기 때문에 입력 뉴런을 8개이고, 이진 분류이기 때문에 0~1사이의 값을 나타내는 출력 뉴런이 1개입니다.\n",
    "\n",
    "- 첫번째 Dense 레이어는 은닉층(hidden layer)으로 8개 뉴런을 입력받아 12개 뉴런을 출력합니다.\n",
    "- 두번째 Dense 레이어는 은닉층으로 12개 뉴런을 입력받아 8개 뉴런을 출력합니다.\n",
    "- 마지막 Dense 레이어는 출럭 레이어로 8개 뉴런을 입력받아 1개 뉴런을 출력합니다.\n",
    "\n",
    "이 것을 앞 강좌에서 표현했던 것 처럼 레고 블럭으로 쌓아봤습니다. 총 세 개의 Dense 레이어 블럭으로 모델을 구성한 다음, 8개의 속성 값을 입력하면 1개의 출력값을 얻을 수 있는 구성입니다.\n",
    "\n",
    "![lego](http://tykimos.github.com/Keras/warehouse/2017-2-4_MLP_Getting_Started_lego.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "은닉 레이어의 활성화 함수는 모두 'relu'를 사용하였고, 출력 레이어만 0과 1사이로 값이 출력될 수 있도록 활성화 함수를 'sigmoid'로 사용하였습니다. 0과 1사이의 실수값이 나오기 때문에 양성 클래스의 확률로 쉽게 매칭할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"296pt\" viewBox=\"0.00 0.00 300.56 296.00\" width=\"301pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 292)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-292 296.5557,-292 296.5557,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 4469686928 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>4469686928</title>\n",
       "<polygon fill=\"none\" points=\"0,-243.5 0,-287.5 292.5557,-287.5 292.5557,-243.5 0,-243.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.6191\" y=\"-261.3\">dense_input_1: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"167.2383,-243.5 167.2383,-287.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.0728\" y=\"-272.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"167.2383,-265.5 222.9072,-265.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.0728\" y=\"-250.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"222.9072,-243.5 222.9072,-287.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257.7314\" y=\"-272.3\">(None, 8)</text>\n",
       "<polyline fill=\"none\" points=\"222.9072,-265.5 292.5557,-265.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257.7314\" y=\"-250.3\">(None, 8)</text>\n",
       "</g>\n",
       "<!-- 4402258192 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>4402258192</title>\n",
       "<polygon fill=\"none\" points=\"27.9932,-162.5 27.9932,-206.5 264.5625,-206.5 264.5625,-162.5 27.9932,-162.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.1191\" y=\"-180.3\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"132.2451,-162.5 132.2451,-206.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160.0796\" y=\"-191.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"132.2451,-184.5 187.9141,-184.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160.0796\" y=\"-169.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"187.9141,-162.5 187.9141,-206.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"226.2383\" y=\"-191.3\">(None, 8)</text>\n",
       "<polyline fill=\"none\" points=\"187.9141,-184.5 264.5625,-184.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"226.2383\" y=\"-169.3\">(None, 12)</text>\n",
       "</g>\n",
       "<!-- 4469686928&#45;&gt;4402258192 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>4469686928-&gt;4402258192</title>\n",
       "<path d=\"M146.2778,-243.3664C146.2778,-235.1516 146.2778,-225.6579 146.2778,-216.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"149.7779,-216.6068 146.2778,-206.6068 142.7779,-216.6069 149.7779,-216.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4469686864 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>4469686864</title>\n",
       "<polygon fill=\"none\" points=\"27.9932,-81.5 27.9932,-125.5 264.5625,-125.5 264.5625,-81.5 27.9932,-81.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.1191\" y=\"-99.3\">dense_2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"132.2451,-81.5 132.2451,-125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160.0796\" y=\"-110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"132.2451,-103.5 187.9141,-103.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160.0796\" y=\"-88.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"187.9141,-81.5 187.9141,-125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"226.2383\" y=\"-110.3\">(None, 12)</text>\n",
       "<polyline fill=\"none\" points=\"187.9141,-103.5 264.5625,-103.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"226.2383\" y=\"-88.3\">(None, 8)</text>\n",
       "</g>\n",
       "<!-- 4402258192&#45;&gt;4469686864 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>4402258192-&gt;4469686864</title>\n",
       "<path d=\"M146.2778,-162.3664C146.2778,-154.1516 146.2778,-144.6579 146.2778,-135.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"149.7779,-135.6068 146.2778,-125.6068 142.7779,-135.6069 149.7779,-135.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4471684304 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>4471684304</title>\n",
       "<polygon fill=\"none\" points=\"31.4932,-.5 31.4932,-44.5 261.0625,-44.5 261.0625,-.5 31.4932,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.6191\" y=\"-18.3\">dense_3: Dense</text>\n",
       "<polyline fill=\"none\" points=\"135.7451,-.5 135.7451,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163.5796\" y=\"-29.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"135.7451,-22.5 191.4141,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163.5796\" y=\"-7.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"191.4141,-.5 191.4141,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"226.2383\" y=\"-29.3\">(None, 8)</text>\n",
       "<polyline fill=\"none\" points=\"191.4141,-22.5 261.0625,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"226.2383\" y=\"-7.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 4469686864&#45;&gt;4471684304 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>4469686864-&gt;4471684304</title>\n",
       "<path d=\"M146.2778,-81.3664C146.2778,-73.1516 146.2778,-63.6579 146.2778,-54.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"149.7779,-54.6068 146.2778,-44.6068 142.7779,-54.6069 149.7779,-54.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "# 모델 구성 가시화하기\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](http://tykimos.github.com/Keras/warehouse/2017-2-4_MLP_Getting_Started_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 모델 엮기\n",
    "\n",
    "모델을 정의했다면 모델을 손실함수와 최적화 알고리즘으로 엮어봅니다. \n",
    "- loss : 현재 가중치 세트를 평가하는 데 사용한 손실 함수 입니다. 이진 클래스 문제이므로 'binary_crossentropy'으로 지정합니다.\n",
    "- optimizer : 최적의 가중치를 검색하는 데 사용되는 최적화 알고리즘으로 효율적인 경사 하강법 알고리즘 중 하나인 'adam'을 사용합니다.\n",
    "- metrics : 평가 척도를 나타내며 분류 문제에서는 일반적으로 'accuracy'으로 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 모델 엮기\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 모델 학습시키기\n",
    "\n",
    "모델을 학습시키기 위해서 fit() 함수를 사용합니다. \n",
    "- 첫번째 인자 : 입력 변수입니다. 8개의 속성 값을 담고 있는 X를 입력합니다.\n",
    "- 두번째 인자 : 출력 변수 즉 라벨값입니다. 결과 값을 담고 았는 Y를 입력합니다.\n",
    "- nb_epoch : 전체 훈련 데이터셋에 대해 학습 반복 횟수를 지정합니다. 100번을 반복적으로 학습시켜 보겠습니다.\n",
    "- batch_size : 가중치를 업데이트할 배치 크기를 의미하며, 10개로 지정했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "768/768 [==============================] - 0s - loss: 0.6854 - acc: 0.6211     \n",
      "Epoch 2/100\n",
      "768/768 [==============================] - 0s - loss: 0.6671 - acc: 0.6510     \n",
      "Epoch 3/100\n",
      "768/768 [==============================] - 0s - loss: 0.6550 - acc: 0.6510     \n",
      "Epoch 4/100\n",
      "768/768 [==============================] - 0s - loss: 0.6468 - acc: 0.6484     \n",
      "Epoch 5/100\n",
      "768/768 [==============================] - 0s - loss: 0.6374 - acc: 0.6602     \n",
      "Epoch 6/100\n",
      "768/768 [==============================] - 0s - loss: 0.6276 - acc: 0.6654     \n",
      "Epoch 7/100\n",
      "768/768 [==============================] - 0s - loss: 0.6173 - acc: 0.6901     \n",
      "Epoch 8/100\n",
      "768/768 [==============================] - 0s - loss: 0.6051 - acc: 0.6862     \n",
      "Epoch 9/100\n",
      "768/768 [==============================] - 0s - loss: 0.5984 - acc: 0.7005     \n",
      "Epoch 10/100\n",
      "768/768 [==============================] - 0s - loss: 0.5944 - acc: 0.6940     \n",
      "Epoch 11/100\n",
      "768/768 [==============================] - 0s - loss: 0.5934 - acc: 0.6862     \n",
      "Epoch 12/100\n",
      "768/768 [==============================] - 0s - loss: 0.5911 - acc: 0.6966     \n",
      "Epoch 13/100\n",
      "768/768 [==============================] - 0s - loss: 0.5877 - acc: 0.7018     \n",
      "Epoch 14/100\n",
      "768/768 [==============================] - 0s - loss: 0.5861 - acc: 0.6979     \n",
      "Epoch 15/100\n",
      "768/768 [==============================] - 0s - loss: 0.5810 - acc: 0.7005     \n",
      "Epoch 16/100\n",
      "768/768 [==============================] - 0s - loss: 0.5803 - acc: 0.7005     \n",
      "Epoch 17/100\n",
      "768/768 [==============================] - 0s - loss: 0.5764 - acc: 0.7018     \n",
      "Epoch 18/100\n",
      "768/768 [==============================] - 0s - loss: 0.5745 - acc: 0.7070     \n",
      "Epoch 19/100\n",
      "768/768 [==============================] - 0s - loss: 0.5743 - acc: 0.6914     \n",
      "Epoch 20/100\n",
      "768/768 [==============================] - 0s - loss: 0.5768 - acc: 0.6862     \n",
      "Epoch 21/100\n",
      "768/768 [==============================] - 0s - loss: 0.5703 - acc: 0.7044     \n",
      "Epoch 22/100\n",
      "768/768 [==============================] - 0s - loss: 0.5673 - acc: 0.6940     \n",
      "Epoch 23/100\n",
      "768/768 [==============================] - 0s - loss: 0.5743 - acc: 0.6927     \n",
      "Epoch 24/100\n",
      "768/768 [==============================] - 0s - loss: 0.5718 - acc: 0.7070     \n",
      "Epoch 25/100\n",
      "768/768 [==============================] - 0s - loss: 0.5702 - acc: 0.7109     \n",
      "Epoch 26/100\n",
      "768/768 [==============================] - 0s - loss: 0.5654 - acc: 0.6953     \n",
      "Epoch 27/100\n",
      "768/768 [==============================] - 0s - loss: 0.5644 - acc: 0.7096     \n",
      "Epoch 28/100\n",
      "768/768 [==============================] - 0s - loss: 0.5604 - acc: 0.7109     \n",
      "Epoch 29/100\n",
      "768/768 [==============================] - 0s - loss: 0.5594 - acc: 0.7187     \n",
      "Epoch 30/100\n",
      "768/768 [==============================] - 0s - loss: 0.5591 - acc: 0.7240     \n",
      "Epoch 31/100\n",
      "768/768 [==============================] - 0s - loss: 0.5610 - acc: 0.7083     \n",
      "Epoch 32/100\n",
      "768/768 [==============================] - 0s - loss: 0.5581 - acc: 0.7096     \n",
      "Epoch 33/100\n",
      "768/768 [==============================] - 0s - loss: 0.5608 - acc: 0.7174     \n",
      "Epoch 34/100\n",
      "768/768 [==============================] - 0s - loss: 0.5613 - acc: 0.7161     \n",
      "Epoch 35/100\n",
      "768/768 [==============================] - 0s - loss: 0.5559 - acc: 0.7122     \n",
      "Epoch 36/100\n",
      "768/768 [==============================] - 0s - loss: 0.5572 - acc: 0.7331     \n",
      "Epoch 37/100\n",
      "768/768 [==============================] - 0s - loss: 0.5531 - acc: 0.7187     \n",
      "Epoch 38/100\n",
      "768/768 [==============================] - 0s - loss: 0.5539 - acc: 0.7227     \n",
      "Epoch 39/100\n",
      "768/768 [==============================] - 0s - loss: 0.5500 - acc: 0.7148     \n",
      "Epoch 40/100\n",
      "768/768 [==============================] - 0s - loss: 0.5420 - acc: 0.7214     \n",
      "Epoch 41/100\n",
      "768/768 [==============================] - 0s - loss: 0.5471 - acc: 0.7201     \n",
      "Epoch 42/100\n",
      "768/768 [==============================] - 0s - loss: 0.5478 - acc: 0.7161     \n",
      "Epoch 43/100\n",
      "768/768 [==============================] - 0s - loss: 0.5430 - acc: 0.7305     \n",
      "Epoch 44/100\n",
      "768/768 [==============================] - 0s - loss: 0.5446 - acc: 0.7253     \n",
      "Epoch 45/100\n",
      "768/768 [==============================] - 0s - loss: 0.5449 - acc: 0.7240     \n",
      "Epoch 46/100\n",
      "768/768 [==============================] - 0s - loss: 0.5400 - acc: 0.7292     \n",
      "Epoch 47/100\n",
      "768/768 [==============================] - 0s - loss: 0.5367 - acc: 0.7292     \n",
      "Epoch 48/100\n",
      "768/768 [==============================] - 0s - loss: 0.5351 - acc: 0.7357     \n",
      "Epoch 49/100\n",
      "768/768 [==============================] - 0s - loss: 0.5353 - acc: 0.7240     \n",
      "Epoch 50/100\n",
      "768/768 [==============================] - 0s - loss: 0.5321 - acc: 0.7500     \n",
      "Epoch 51/100\n",
      "768/768 [==============================] - 0s - loss: 0.5358 - acc: 0.7435     \n",
      "Epoch 52/100\n",
      "768/768 [==============================] - 0s - loss: 0.5346 - acc: 0.7357     \n",
      "Epoch 53/100\n",
      "768/768 [==============================] - 0s - loss: 0.5420 - acc: 0.7305     \n",
      "Epoch 54/100\n",
      "768/768 [==============================] - 0s - loss: 0.5264 - acc: 0.7396     \n",
      "Epoch 55/100\n",
      "768/768 [==============================] - 0s - loss: 0.5242 - acc: 0.7500     \n",
      "Epoch 56/100\n",
      "768/768 [==============================] - 0s - loss: 0.5294 - acc: 0.7487     \n",
      "Epoch 57/100\n",
      "768/768 [==============================] - 0s - loss: 0.5268 - acc: 0.7370     \n",
      "Epoch 58/100\n",
      "768/768 [==============================] - 0s - loss: 0.5307 - acc: 0.7474     \n",
      "Epoch 59/100\n",
      "768/768 [==============================] - 0s - loss: 0.5260 - acc: 0.7344     \n",
      "Epoch 60/100\n",
      "768/768 [==============================] - 0s - loss: 0.5212 - acc: 0.7526     \n",
      "Epoch 61/100\n",
      "768/768 [==============================] - 0s - loss: 0.5192 - acc: 0.7461     \n",
      "Epoch 62/100\n",
      "768/768 [==============================] - 0s - loss: 0.5303 - acc: 0.7305     \n",
      "Epoch 63/100\n",
      "768/768 [==============================] - 0s - loss: 0.5148 - acc: 0.7591     \n",
      "Epoch 64/100\n",
      "768/768 [==============================] - 0s - loss: 0.5171 - acc: 0.7617     \n",
      "Epoch 65/100\n",
      "768/768 [==============================] - 0s - loss: 0.5242 - acc: 0.7435     \n",
      "Epoch 66/100\n",
      "768/768 [==============================] - 0s - loss: 0.5077 - acc: 0.7552     \n",
      "Epoch 67/100\n",
      "768/768 [==============================] - 0s - loss: 0.5090 - acc: 0.7604     \n",
      "Epoch 68/100\n",
      "768/768 [==============================] - 0s - loss: 0.5111 - acc: 0.7565     \n",
      "Epoch 69/100\n",
      "768/768 [==============================] - 0s - loss: 0.5117 - acc: 0.7565     \n",
      "Epoch 70/100\n",
      "768/768 [==============================] - 0s - loss: 0.5062 - acc: 0.7526     \n",
      "Epoch 71/100\n",
      "768/768 [==============================] - 0s - loss: 0.5026 - acc: 0.7474     \n",
      "Epoch 72/100\n",
      "768/768 [==============================] - 0s - loss: 0.5075 - acc: 0.7526     \n",
      "Epoch 73/100\n",
      "768/768 [==============================] - 0s - loss: 0.5133 - acc: 0.7500     \n",
      "Epoch 74/100\n",
      "768/768 [==============================] - 0s - loss: 0.5133 - acc: 0.7578     \n",
      "Epoch 75/100\n",
      "768/768 [==============================] - 0s - loss: 0.5057 - acc: 0.7604     \n",
      "Epoch 76/100\n",
      "768/768 [==============================] - 0s - loss: 0.5104 - acc: 0.7578     \n",
      "Epoch 77/100\n",
      "768/768 [==============================] - 0s - loss: 0.5000 - acc: 0.7539     \n",
      "Epoch 78/100\n",
      "768/768 [==============================] - 0s - loss: 0.5057 - acc: 0.7565     \n",
      "Epoch 79/100\n",
      "768/768 [==============================] - 0s - loss: 0.4971 - acc: 0.7656     \n",
      "Epoch 80/100\n",
      "768/768 [==============================] - 0s - loss: 0.4940 - acc: 0.7682     \n",
      "Epoch 81/100\n",
      "768/768 [==============================] - 0s - loss: 0.5022 - acc: 0.7500     \n",
      "Epoch 82/100\n",
      "768/768 [==============================] - 0s - loss: 0.4974 - acc: 0.7552     \n",
      "Epoch 83/100\n",
      "768/768 [==============================] - 0s - loss: 0.4912 - acc: 0.7669     \n",
      "Epoch 84/100\n",
      "768/768 [==============================] - 0s - loss: 0.4911 - acc: 0.7656     \n",
      "Epoch 85/100\n",
      "768/768 [==============================] - 0s - loss: 0.4919 - acc: 0.7773     \n",
      "Epoch 86/100\n",
      "768/768 [==============================] - 0s - loss: 0.4977 - acc: 0.7526     \n",
      "Epoch 87/100\n",
      "768/768 [==============================] - 0s - loss: 0.4910 - acc: 0.7695     \n",
      "Epoch 88/100\n",
      "768/768 [==============================] - 0s - loss: 0.4866 - acc: 0.7682     \n",
      "Epoch 89/100\n",
      "768/768 [==============================] - 0s - loss: 0.4872 - acc: 0.7760     \n",
      "Epoch 90/100\n",
      "768/768 [==============================] - 0s - loss: 0.4869 - acc: 0.7630     \n",
      "Epoch 91/100\n",
      "768/768 [==============================] - 0s - loss: 0.4938 - acc: 0.7565     \n",
      "Epoch 92/100\n",
      "768/768 [==============================] - 0s - loss: 0.4899 - acc: 0.7617     \n",
      "Epoch 93/100\n",
      "768/768 [==============================] - 0s - loss: 0.4929 - acc: 0.7578     \n",
      "Epoch 94/100\n",
      "768/768 [==============================] - 0s - loss: 0.4935 - acc: 0.7630     \n",
      "Epoch 95/100\n",
      "768/768 [==============================] - 0s - loss: 0.4857 - acc: 0.7643     \n",
      "Epoch 96/100\n",
      "768/768 [==============================] - 0s - loss: 0.4822 - acc: 0.7682     \n",
      "Epoch 97/100\n",
      "768/768 [==============================] - 0s - loss: 0.4846 - acc: 0.7656     \n",
      "Epoch 98/100\n",
      "768/768 [==============================] - 0s - loss: 0.4854 - acc: 0.7695     \n",
      "Epoch 99/100\n",
      "768/768 [==============================] - 0s - loss: 0.4782 - acc: 0.7656     \n",
      "Epoch 100/100\n",
      "768/768 [==============================] - 0s - loss: 0.4811 - acc: 0.7747     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10ba05c10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습시키기\n",
    "model.fit(X, Y, nb_epoch=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 모델 사용하기\n",
    "\n",
    "동일한 데이터셋으로 학습한 모델을 평가해봅니다. 일반적으로 모델을 평가할 때 훈련셋과 동일한 데이터셋을 이용하지 않습니다. 모델 평가 하는 법에 대해서는 이후 강좌에서 다루겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/768 [>.............................] - ETA: 0sacc: 77.21%\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가하기\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "77.21% 이라는 결과가 나왔습니다. 현재 튜닝도 하지 않았고 모델 평가도 제대로 된 방법으로 이루어지진 않았지만 만족할만한 수준인 것 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 전체 소스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "768/768 [==============================] - 0s - loss: 0.6854 - acc: 0.6211     \n",
      "Epoch 2/100\n",
      "768/768 [==============================] - 0s - loss: 0.6671 - acc: 0.6510     \n",
      "Epoch 3/100\n",
      "768/768 [==============================] - 0s - loss: 0.6550 - acc: 0.6510     \n",
      "Epoch 4/100\n",
      "768/768 [==============================] - 0s - loss: 0.6468 - acc: 0.6484     \n",
      "Epoch 5/100\n",
      "768/768 [==============================] - 0s - loss: 0.6374 - acc: 0.6602     \n",
      "Epoch 6/100\n",
      "768/768 [==============================] - 0s - loss: 0.6276 - acc: 0.6654     \n",
      "Epoch 7/100\n",
      "768/768 [==============================] - 0s - loss: 0.6173 - acc: 0.6901     \n",
      "Epoch 8/100\n",
      "768/768 [==============================] - 0s - loss: 0.6051 - acc: 0.6862     \n",
      "Epoch 9/100\n",
      "768/768 [==============================] - 0s - loss: 0.5984 - acc: 0.7005     \n",
      "Epoch 10/100\n",
      "768/768 [==============================] - 0s - loss: 0.5944 - acc: 0.6940     \n",
      "Epoch 11/100\n",
      "768/768 [==============================] - 0s - loss: 0.5934 - acc: 0.6862     \n",
      "Epoch 12/100\n",
      "768/768 [==============================] - 0s - loss: 0.5911 - acc: 0.6966     \n",
      "Epoch 13/100\n",
      "768/768 [==============================] - 0s - loss: 0.5877 - acc: 0.7018     \n",
      "Epoch 14/100\n",
      "768/768 [==============================] - 0s - loss: 0.5861 - acc: 0.6979     \n",
      "Epoch 15/100\n",
      "768/768 [==============================] - 0s - loss: 0.5810 - acc: 0.7005     \n",
      "Epoch 16/100\n",
      "768/768 [==============================] - 0s - loss: 0.5803 - acc: 0.7005     \n",
      "Epoch 17/100\n",
      "768/768 [==============================] - 0s - loss: 0.5764 - acc: 0.7018     \n",
      "Epoch 18/100\n",
      "768/768 [==============================] - 0s - loss: 0.5745 - acc: 0.7070     \n",
      "Epoch 19/100\n",
      "768/768 [==============================] - 0s - loss: 0.5743 - acc: 0.6914     \n",
      "Epoch 20/100\n",
      "768/768 [==============================] - 0s - loss: 0.5768 - acc: 0.6862     \n",
      "Epoch 21/100\n",
      "768/768 [==============================] - 0s - loss: 0.5703 - acc: 0.7044     \n",
      "Epoch 22/100\n",
      "768/768 [==============================] - 0s - loss: 0.5673 - acc: 0.6940     \n",
      "Epoch 23/100\n",
      "768/768 [==============================] - 0s - loss: 0.5743 - acc: 0.6927     \n",
      "Epoch 24/100\n",
      "768/768 [==============================] - 0s - loss: 0.5718 - acc: 0.7070     \n",
      "Epoch 25/100\n",
      "768/768 [==============================] - 0s - loss: 0.5702 - acc: 0.7109     \n",
      "Epoch 26/100\n",
      "768/768 [==============================] - 0s - loss: 0.5654 - acc: 0.6953     \n",
      "Epoch 27/100\n",
      "768/768 [==============================] - 0s - loss: 0.5644 - acc: 0.7096     \n",
      "Epoch 28/100\n",
      "768/768 [==============================] - 0s - loss: 0.5604 - acc: 0.7109     \n",
      "Epoch 29/100\n",
      "768/768 [==============================] - 0s - loss: 0.5594 - acc: 0.7187     \n",
      "Epoch 30/100\n",
      "768/768 [==============================] - 0s - loss: 0.5591 - acc: 0.7240     \n",
      "Epoch 31/100\n",
      "768/768 [==============================] - 0s - loss: 0.5610 - acc: 0.7083     \n",
      "Epoch 32/100\n",
      "768/768 [==============================] - 0s - loss: 0.5581 - acc: 0.7096     \n",
      "Epoch 33/100\n",
      "768/768 [==============================] - 0s - loss: 0.5608 - acc: 0.7174     \n",
      "Epoch 34/100\n",
      "768/768 [==============================] - 0s - loss: 0.5613 - acc: 0.7161     \n",
      "Epoch 35/100\n",
      "768/768 [==============================] - 0s - loss: 0.5559 - acc: 0.7122     \n",
      "Epoch 36/100\n",
      "768/768 [==============================] - 0s - loss: 0.5572 - acc: 0.7331     \n",
      "Epoch 37/100\n",
      "768/768 [==============================] - 0s - loss: 0.5531 - acc: 0.7187     \n",
      "Epoch 38/100\n",
      "768/768 [==============================] - 0s - loss: 0.5539 - acc: 0.7227     \n",
      "Epoch 39/100\n",
      "768/768 [==============================] - 0s - loss: 0.5500 - acc: 0.7148     \n",
      "Epoch 40/100\n",
      "768/768 [==============================] - 0s - loss: 0.5420 - acc: 0.7214     \n",
      "Epoch 41/100\n",
      "768/768 [==============================] - 0s - loss: 0.5471 - acc: 0.7201     \n",
      "Epoch 42/100\n",
      "768/768 [==============================] - 0s - loss: 0.5478 - acc: 0.7161     \n",
      "Epoch 43/100\n",
      "768/768 [==============================] - 0s - loss: 0.5430 - acc: 0.7305     \n",
      "Epoch 44/100\n",
      "768/768 [==============================] - 0s - loss: 0.5446 - acc: 0.7253     \n",
      "Epoch 45/100\n",
      "768/768 [==============================] - 0s - loss: 0.5449 - acc: 0.7240     \n",
      "Epoch 46/100\n",
      "768/768 [==============================] - 0s - loss: 0.5400 - acc: 0.7292     \n",
      "Epoch 47/100\n",
      "768/768 [==============================] - 0s - loss: 0.5367 - acc: 0.7292     \n",
      "Epoch 48/100\n",
      "768/768 [==============================] - 0s - loss: 0.5351 - acc: 0.7357     \n",
      "Epoch 49/100\n",
      "768/768 [==============================] - 0s - loss: 0.5353 - acc: 0.7240     \n",
      "Epoch 50/100\n",
      "768/768 [==============================] - 0s - loss: 0.5321 - acc: 0.7500     \n",
      "Epoch 51/100\n",
      "768/768 [==============================] - 0s - loss: 0.5358 - acc: 0.7435     \n",
      "Epoch 52/100\n",
      "768/768 [==============================] - 0s - loss: 0.5346 - acc: 0.7357     \n",
      "Epoch 53/100\n",
      "768/768 [==============================] - 0s - loss: 0.5420 - acc: 0.7305     \n",
      "Epoch 54/100\n",
      "768/768 [==============================] - 0s - loss: 0.5264 - acc: 0.7396     \n",
      "Epoch 55/100\n",
      "768/768 [==============================] - 0s - loss: 0.5242 - acc: 0.7500     \n",
      "Epoch 56/100\n",
      "768/768 [==============================] - 0s - loss: 0.5294 - acc: 0.7487     \n",
      "Epoch 57/100\n",
      "768/768 [==============================] - 0s - loss: 0.5268 - acc: 0.7370     \n",
      "Epoch 58/100\n",
      "768/768 [==============================] - 0s - loss: 0.5307 - acc: 0.7474     \n",
      "Epoch 59/100\n",
      "768/768 [==============================] - 0s - loss: 0.5260 - acc: 0.7344     \n",
      "Epoch 60/100\n",
      "768/768 [==============================] - 0s - loss: 0.5212 - acc: 0.7526     \n",
      "Epoch 61/100\n",
      "768/768 [==============================] - 0s - loss: 0.5192 - acc: 0.7461     \n",
      "Epoch 62/100\n",
      "768/768 [==============================] - 0s - loss: 0.5303 - acc: 0.7305     \n",
      "Epoch 63/100\n",
      "768/768 [==============================] - 0s - loss: 0.5148 - acc: 0.7591     \n",
      "Epoch 64/100\n",
      "768/768 [==============================] - 0s - loss: 0.5171 - acc: 0.7617     \n",
      "Epoch 65/100\n",
      "768/768 [==============================] - 0s - loss: 0.5242 - acc: 0.7435     \n",
      "Epoch 66/100\n",
      "768/768 [==============================] - 0s - loss: 0.5077 - acc: 0.7552     \n",
      "Epoch 67/100\n",
      "768/768 [==============================] - 0s - loss: 0.5090 - acc: 0.7604     \n",
      "Epoch 68/100\n",
      "768/768 [==============================] - 0s - loss: 0.5111 - acc: 0.7565     \n",
      "Epoch 69/100\n",
      "768/768 [==============================] - 0s - loss: 0.5117 - acc: 0.7565     \n",
      "Epoch 70/100\n",
      "768/768 [==============================] - 0s - loss: 0.5062 - acc: 0.7526     \n",
      "Epoch 71/100\n",
      "768/768 [==============================] - 0s - loss: 0.5026 - acc: 0.7474     \n",
      "Epoch 72/100\n",
      "768/768 [==============================] - 0s - loss: 0.5075 - acc: 0.7526     \n",
      "Epoch 73/100\n",
      "768/768 [==============================] - 0s - loss: 0.5133 - acc: 0.7500     \n",
      "Epoch 74/100\n",
      "768/768 [==============================] - 0s - loss: 0.5133 - acc: 0.7578     \n",
      "Epoch 75/100\n",
      "768/768 [==============================] - 0s - loss: 0.5057 - acc: 0.7604     \n",
      "Epoch 76/100\n",
      "768/768 [==============================] - 0s - loss: 0.5104 - acc: 0.7578     \n",
      "Epoch 77/100\n",
      "768/768 [==============================] - 0s - loss: 0.5000 - acc: 0.7539     \n",
      "Epoch 78/100\n",
      "768/768 [==============================] - 0s - loss: 0.5057 - acc: 0.7565     \n",
      "Epoch 79/100\n",
      "768/768 [==============================] - 0s - loss: 0.4971 - acc: 0.7656     \n",
      "Epoch 80/100\n",
      "768/768 [==============================] - 0s - loss: 0.4940 - acc: 0.7682     \n",
      "Epoch 81/100\n",
      "768/768 [==============================] - 0s - loss: 0.5022 - acc: 0.7500     \n",
      "Epoch 82/100\n",
      "768/768 [==============================] - 0s - loss: 0.4974 - acc: 0.7552     \n",
      "Epoch 83/100\n",
      "768/768 [==============================] - 0s - loss: 0.4912 - acc: 0.7669     \n",
      "Epoch 84/100\n",
      "768/768 [==============================] - 0s - loss: 0.4911 - acc: 0.7656     \n",
      "Epoch 85/100\n",
      "768/768 [==============================] - 0s - loss: 0.4919 - acc: 0.7773     \n",
      "Epoch 86/100\n",
      "768/768 [==============================] - 0s - loss: 0.4977 - acc: 0.7526     \n",
      "Epoch 87/100\n",
      "768/768 [==============================] - 0s - loss: 0.4910 - acc: 0.7695     \n",
      "Epoch 88/100\n",
      "768/768 [==============================] - 0s - loss: 0.4866 - acc: 0.7682     \n",
      "Epoch 89/100\n",
      "768/768 [==============================] - 0s - loss: 0.4872 - acc: 0.7760     \n",
      "Epoch 90/100\n",
      "768/768 [==============================] - 0s - loss: 0.4869 - acc: 0.7630     \n",
      "Epoch 91/100\n",
      "768/768 [==============================] - 0s - loss: 0.4938 - acc: 0.7565     \n",
      "Epoch 92/100\n",
      "768/768 [==============================] - 0s - loss: 0.4899 - acc: 0.7617     \n",
      "Epoch 93/100\n",
      "768/768 [==============================] - 0s - loss: 0.4929 - acc: 0.7578     \n",
      "Epoch 94/100\n",
      "768/768 [==============================] - 0s - loss: 0.4935 - acc: 0.7630     \n",
      "Epoch 95/100\n",
      "768/768 [==============================] - 0s - loss: 0.4857 - acc: 0.7643     \n",
      "Epoch 96/100\n",
      "768/768 [==============================] - 0s - loss: 0.4822 - acc: 0.7682     \n",
      "Epoch 97/100\n",
      "768/768 [==============================] - 0s - loss: 0.4846 - acc: 0.7656     \n",
      "Epoch 98/100\n",
      "768/768 [==============================] - 0s - loss: 0.4854 - acc: 0.7695     \n",
      "Epoch 99/100\n",
      "768/768 [==============================] - 0s - loss: 0.4782 - acc: 0.7656     \n",
      "Epoch 100/100\n",
      "768/768 [==============================] - 0s - loss: 0.4811 - acc: 0.7747     \n",
      " 32/768 [>.............................] - ETA: 0sacc: 77.21%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 랜덤시드 고정시키기\n",
    "np.random.seed(5)\n",
    "\n",
    "# 데이터셋 불러오기\n",
    "dataset = np.loadtxt(\"./warehouse/pima-indians-diabetes.data\", delimiter=\",\")\n",
    "\n",
    "# 입력(X)과 출력(Y) 변수로 분리하기\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "\n",
    "# 모델 엮기\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습시키기\n",
    "model.fit(X, Y, nb_epoch=100, batch_size=10)\n",
    "\n",
    "# 모델 평가하기\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 결론\n",
    "\n",
    "다층 퍼셉트론 모델을 만들어보고 실제 데이터셋을 사용하여 학습시켜봤습니다. 수치로 된 데이터를 불러오는 법과 모델에 학습시키기 위해서 간단히 가공을 해봤습니다. 또한 이진 분류 문제를 적용하기 위해서 입력 레이어와 출력 레이어를 어떻게 구성해야 하는 지도 알아봤습니다.\n",
    "\n",
    "본 강좌를 마치기 전에 '피마족 인디언 당뇨병 발병 데이터셋'에 대해서 조금 더 알아보고자 합니다. 위 링크의 'Data Folder'안에 'costs'라는 폴더가 있는데 여기에 있는 파일에는 각 속성별로 비용이라던지 획득 시간 등의 수치 정보가 포함되어 있습니다. 먼저 costs 폴더에 어떤 파일이 있는 지 알아보겠습니다.\n",
    "\n",
    "* pima-indians-diabetes.cost : 속성별로 테스트를 위한 비용이 캐나다 달러로 표시되어 있습니다. \n",
    "* pima-indians-diabetes.delay : 속성별로 테스트 시에 바로 결과가 나오는 지('immediate') 아니면 시간이 걸리는 지('delayed')가 표시되어 있습니다. 예를 들어 혈액 검사는 혈액을 취득 후에 실험실로 보내졌다가 다음날 의사에게 전달되기 때문에 테스트에 시간이 걸립니다.\n",
    "* pima-indians-diabetes.expense : 단체로 테스트를 할 경우에는 할인이 될 수 있기 때문에, 각 속성별로 단체 할인 비용을 표시하였습니다.\n",
    "* pima-indians-diabetes.group : 단체로 그룹핑할 수 있는 속성이 표기되어 있습니다.\n",
    "\n",
    "표로 요약해봤습니다. 임신 횟수나 나이, 혈압 등은 구두로 물어보거나 측정기로 간단하게 측정할 수 있기 때문에 비용이 얼마 들지 않지만, 포도당 내성 검사나 혈청 인슐린 수치 등 혈액 검사가 필요한 것은 비용도 발생하고 테스트 결과도 즉시 알 수 없습니다. 실제로도 딥러닝을 실무에 적용하려다 보면 데이터 수집 및 판정 결과를 얻기가 쉽지 않고 비용 산정도 어려울 때가 많습니다. 기간, 비용등을 고려하여 계획을 세워야 효율적으로 데이터를 원할하게 수집할 수가 있습니다. \n",
    "\n",
    "|No.|속성|테스트 시간|비용(CAD)|단체할인비용(CAD)|\n",
    "|:-:|:-:|:-:|-:|-:|\n",
    "|1|임신 횟수|즉시|1.00|N/A|\n",
    "|2|포도당 내성|지연|17.61|15.51|\n",
    "|3|이완기 혈압|즉시|1.00|N/A|\n",
    "|4|삼두근 피부 두겹 두께|즉시|1.00|N/A|\n",
    "|5|혈청 인슐린|지연|22.78|20.68|\n",
    "|6|체질량 지수|즉시|1.00|N/A|\n",
    "|7|당뇨 직계 가족력|즉시|1.00|N/A|\n",
    "|8|나이|즉시|1.00|N/A|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "### 같이 보기\n",
    "\n",
    "* [강좌 목차](https://tykimos.github.io/Keras/2017/01/27/Keras_Lecture_Contents/)\n",
    "* 이전 : [딥러닝 모델 이야기/다층 퍼셉트론 레이어 이야기](https://tykimos.github.io/Keras/2017/01/27/MLP_Layer_Talk/)\n",
    "* 다음 : [딥러닝 모델 이야기/컨볼루션 신경망 레이어 이야기](https://tykimos.github.io/Keras/2017/01/27/CNN_Layer_Talk/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
