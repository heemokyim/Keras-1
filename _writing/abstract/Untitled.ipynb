{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "# 지정된 너비, 높이로 씬을 생성합니다.\n",
    "# 씬에는 두 개의 객체를 포함하고 있습니다.\n",
    "# 객체가 위치된 픽셀 값은 1.0이고 나머지 픽셀 값은 0.0입니다.\n",
    "def generate_scene(w, h):\n",
    "    \n",
    "    scene = np.zeros((w, h))\n",
    "    \n",
    "    # 첫번째 객체 위치를 임의로 선정합니다.\n",
    "    pos_1_x = random.randrange(0, w) # 0, 1, 2 중 하나\n",
    "    pos_1_y = random.randrange(0, h) # 0, 1, 2 중 하나\n",
    "    \n",
    "    # 두번째 객체 위치를 첫번째 객체 위치와 겹치지 않도록 임의로 선정합니다.\n",
    "    find_pos_2 = False\n",
    "    while not find_pos_2:\n",
    "        pos_2_x = random.randrange(0, w)\n",
    "        pos_2_y = random.randrange(0, h)\n",
    "        if pos_1_x == pos_2_x and pos_1_y == pos_2_y:\n",
    "            continue\n",
    "        find_pos_2 = True\n",
    "    \n",
    "    # 선정된 두 객체 위치에 1.0을 셋팅합니다.\n",
    "    scene[pos_1_y][pos_1_x] = 1.0\n",
    "    scene[pos_2_y][pos_2_x] = 1.0    \n",
    "    \n",
    "    return scene\n",
    "\n",
    "# 씬을 이미지 파일로 저장합니다.\n",
    "def save_image_from_scene(scene, filename):\n",
    "    im_scene = scene * 255.0    \n",
    "    im = Image.new('L', (im_scene.shape[0], im_scene.shape[1]))\n",
    "    im.putdata(im_scene.flatten().tolist())\n",
    "    im.save(filename)\n",
    "    \n",
    "# 씬의 두 객체 간의 거리를 구합니다.\n",
    "def distance_objects(scene):\n",
    "        \n",
    "    pos_x = []\n",
    "    pos_y = []\n",
    "\n",
    "    # 두 객체의 위치를 찾습니다.\n",
    "    for x in range(scene.shape[0]):\n",
    "        for y in range(scene.shape[1]):\n",
    "            if scene[y][x] == 1.0:\n",
    "                pos_x.append(x)\n",
    "                pos_y.append(y)                \n",
    "\n",
    "    # 두 객체의 거리를 구합니다.\n",
    "    dist = math.sqrt(math.pow(pos_x[0] - pos_x[1], 2) + math.pow(pos_y[0] - pos_y[1], 2))\n",
    "    \n",
    "    return dist\n",
    "    \n",
    "def generate_dataset(count, width, height, dist_threshold, save_file = False):\n",
    "    \n",
    "    dataset_x = []\n",
    "    dataset_y = []\n",
    "    \n",
    "    for i in range(count):\n",
    "        \n",
    "        scene = generate_scene(width, height)\n",
    "        dist = distance_objects(scene)\n",
    "    \n",
    "        if dist < dist_threshold:\n",
    "            dist_label = 0 # 두 객체 간의 거리가 가까우면 0을 반환합니다.\n",
    "        else:\n",
    "            dist_label = 1 # 두 객체 간의 거리가 멀면 1을 반환합니다.\n",
    "        \n",
    "        # 이미지로 저장합니다.\n",
    "        if save_file :\n",
    "            filename = './warehouse/rn/' + str(dist_label) + '_' + str(i) + '.png'\n",
    "            save_image_from_scene(scene, filename)\n",
    "        \n",
    "        # 데이터셋을 생성합니다.\n",
    "        dataset_x.append(scene)\n",
    "        dataset_y.append(dist_label)\n",
    "    \n",
    "    return np.array(dataset_x), np.array(dataset_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 생성 및 구성\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 200\n",
    "width = 5\n",
    "height = 5\n",
    "dist_threshold = math.sqrt(width*height)/2.0\n",
    "\n",
    "dataset_X, dataset_Y = generate_dataset(count, width, height, dist_threshold, True)\n",
    "\n",
    "train_size = int(len(dataset_X) * 0.70)\n",
    "test_size = len(dataset_X) - train_size\n",
    "\n",
    "train_X, test_X = dataset_X[0:train_size], dataset_X[train_size:len(dataset_X)]\n",
    "train_Y, test_Y = dataset_Y[0:train_size], dataset_Y[train_size:len(dataset_Y)]\n",
    "\n",
    "train_X = train_X.reshape(train_X.shape[0], train_X.shape[1]*train_X.shape[2])\n",
    "test_X = test_X.reshape(test_X.shape[0], test_X.shape[1]*test_X.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "# 손실 이력 클래스 정의\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def init(self):\n",
    "        self.acc = []\n",
    "        self.loss = []\n",
    "        self.val_acc = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.loss.append(logs.get('loss'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        self.val_loss.append(logs.get('val_loss'))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140 samples, validate on 60 samples\n",
      "Epoch 1/100\n",
      "140/140 [==============================] - 0s - loss: 0.6930 - acc: 0.5286 - val_loss: 0.6930 - val_acc: 0.4333\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 0s - loss: 0.6918 - acc: 0.5500 - val_loss: 0.6935 - val_acc: 0.4167\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 0s - loss: 0.6891 - acc: 0.6143 - val_loss: 0.6927 - val_acc: 0.4500\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 0s - loss: 0.6821 - acc: 0.6357 - val_loss: 0.6908 - val_acc: 0.4333\n",
      "Epoch 5/100\n",
      "140/140 [==============================] - 0s - loss: 0.6662 - acc: 0.6786 - val_loss: 0.6872 - val_acc: 0.5167\n",
      "Epoch 6/100\n",
      "140/140 [==============================] - 0s - loss: 0.6383 - acc: 0.7000 - val_loss: 0.6797 - val_acc: 0.5500\n",
      "Epoch 7/100\n",
      "140/140 [==============================] - 0s - loss: 0.6048 - acc: 0.7286 - val_loss: 0.6762 - val_acc: 0.6000\n",
      "Epoch 8/100\n",
      "140/140 [==============================] - 0s - loss: 0.5633 - acc: 0.7643 - val_loss: 0.6499 - val_acc: 0.7000\n",
      "Epoch 9/100\n",
      "140/140 [==============================] - 0s - loss: 0.5259 - acc: 0.7643 - val_loss: 0.6514 - val_acc: 0.7000\n",
      "Epoch 10/100\n",
      "140/140 [==============================] - 0s - loss: 0.4927 - acc: 0.7786 - val_loss: 0.6710 - val_acc: 0.7000\n",
      "Epoch 11/100\n",
      "140/140 [==============================] - 0s - loss: 0.4616 - acc: 0.7714 - val_loss: 0.6513 - val_acc: 0.6833\n",
      "Epoch 12/100\n",
      "140/140 [==============================] - 0s - loss: 0.4352 - acc: 0.8000 - val_loss: 0.6578 - val_acc: 0.6667\n",
      "Epoch 13/100\n",
      "140/140 [==============================] - 0s - loss: 0.4137 - acc: 0.8286 - val_loss: 0.6691 - val_acc: 0.6833\n",
      "Epoch 14/100\n",
      "140/140 [==============================] - 0s - loss: 0.3880 - acc: 0.8643 - val_loss: 0.6743 - val_acc: 0.6667\n",
      "Epoch 15/100\n",
      "140/140 [==============================] - 0s - loss: 0.3625 - acc: 0.8786 - val_loss: 0.6811 - val_acc: 0.6667\n",
      "Epoch 16/100\n",
      "140/140 [==============================] - 0s - loss: 0.3440 - acc: 0.8786 - val_loss: 0.6934 - val_acc: 0.6833\n",
      "Epoch 17/100\n",
      "140/140 [==============================] - 0s - loss: 0.3179 - acc: 0.8929 - val_loss: 0.7057 - val_acc: 0.7000\n",
      "Epoch 18/100\n",
      "140/140 [==============================] - 0s - loss: 0.2903 - acc: 0.9286 - val_loss: 0.6795 - val_acc: 0.6833\n",
      "Epoch 19/100\n",
      "140/140 [==============================] - 0s - loss: 0.2686 - acc: 0.9429 - val_loss: 0.7082 - val_acc: 0.7000\n",
      "Epoch 20/100\n",
      "140/140 [==============================] - 0s - loss: 0.2448 - acc: 0.9500 - val_loss: 0.6993 - val_acc: 0.6667\n",
      "Epoch 21/100\n",
      "140/140 [==============================] - 0s - loss: 0.2218 - acc: 0.9500 - val_loss: 0.7205 - val_acc: 0.6667\n",
      "Epoch 22/100\n",
      "140/140 [==============================] - 0s - loss: 0.2003 - acc: 0.9643 - val_loss: 0.7126 - val_acc: 0.6667\n",
      "Epoch 23/100\n",
      "140/140 [==============================] - 0s - loss: 0.1821 - acc: 0.9714 - val_loss: 0.7136 - val_acc: 0.6833\n",
      "Epoch 24/100\n",
      "140/140 [==============================] - 0s - loss: 0.1637 - acc: 0.9714 - val_loss: 0.7200 - val_acc: 0.6833\n",
      "Epoch 25/100\n",
      "140/140 [==============================] - 0s - loss: 0.1477 - acc: 0.9786 - val_loss: 0.7301 - val_acc: 0.6833\n",
      "Epoch 26/100\n",
      "140/140 [==============================] - 0s - loss: 0.1303 - acc: 0.9786 - val_loss: 0.7342 - val_acc: 0.7000\n",
      "Epoch 27/100\n",
      "140/140 [==============================] - 0s - loss: 0.1165 - acc: 0.9786 - val_loss: 0.7465 - val_acc: 0.6833\n",
      "Epoch 28/100\n",
      "140/140 [==============================] - 0s - loss: 0.1021 - acc: 0.9786 - val_loss: 0.7497 - val_acc: 0.6833\n",
      "Epoch 29/100\n",
      "140/140 [==============================] - 0s - loss: 0.0905 - acc: 0.9929 - val_loss: 0.7464 - val_acc: 0.6833\n",
      "Epoch 30/100\n",
      "140/140 [==============================] - 0s - loss: 0.0808 - acc: 0.9929 - val_loss: 0.7744 - val_acc: 0.6833\n",
      "Epoch 31/100\n",
      "140/140 [==============================] - 0s - loss: 0.0721 - acc: 0.9929 - val_loss: 0.7677 - val_acc: 0.6833\n",
      "Epoch 32/100\n",
      "140/140 [==============================] - 0s - loss: 0.0649 - acc: 0.9929 - val_loss: 0.7822 - val_acc: 0.6833\n",
      "Epoch 33/100\n",
      "140/140 [==============================] - 0s - loss: 0.0582 - acc: 0.9929 - val_loss: 0.7990 - val_acc: 0.6833\n",
      "Epoch 34/100\n",
      "140/140 [==============================] - 0s - loss: 0.0515 - acc: 0.9929 - val_loss: 0.7841 - val_acc: 0.7000\n",
      "Epoch 35/100\n",
      "140/140 [==============================] - 0s - loss: 0.0443 - acc: 0.9929 - val_loss: 0.8096 - val_acc: 0.7000\n",
      "Epoch 36/100\n",
      "140/140 [==============================] - 0s - loss: 0.0389 - acc: 0.9929 - val_loss: 0.7985 - val_acc: 0.6667\n",
      "Epoch 37/100\n",
      "140/140 [==============================] - 0s - loss: 0.0338 - acc: 1.0000 - val_loss: 0.8173 - val_acc: 0.7000\n",
      "Epoch 38/100\n",
      "140/140 [==============================] - 0s - loss: 0.0299 - acc: 1.0000 - val_loss: 0.8163 - val_acc: 0.7000\n",
      "Epoch 39/100\n",
      "140/140 [==============================] - 0s - loss: 0.0265 - acc: 1.0000 - val_loss: 0.8240 - val_acc: 0.7000\n",
      "Epoch 40/100\n",
      "140/140 [==============================] - 0s - loss: 0.0236 - acc: 1.0000 - val_loss: 0.8310 - val_acc: 0.7000\n",
      "Epoch 41/100\n",
      "140/140 [==============================] - 0s - loss: 0.0213 - acc: 1.0000 - val_loss: 0.8344 - val_acc: 0.7000\n",
      "Epoch 42/100\n",
      "140/140 [==============================] - 0s - loss: 0.0192 - acc: 1.0000 - val_loss: 0.8520 - val_acc: 0.7000\n",
      "Epoch 43/100\n",
      "140/140 [==============================] - 0s - loss: 0.0172 - acc: 1.0000 - val_loss: 0.8487 - val_acc: 0.7000\n",
      "Epoch 44/100\n",
      "140/140 [==============================] - 0s - loss: 0.0160 - acc: 1.0000 - val_loss: 0.8571 - val_acc: 0.7000\n",
      "Epoch 45/100\n",
      "140/140 [==============================] - 0s - loss: 0.0143 - acc: 1.0000 - val_loss: 0.8672 - val_acc: 0.7000\n",
      "Epoch 46/100\n",
      "140/140 [==============================] - 0s - loss: 0.0132 - acc: 1.0000 - val_loss: 0.8689 - val_acc: 0.7000\n",
      "Epoch 47/100\n",
      "140/140 [==============================] - 0s - loss: 0.0123 - acc: 1.0000 - val_loss: 0.8672 - val_acc: 0.7000\n",
      "Epoch 48/100\n",
      "140/140 [==============================] - 0s - loss: 0.0112 - acc: 1.0000 - val_loss: 0.8814 - val_acc: 0.7167\n",
      "Epoch 49/100\n",
      "140/140 [==============================] - 0s - loss: 0.0103 - acc: 1.0000 - val_loss: 0.8795 - val_acc: 0.7000\n",
      "Epoch 50/100\n",
      "140/140 [==============================] - 0s - loss: 0.0095 - acc: 1.0000 - val_loss: 0.8849 - val_acc: 0.7000\n",
      "Epoch 51/100\n",
      "140/140 [==============================] - 0s - loss: 0.0089 - acc: 1.0000 - val_loss: 0.8919 - val_acc: 0.7167\n",
      "Epoch 52/100\n",
      "140/140 [==============================] - 0s - loss: 0.0084 - acc: 1.0000 - val_loss: 0.8937 - val_acc: 0.7167\n",
      "Epoch 53/100\n",
      "140/140 [==============================] - 0s - loss: 0.0078 - acc: 1.0000 - val_loss: 0.9039 - val_acc: 0.7167\n",
      "Epoch 54/100\n",
      "140/140 [==============================] - 0s - loss: 0.0074 - acc: 1.0000 - val_loss: 0.8974 - val_acc: 0.7167\n",
      "Epoch 55/100\n",
      "140/140 [==============================] - 0s - loss: 0.0070 - acc: 1.0000 - val_loss: 0.9105 - val_acc: 0.7167\n",
      "Epoch 56/100\n",
      "140/140 [==============================] - 0s - loss: 0.0065 - acc: 1.0000 - val_loss: 0.9117 - val_acc: 0.7167\n",
      "Epoch 57/100\n",
      "140/140 [==============================] - 0s - loss: 0.0061 - acc: 1.0000 - val_loss: 0.9115 - val_acc: 0.7167\n",
      "Epoch 58/100\n",
      "140/140 [==============================] - 0s - loss: 0.0057 - acc: 1.0000 - val_loss: 0.9224 - val_acc: 0.7167\n",
      "Epoch 59/100\n",
      "140/140 [==============================] - 0s - loss: 0.0055 - acc: 1.0000 - val_loss: 0.9305 - val_acc: 0.7167\n",
      "Epoch 60/100\n",
      "140/140 [==============================] - 0s - loss: 0.0052 - acc: 1.0000 - val_loss: 0.9283 - val_acc: 0.7167\n",
      "Epoch 61/100\n",
      "140/140 [==============================] - 0s - loss: 0.0049 - acc: 1.0000 - val_loss: 0.9330 - val_acc: 0.7167\n",
      "Epoch 62/100\n",
      "140/140 [==============================] - 0s - loss: 0.0046 - acc: 1.0000 - val_loss: 0.9436 - val_acc: 0.7167\n",
      "Epoch 63/100\n",
      "140/140 [==============================] - 0s - loss: 0.0044 - acc: 1.0000 - val_loss: 0.9423 - val_acc: 0.7167\n",
      "Epoch 64/100\n",
      "140/140 [==============================] - 0s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.9439 - val_acc: 0.7167\n",
      "Epoch 65/100\n",
      "140/140 [==============================] - 0s - loss: 0.0040 - acc: 1.0000 - val_loss: 0.9490 - val_acc: 0.7167\n",
      "Epoch 66/100\n",
      "140/140 [==============================] - 0s - loss: 0.0039 - acc: 1.0000 - val_loss: 0.9591 - val_acc: 0.7167\n",
      "Epoch 67/100\n",
      "140/140 [==============================] - 0s - loss: 0.0037 - acc: 1.0000 - val_loss: 0.9571 - val_acc: 0.7167\n",
      "Epoch 68/100\n",
      "140/140 [==============================] - 0s - loss: 0.0035 - acc: 1.0000 - val_loss: 0.9564 - val_acc: 0.7167\n",
      "Epoch 69/100\n",
      "140/140 [==============================] - 0s - loss: 0.0034 - acc: 1.0000 - val_loss: 0.9625 - val_acc: 0.7500\n",
      "Epoch 70/100\n",
      "140/140 [==============================] - 0s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.9678 - val_acc: 0.7167\n",
      "Epoch 71/100\n",
      "140/140 [==============================] - 0s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.9702 - val_acc: 0.7167\n",
      "Epoch 72/100\n",
      "140/140 [==============================] - 0s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.9750 - val_acc: 0.7500\n",
      "Epoch 73/100\n",
      "140/140 [==============================] - 0s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.9763 - val_acc: 0.7167\n",
      "Epoch 74/100\n",
      "140/140 [==============================] - 0s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.9763 - val_acc: 0.7500\n",
      "Epoch 75/100\n",
      "140/140 [==============================] - 0s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.9827 - val_acc: 0.7167\n",
      "Epoch 76/100\n",
      "140/140 [==============================] - 0s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.9830 - val_acc: 0.7500\n",
      "Epoch 77/100\n",
      "140/140 [==============================] - 0s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.9851 - val_acc: 0.7500\n",
      "Epoch 78/100\n",
      "140/140 [==============================] - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.9949 - val_acc: 0.7500\n",
      "Epoch 79/100\n",
      "140/140 [==============================] - 0s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.9927 - val_acc: 0.7500\n",
      "Epoch 80/100\n",
      "140/140 [==============================] - 0s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.9969 - val_acc: 0.7500\n",
      "Epoch 81/100\n",
      "140/140 [==============================] - 0s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.9972 - val_acc: 0.7500\n",
      "Epoch 82/100\n",
      "140/140 [==============================] - 0s - loss: 0.0021 - acc: 1.0000 - val_loss: 1.0026 - val_acc: 0.7500\n",
      "Epoch 83/100\n",
      "140/140 [==============================] - 0s - loss: 0.0020 - acc: 1.0000 - val_loss: 1.0061 - val_acc: 0.7500\n",
      "Epoch 84/100\n",
      "140/140 [==============================] - 0s - loss: 0.0019 - acc: 1.0000 - val_loss: 1.0066 - val_acc: 0.7500\n",
      "Epoch 85/100\n",
      "140/140 [==============================] - 0s - loss: 0.0019 - acc: 1.0000 - val_loss: 1.0126 - val_acc: 0.7500\n",
      "Epoch 86/100\n",
      "140/140 [==============================] - 0s - loss: 0.0018 - acc: 1.0000 - val_loss: 1.0125 - val_acc: 0.7500\n",
      "Epoch 87/100\n",
      "140/140 [==============================] - 0s - loss: 0.0018 - acc: 1.0000 - val_loss: 1.0178 - val_acc: 0.7500\n",
      "Epoch 88/100\n",
      "140/140 [==============================] - 0s - loss: 0.0017 - acc: 1.0000 - val_loss: 1.0161 - val_acc: 0.7500\n",
      "Epoch 89/100\n",
      "140/140 [==============================] - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 1.0191 - val_acc: 0.7500\n",
      "Epoch 90/100\n",
      "140/140 [==============================] - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 1.0203 - val_acc: 0.7500\n",
      "Epoch 91/100\n",
      "140/140 [==============================] - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 1.0273 - val_acc: 0.7500\n",
      "Epoch 92/100\n",
      "140/140 [==============================] - 0s - loss: 0.0015 - acc: 1.0000 - val_loss: 1.0263 - val_acc: 0.7500\n",
      "Epoch 93/100\n",
      "140/140 [==============================] - 0s - loss: 0.0015 - acc: 1.0000 - val_loss: 1.0322 - val_acc: 0.7500\n",
      "Epoch 94/100\n",
      "140/140 [==============================] - 0s - loss: 0.0014 - acc: 1.0000 - val_loss: 1.0317 - val_acc: 0.7500\n",
      "Epoch 95/100\n",
      "140/140 [==============================] - 0s - loss: 0.0014 - acc: 1.0000 - val_loss: 1.0358 - val_acc: 0.7500\n",
      "Epoch 96/100\n",
      "140/140 [==============================] - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0356 - val_acc: 0.7500\n",
      "Epoch 97/100\n",
      "140/140 [==============================] - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0395 - val_acc: 0.7500\n",
      "Epoch 98/100\n",
      "140/140 [==============================] - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 1.0405 - val_acc: 0.7500\n",
      "Epoch 99/100\n",
      "140/140 [==============================] - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0443 - val_acc: 0.7500\n",
      "Epoch 100/100\n",
      "140/140 [==============================] - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 1.0490 - val_acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1160c8a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/60 [===============>..............] - ETA: 0sacc: 75.00%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim = width * height, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(64, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "# 모델 엮기\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = LossHistory()\n",
    "history.init()\n",
    "\n",
    "# 모델 학습시키기\n",
    "model.fit(train_X, train_Y, epochs=100, batch_size=10, validation_data = (test_X, test_Y), callbacks=[history])\n",
    "\n",
    "# 학습 과정 표시하기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.loss)\n",
    "plt.plot(history.val_loss)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 모델 평가하기\n",
    "scores = model.evaluate(test_X, test_Y)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slice_1(t):\n",
    "    return t[:, 0, :, :]\n",
    "\n",
    "def slice_2(t):\n",
    "    return t[:, 1:, :, :]\n",
    "\n",
    "def slice_3(t):\n",
    "    return t[:, 0, :]\n",
    "\n",
    "def slice_4(t):\n",
    "    return t[:, 1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input1 = Input((50, 200, 3))\n",
    "input2 = Input((mxlen,))\n",
    "cnn_features = conv_net(input1)\n",
    "embedding_layer = embedding_layer(tokenizer.word_index, get_embeddings_index(), mxlen)\n",
    "embedding = embedding_layer(input2)\n",
    "# embedding = Embedding(mxlen, embedding_dim)(input2)\n",
    "bi_lstm = Bidirectional(LSTM(lstm_unit, implementation=2, return_sequences=False,\n",
    "                             recurrent_regularizer=regularizers.l2(l2_norm), recurrent_dropout=0.25))\n",
    "lstm_encode = bi_lstm(embedding)\n",
    "shapes = cnn_features.shape\n",
    "w, h = shapes[1], shapes[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_map = dataset\n",
    "feature_map_width = 3\n",
    "feature_map_height = 3\n",
    "\n",
    "features = []\n",
    "for k1 in range(feature_map_width):\n",
    "    features1 = slice_1(feature_map)\n",
    "    feature_map = slice_2(feature_map)\n",
    "    for k2 in range(feature_map_height):\n",
    "        features2 = slice_3(features1)\n",
    "        features1 = slice_4(features1)\n",
    "        features.append(features2)\n",
    "        \n",
    "np_f = np.array(features)\n",
    "print(np_f.shape)\n",
    "print(np_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_map = dataset\n",
    "feature_map_width = 3\n",
    "feature_map_height = 3\n",
    "\n",
    "features_test = []\n",
    "for fw in range(feature_map_width):\n",
    "    for fh in range(feature_map_height):\n",
    "        features_test.append(feature_map[:, fw, fh, :])\n",
    "\n",
    "np_ft = np.array(features_test)\n",
    "print(np_ft.shape)\n",
    "print(np_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np_fm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np_fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relations = []\n",
    "\n",
    "for feature1 in features:\n",
    "    for feature2 in features:\n",
    "        relations.append(np.concatenate([feature1, feature2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np_r = np.array(relations)\n",
    "np_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
