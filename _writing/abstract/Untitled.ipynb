{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "# 지정된 너비, 높이로 씬을 생성합니다.\n",
    "# 씬에는 두 개의 객체를 포함하고 있습니다.\n",
    "# 객체가 위치된 픽셀 값은 1.0이고 나머지 픽셀 값은 0.0입니다.\n",
    "def generate_scene(w, h):\n",
    "    \n",
    "    scene = np.zeros((w, h))\n",
    "    \n",
    "    # 첫번째 객체 위치를 임의로 선정합니다.\n",
    "    pos_1_x = random.randrange(0, w) # 0, 1, 2 중 하나\n",
    "    pos_1_y = random.randrange(0, h) # 0, 1, 2 중 하나\n",
    "    \n",
    "    # 두번째 객체 위치를 첫번째 객체 위치와 겹치지 않도록 임의로 선정합니다.\n",
    "    find_pos_2 = False\n",
    "    while not find_pos_2:\n",
    "        pos_2_x = random.randrange(0, w)\n",
    "        pos_2_y = random.randrange(0, h)\n",
    "        if pos_1_x == pos_2_x and pos_1_y == pos_2_y:\n",
    "            continue\n",
    "        find_pos_2 = True\n",
    "    \n",
    "    # 선정된 두 객체 위치에 1.0을 셋팅합니다.\n",
    "    scene[pos_1_y][pos_1_x] = 1.0\n",
    "    scene[pos_2_y][pos_2_x] = 1.0    \n",
    "    \n",
    "    return scene\n",
    "\n",
    "# 씬을 이미지 파일로 저장합니다.\n",
    "def save_image_from_scene(scene, filename):\n",
    "    im_scene = scene * 255.0    \n",
    "    im = Image.new('L', (im_scene.shape[0], im_scene.shape[1]))\n",
    "    im.putdata(im_scene.flatten().tolist())\n",
    "    im.save(filename)\n",
    "    \n",
    "# 씬의 두 객체 간의 거리를 구합니다.\n",
    "def distance_objects(scene):\n",
    "        \n",
    "    pos_x = []\n",
    "    pos_y = []\n",
    "\n",
    "    # 두 객체의 위치를 찾습니다.\n",
    "    for x in range(scene.shape[0]):\n",
    "        for y in range(scene.shape[1]):\n",
    "            if scene[y][x] == 1.0:\n",
    "                pos_x.append(x)\n",
    "                pos_y.append(y)                \n",
    "\n",
    "    # 두 객체의 거리를 구합니다.\n",
    "    dist = math.sqrt(math.pow(pos_x[0] - pos_x[1], 2) + math.pow(pos_y[0] - pos_y[1], 2))\n",
    "    \n",
    "    return dist\n",
    "    \n",
    "def generate_dataset(count, width, height, dist_threshold, save_file = False):\n",
    "    \n",
    "    dataset_x = []\n",
    "    dataset_y = []\n",
    "    \n",
    "    for i in range(count):\n",
    "        \n",
    "        scene = generate_scene(width, height)\n",
    "        dist = distance_objects(scene)\n",
    "    \n",
    "        if dist < dist_threshold:\n",
    "            dist_label = 0 # 두 객체 간의 거리가 가까우면 0을 반환합니다.\n",
    "        else:\n",
    "            dist_label = 1 # 두 객체 간의 거리가 멀면 1을 반환합니다.\n",
    "        \n",
    "        # 이미지로 저장합니다.\n",
    "        if save_file :\n",
    "            filename = './warehouse/rn/' + str(dist_label) + '_' + str(i) + '.png'\n",
    "            save_image_from_scene(scene, filename)\n",
    "        \n",
    "        # 데이터셋을 생성합니다.\n",
    "        dataset_x.append(scene)\n",
    "        dataset_y.append(dist_label)\n",
    "    \n",
    "    return np.array(dataset_x), np.array(dataset_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 생성 및 구성\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 1000\n",
    "width = 5\n",
    "height = 5\n",
    "dist_threshold = math.sqrt(width*height)/2.0\n",
    "\n",
    "dataset_X, dataset_Y = generate_dataset(count, width, height, dist_threshold, True)\n",
    "\n",
    "train_size = int(len(dataset_X) * 0.70)\n",
    "test_size = len(dataset_X) - train_size\n",
    "\n",
    "train_X, test_X = dataset_X[0:train_size], dataset_X[train_size:len(dataset_X)]\n",
    "train_Y, test_Y = dataset_Y[0:train_size], dataset_Y[train_size:len(dataset_Y)]\n",
    "\n",
    "train_X = train_X.reshape(train_X.shape[0], train_X.shape[1]*train_X.shape[2])\n",
    "test_X = test_X.reshape(test_X.shape[0], test_X.shape[1]*test_X.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/100\n",
      "700/700 [==============================] - 0s - loss: 0.6887 - acc: 0.5614 - val_loss: 0.6733 - val_acc: 0.6433\n",
      "Epoch 2/100\n",
      "700/700 [==============================] - 0s - loss: 0.6146 - acc: 0.6843 - val_loss: 0.5904 - val_acc: 0.6500\n",
      "Epoch 3/100\n",
      "700/700 [==============================] - 0s - loss: 0.5329 - acc: 0.7271 - val_loss: 0.5698 - val_acc: 0.6833\n",
      "Epoch 4/100\n",
      "700/700 [==============================] - 0s - loss: 0.4937 - acc: 0.7671 - val_loss: 0.5356 - val_acc: 0.7100\n",
      "Epoch 5/100\n",
      "700/700 [==============================] - 0s - loss: 0.4393 - acc: 0.8000 - val_loss: 0.4829 - val_acc: 0.7600\n",
      "Epoch 6/100\n",
      "700/700 [==============================] - 0s - loss: 0.3775 - acc: 0.8371 - val_loss: 0.4297 - val_acc: 0.8100\n",
      "Epoch 7/100\n",
      "700/700 [==============================] - 0s - loss: 0.3089 - acc: 0.8800 - val_loss: 0.3409 - val_acc: 0.8567\n",
      "Epoch 8/100\n",
      "700/700 [==============================] - 0s - loss: 0.2302 - acc: 0.9257 - val_loss: 0.2601 - val_acc: 0.8800\n",
      "Epoch 9/100\n",
      "700/700 [==============================] - 0s - loss: 0.1695 - acc: 0.9614 - val_loss: 0.2023 - val_acc: 0.9333\n",
      "Epoch 10/100\n",
      "700/700 [==============================] - 0s - loss: 0.1195 - acc: 0.9814 - val_loss: 0.1561 - val_acc: 0.9367\n",
      "Epoch 11/100\n",
      "700/700 [==============================] - 0s - loss: 0.0857 - acc: 0.9857 - val_loss: 0.1296 - val_acc: 0.9800\n",
      "Epoch 12/100\n",
      "700/700 [==============================] - 0s - loss: 0.0669 - acc: 0.9929 - val_loss: 0.0984 - val_acc: 0.9667\n",
      "Epoch 13/100\n",
      "700/700 [==============================] - 0s - loss: 0.0490 - acc: 0.9929 - val_loss: 0.0848 - val_acc: 0.9667\n",
      "Epoch 14/100\n",
      "700/700 [==============================] - 0s - loss: 0.0370 - acc: 0.9957 - val_loss: 0.0685 - val_acc: 0.9767\n",
      "Epoch 15/100\n",
      "700/700 [==============================] - 0s - loss: 0.0282 - acc: 0.9971 - val_loss: 0.0626 - val_acc: 0.9867\n",
      "Epoch 16/100\n",
      "700/700 [==============================] - 0s - loss: 0.0221 - acc: 0.9971 - val_loss: 0.0460 - val_acc: 0.9933\n",
      "Epoch 17/100\n",
      "700/700 [==============================] - 0s - loss: 0.0166 - acc: 1.0000 - val_loss: 0.0447 - val_acc: 0.9800\n",
      "Epoch 18/100\n",
      "700/700 [==============================] - 0s - loss: 0.0134 - acc: 1.0000 - val_loss: 0.0429 - val_acc: 0.9867\n",
      "Epoch 19/100\n",
      "700/700 [==============================] - 0s - loss: 0.0113 - acc: 1.0000 - val_loss: 0.0402 - val_acc: 0.9867\n",
      "Epoch 20/100\n",
      "700/700 [==============================] - 0s - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0386 - val_acc: 0.9867\n",
      "Epoch 21/100\n",
      "700/700 [==============================] - 0s - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0392 - val_acc: 0.9867\n",
      "Epoch 22/100\n",
      "700/700 [==============================] - 0s - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0332 - val_acc: 0.9933\n",
      "Epoch 23/100\n",
      "700/700 [==============================] - 0s - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0325 - val_acc: 0.9867\n",
      "Epoch 24/100\n",
      "700/700 [==============================] - 0s - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0314 - val_acc: 0.9933\n",
      "Epoch 25/100\n",
      "700/700 [==============================] - 0s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0305 - val_acc: 0.9933\n",
      "Epoch 26/100\n",
      "700/700 [==============================] - 0s - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0298 - val_acc: 0.9933\n",
      "Epoch 27/100\n",
      "700/700 [==============================] - 0s - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0296 - val_acc: 0.9933\n",
      "Epoch 28/100\n",
      "700/700 [==============================] - 0s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0304 - val_acc: 0.9867\n",
      "Epoch 29/100\n",
      "700/700 [==============================] - 0s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0294 - val_acc: 0.9933\n",
      "Epoch 30/100\n",
      "700/700 [==============================] - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0297 - val_acc: 0.9867\n",
      "Epoch 31/100\n",
      "700/700 [==============================] - 0s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0285 - val_acc: 0.9933\n",
      "Epoch 32/100\n",
      "700/700 [==============================] - 0s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0274 - val_acc: 0.9933\n",
      "Epoch 33/100\n",
      "700/700 [==============================] - 0s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0282 - val_acc: 0.9933\n",
      "Epoch 34/100\n",
      "700/700 [==============================] - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0280 - val_acc: 0.9933\n",
      "Epoch 35/100\n",
      "700/700 [==============================] - 0s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0296 - val_acc: 0.9867\n",
      "Epoch 36/100\n",
      "700/700 [==============================] - 0s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0268 - val_acc: 0.9933\n",
      "Epoch 37/100\n",
      "700/700 [==============================] - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0267 - val_acc: 0.9933\n",
      "Epoch 38/100\n",
      "700/700 [==============================] - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0282 - val_acc: 0.9933\n",
      "Epoch 39/100\n",
      "700/700 [==============================] - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0270 - val_acc: 0.9933\n",
      "Epoch 40/100\n",
      "700/700 [==============================] - 0s - loss: 9.8772e-04 - acc: 1.0000 - val_loss: 0.0268 - val_acc: 0.9933\n",
      "Epoch 41/100\n",
      "700/700 [==============================] - 0s - loss: 9.0418e-04 - acc: 1.0000 - val_loss: 0.0284 - val_acc: 0.9867\n",
      "Epoch 42/100\n",
      "700/700 [==============================] - 0s - loss: 8.4807e-04 - acc: 1.0000 - val_loss: 0.0263 - val_acc: 0.9933\n",
      "Epoch 43/100\n",
      "700/700 [==============================] - 0s - loss: 7.8580e-04 - acc: 1.0000 - val_loss: 0.0273 - val_acc: 0.9933\n",
      "Epoch 44/100\n",
      "700/700 [==============================] - 0s - loss: 7.3203e-04 - acc: 1.0000 - val_loss: 0.0279 - val_acc: 0.9933\n",
      "Epoch 45/100\n",
      "700/700 [==============================] - 0s - loss: 6.7834e-04 - acc: 1.0000 - val_loss: 0.0272 - val_acc: 0.9933\n",
      "Epoch 46/100\n",
      "700/700 [==============================] - 0s - loss: 6.3889e-04 - acc: 1.0000 - val_loss: 0.0276 - val_acc: 0.9933\n",
      "Epoch 47/100\n",
      "700/700 [==============================] - 0s - loss: 5.9632e-04 - acc: 1.0000 - val_loss: 0.0269 - val_acc: 0.9933\n",
      "Epoch 48/100\n",
      "700/700 [==============================] - 0s - loss: 5.5671e-04 - acc: 1.0000 - val_loss: 0.0269 - val_acc: 0.9933\n",
      "Epoch 49/100\n",
      "700/700 [==============================] - 0s - loss: 5.2082e-04 - acc: 1.0000 - val_loss: 0.0273 - val_acc: 0.9933\n",
      "Epoch 50/100\n",
      "700/700 [==============================] - 0s - loss: 4.9232e-04 - acc: 1.0000 - val_loss: 0.0270 - val_acc: 0.9933\n",
      "Epoch 51/100\n",
      "700/700 [==============================] - 0s - loss: 4.6443e-04 - acc: 1.0000 - val_loss: 0.0274 - val_acc: 0.9933\n",
      "Epoch 52/100\n",
      "700/700 [==============================] - 0s - loss: 4.3289e-04 - acc: 1.0000 - val_loss: 0.0272 - val_acc: 0.9933\n",
      "Epoch 53/100\n",
      "700/700 [==============================] - 0s - loss: 4.1139e-04 - acc: 1.0000 - val_loss: 0.0270 - val_acc: 0.9933\n",
      "Epoch 54/100\n",
      "700/700 [==============================] - 0s - loss: 3.8467e-04 - acc: 1.0000 - val_loss: 0.0270 - val_acc: 0.9933\n",
      "Epoch 55/100\n",
      "700/700 [==============================] - 0s - loss: 3.6107e-04 - acc: 1.0000 - val_loss: 0.0270 - val_acc: 0.9933\n",
      "Epoch 56/100\n",
      "700/700 [==============================] - 0s - loss: 3.4118e-04 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 0.9933\n",
      "Epoch 57/100\n",
      "700/700 [==============================] - 0s - loss: 3.2109e-04 - acc: 1.0000 - val_loss: 0.0276 - val_acc: 0.9933\n",
      "Epoch 58/100\n",
      "700/700 [==============================] - 0s - loss: 3.0478e-04 - acc: 1.0000 - val_loss: 0.0266 - val_acc: 0.9933\n",
      "Epoch 59/100\n",
      "700/700 [==============================] - 0s - loss: 2.8880e-04 - acc: 1.0000 - val_loss: 0.0275 - val_acc: 0.9933\n",
      "Epoch 60/100\n",
      "700/700 [==============================] - 0s - loss: 2.7279e-04 - acc: 1.0000 - val_loss: 0.0279 - val_acc: 0.9933\n",
      "Epoch 61/100\n",
      "700/700 [==============================] - 0s - loss: 2.5729e-04 - acc: 1.0000 - val_loss: 0.0276 - val_acc: 0.9933\n",
      "Epoch 62/100\n",
      "700/700 [==============================] - 0s - loss: 2.4274e-04 - acc: 1.0000 - val_loss: 0.0276 - val_acc: 0.9933\n",
      "Epoch 63/100\n",
      "700/700 [==============================] - 0s - loss: 2.2911e-04 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 0.9933\n",
      "Epoch 64/100\n",
      "700/700 [==============================] - 0s - loss: 2.1784e-04 - acc: 1.0000 - val_loss: 0.0276 - val_acc: 0.9933\n",
      "Epoch 65/100\n",
      "700/700 [==============================] - 0s - loss: 2.0766e-04 - acc: 1.0000 - val_loss: 0.0283 - val_acc: 0.9933\n",
      "Epoch 66/100\n",
      "700/700 [==============================] - 0s - loss: 1.9763e-04 - acc: 1.0000 - val_loss: 0.0272 - val_acc: 0.9933\n",
      "Epoch 67/100\n",
      "700/700 [==============================] - 0s - loss: 1.8668e-04 - acc: 1.0000 - val_loss: 0.0275 - val_acc: 0.9933\n",
      "Epoch 68/100\n",
      "700/700 [==============================] - 0s - loss: 1.7695e-04 - acc: 1.0000 - val_loss: 0.0281 - val_acc: 0.9933\n",
      "Epoch 69/100\n",
      "700/700 [==============================] - 0s - loss: 1.6779e-04 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 0.9933\n",
      "Epoch 70/100\n",
      "700/700 [==============================] - 0s - loss: 1.5979e-04 - acc: 1.0000 - val_loss: 0.0281 - val_acc: 0.9933\n",
      "Epoch 71/100\n",
      "700/700 [==============================] - 0s - loss: 1.5105e-04 - acc: 1.0000 - val_loss: 0.0276 - val_acc: 0.9933\n",
      "Epoch 72/100\n",
      "700/700 [==============================] - 0s - loss: 1.4453e-04 - acc: 1.0000 - val_loss: 0.0288 - val_acc: 0.9933\n",
      "Epoch 73/100\n",
      "700/700 [==============================] - 0s - loss: 1.3752e-04 - acc: 1.0000 - val_loss: 0.0281 - val_acc: 0.9933\n",
      "Epoch 74/100\n",
      "700/700 [==============================] - 0s - loss: 1.3052e-04 - acc: 1.0000 - val_loss: 0.0285 - val_acc: 0.9933\n",
      "Epoch 75/100\n",
      "700/700 [==============================] - 0s - loss: 1.2562e-04 - acc: 1.0000 - val_loss: 0.0279 - val_acc: 0.9933\n",
      "Epoch 76/100\n",
      "700/700 [==============================] - 0s - loss: 1.1798e-04 - acc: 1.0000 - val_loss: 0.0281 - val_acc: 0.9933\n",
      "Epoch 77/100\n",
      "700/700 [==============================] - 0s - loss: 1.1266e-04 - acc: 1.0000 - val_loss: 0.0278 - val_acc: 0.9933\n",
      "Epoch 78/100\n",
      "700/700 [==============================] - 0s - loss: 1.0686e-04 - acc: 1.0000 - val_loss: 0.0282 - val_acc: 0.9933\n",
      "Epoch 79/100\n",
      "700/700 [==============================] - 0s - loss: 1.0203e-04 - acc: 1.0000 - val_loss: 0.0286 - val_acc: 0.9933\n",
      "Epoch 80/100\n",
      "700/700 [==============================] - 0s - loss: 9.7559e-05 - acc: 1.0000 - val_loss: 0.0282 - val_acc: 0.9933\n",
      "Epoch 81/100\n",
      "700/700 [==============================] - 0s - loss: 9.3229e-05 - acc: 1.0000 - val_loss: 0.0282 - val_acc: 0.9933\n",
      "Epoch 82/100\n",
      "700/700 [==============================] - 0s - loss: 8.8953e-05 - acc: 1.0000 - val_loss: 0.0286 - val_acc: 0.9933\n",
      "Epoch 83/100\n",
      "700/700 [==============================] - 0s - loss: 8.4733e-05 - acc: 1.0000 - val_loss: 0.0282 - val_acc: 0.9933\n",
      "Epoch 84/100\n",
      "700/700 [==============================] - 0s - loss: 8.0920e-05 - acc: 1.0000 - val_loss: 0.0288 - val_acc: 0.9933\n",
      "Epoch 85/100\n",
      "700/700 [==============================] - 0s - loss: 7.7170e-05 - acc: 1.0000 - val_loss: 0.0288 - val_acc: 0.9933\n",
      "Epoch 86/100\n",
      "700/700 [==============================] - 0s - loss: 7.3859e-05 - acc: 1.0000 - val_loss: 0.0292 - val_acc: 0.9933\n",
      "Epoch 87/100\n",
      "700/700 [==============================] - 0s - loss: 6.9996e-05 - acc: 1.0000 - val_loss: 0.0287 - val_acc: 0.9933\n",
      "Epoch 88/100\n",
      "700/700 [==============================] - 0s - loss: 6.7301e-05 - acc: 1.0000 - val_loss: 0.0291 - val_acc: 0.9933\n",
      "Epoch 89/100\n",
      "700/700 [==============================] - 0s - loss: 6.3632e-05 - acc: 1.0000 - val_loss: 0.0290 - val_acc: 0.9933\n",
      "Epoch 90/100\n",
      "700/700 [==============================] - 0s - loss: 6.1371e-05 - acc: 1.0000 - val_loss: 0.0285 - val_acc: 0.9933\n",
      "Epoch 91/100\n",
      "700/700 [==============================] - 0s - loss: 5.8070e-05 - acc: 1.0000 - val_loss: 0.0294 - val_acc: 0.9933\n",
      "Epoch 92/100\n",
      "700/700 [==============================] - 0s - loss: 5.6167e-05 - acc: 1.0000 - val_loss: 0.0293 - val_acc: 0.9933\n",
      "Epoch 93/100\n",
      "700/700 [==============================] - 0s - loss: 5.3821e-05 - acc: 1.0000 - val_loss: 0.0297 - val_acc: 0.9867\n",
      "Epoch 94/100\n",
      "700/700 [==============================] - 0s - loss: 5.1104e-05 - acc: 1.0000 - val_loss: 0.0289 - val_acc: 0.9933\n",
      "Epoch 95/100\n",
      "700/700 [==============================] - 0s - loss: 4.8776e-05 - acc: 1.0000 - val_loss: 0.0291 - val_acc: 0.9933\n",
      "Epoch 96/100\n",
      "700/700 [==============================] - 0s - loss: 4.6854e-05 - acc: 1.0000 - val_loss: 0.0299 - val_acc: 0.9867\n",
      "Epoch 97/100\n",
      "700/700 [==============================] - 0s - loss: 4.4674e-05 - acc: 1.0000 - val_loss: 0.0291 - val_acc: 0.9933\n",
      "Epoch 98/100\n",
      "700/700 [==============================] - 0s - loss: 4.2644e-05 - acc: 1.0000 - val_loss: 0.0291 - val_acc: 0.9933\n",
      "Epoch 99/100\n",
      "700/700 [==============================] - 0s - loss: 4.0636e-05 - acc: 1.0000 - val_loss: 0.0294 - val_acc: 0.9933\n",
      "Epoch 100/100\n",
      "700/700 [==============================] - 0s - loss: 3.9071e-05 - acc: 1.0000 - val_loss: 0.0289 - val_acc: 0.9933\n",
      " 32/300 [==>...........................] - ETA: 0sacc: 99.33%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim = width * height, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(64, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "# 모델 엮기\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습시키기\n",
    "model.fit(train_X, train_Y, epochs=100, batch_size=10, validation_data = (test_X, test_Y))\n",
    "\n",
    "# 모델 평가하기\n",
    "scores = model.evaluate(test_X, test_Y)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slice_1(t):\n",
    "    return t[:, 0, :, :]\n",
    "\n",
    "def slice_2(t):\n",
    "    return t[:, 1:, :, :]\n",
    "\n",
    "def slice_3(t):\n",
    "    return t[:, 0, :]\n",
    "\n",
    "def slice_4(t):\n",
    "    return t[:, 1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input1 = Input((50, 200, 3))\n",
    "input2 = Input((mxlen,))\n",
    "cnn_features = conv_net(input1)\n",
    "embedding_layer = embedding_layer(tokenizer.word_index, get_embeddings_index(), mxlen)\n",
    "embedding = embedding_layer(input2)\n",
    "# embedding = Embedding(mxlen, embedding_dim)(input2)\n",
    "bi_lstm = Bidirectional(LSTM(lstm_unit, implementation=2, return_sequences=False,\n",
    "                             recurrent_regularizer=regularizers.l2(l2_norm), recurrent_dropout=0.25))\n",
    "lstm_encode = bi_lstm(embedding)\n",
    "shapes = cnn_features.shape\n",
    "w, h = shapes[1], shapes[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_map = dataset\n",
    "feature_map_width = 3\n",
    "feature_map_height = 3\n",
    "\n",
    "features = []\n",
    "for k1 in range(feature_map_width):\n",
    "    features1 = slice_1(feature_map)\n",
    "    feature_map = slice_2(feature_map)\n",
    "    for k2 in range(feature_map_height):\n",
    "        features2 = slice_3(features1)\n",
    "        features1 = slice_4(features1)\n",
    "        features.append(features2)\n",
    "        \n",
    "np_f = np.array(features)\n",
    "print(np_f.shape)\n",
    "print(np_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_map = dataset\n",
    "feature_map_width = 3\n",
    "feature_map_height = 3\n",
    "\n",
    "features_test = []\n",
    "for fw in range(feature_map_width):\n",
    "    for fh in range(feature_map_height):\n",
    "        features_test.append(feature_map[:, fw, fh, :])\n",
    "\n",
    "np_ft = np.array(features_test)\n",
    "print(np_ft.shape)\n",
    "print(np_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np_fm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np_fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relations = []\n",
    "\n",
    "for feature1 in features:\n",
    "    for feature2 in features:\n",
    "        relations.append(np.concatenate([feature1, feature2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np_r = np.array(relations)\n",
    "np_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
