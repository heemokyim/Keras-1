{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title:  \"레이어 이야기\"\n",
    "author: Taeyoung, Kim\n",
    "date:   2017-01-27 22:07:00\n",
    "categories: Keras\n",
    "comments: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "About Keras models\n",
    "\n",
    "There are two types of models available in Keras: the Sequential model and the Model class used with functional API.\n",
    "\n",
    "These models have a number of methods in common:\n",
    "\n",
    "model.summary(): prints a summary representation of your model.\n",
    "model.get_config(): returns a dictionary containing the configuration of the model. The model can be reinstantiated from its config via:\n",
    "config = model.get_config()\n",
    "model = Model.from_config(config)\n",
    "# or, for Sequential:\n",
    "model = Sequential.from_config(config)\n",
    "model.get_weights(): returns a list of all weight tensors in the model, as Numpy arrays.\n",
    "model.set_weights(weights): sets the values of the weights of the model, from a list of Numpy arrays. The arrays in the list should have the same shape as those returned by get_weights().\n",
    "model.to_json(): returns a representation of the model as a JSON string. Note that the representation does not include the weights, only the architecture. You can reinstantiate the same model (with reinitialized weights) from the JSON string via:\n",
    "from models import model_from_json\n",
    "\n",
    "json_string = model.to_json()\n",
    "model = model_from_json(json_string)\n",
    "model.to_yaml(): returns a representation of the model as a YAML string. Note that the representation does not include the weights, only the architecture. You can reinstantiate the same model (with reinitialized weights) from the YAML string via:\n",
    "from models import model_from_yaml\n",
    "\n",
    "yaml_string = model.to_yaml()\n",
    "model = model_from_yaml(yaml_string)\n",
    "model.save_weights(filepath): saves the weights of the model as a HDF5 file.\n",
    "model.load_weights(filepath, by_name=False): loads the weights of the model from a HDF5 file (created by  save_weights). By default, the architecture is expected to be unchanged. To load weights into a different architecture (with some layers in common), use by_name=True to load only those layers with the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "About Keras layers\n",
    "\n",
    "All Keras layers have a number of methods in common:\n",
    "\n",
    "layer.get_weights(): returns the weights of the layer as a list of Numpy arrays.\n",
    "layer.set_weights(weights): sets the weights of the layer from a list of Numpy arrays (with the same shapes as the output of get_weights).\n",
    "layer.get_config(): returns a dictionary containing the configuration of the layer. The layer can be reinstantiated from its config via:\n",
    "from keras.utils.layer_utils import layer_from_config\n",
    "\n",
    "config = layer.get_config()\n",
    "layer = layer_from_config(config)\n",
    "If a layer has a single node (i.e. if it isn't a shared layer), you can get its input tensor, output tensor, input shape and output shape via:\n",
    "\n",
    "layer.input\n",
    "layer.output\n",
    "layer.input_shape\n",
    "layer.output_shape\n",
    "If the layer has multiple nodes (see: the concept of layer node and shared layers), you can use the following methods:\n",
    "\n",
    "layer.get_input_at(node_index)\n",
    "layer.get_output_at(node_index)\n",
    "layer.get_input_shape_at(node_index)\n",
    "layer.get_output_shape_at(node_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dense\n",
    "\n",
    "keras.layers.core.Dense(output_dim, init='glorot_uniform', activation=None, weights=None, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True, input_dim=None)\n",
    "Just your regular fully connected NN layer.\n",
    "\n",
    "Example\n",
    "\n",
    "# as first layer in a sequential model:\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=16))\n",
    "# now the model will take as input arrays of shape (*, 16)\n",
    "# and output arrays of shape (*, 32)\n",
    "\n",
    "# this is equivalent to the above:\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(16,)))\n",
    "\n",
    "# after the first layer, you don't need to specify\n",
    "# the size of the input anymore:\n",
    "model.add(Dense(32))\n",
    "Arguments\n",
    "\n",
    "output_dim: int > 0.\n",
    "init: name of initialization function for the weights of the layer (see initializations), or alternatively, Theano function to use for weights initialization. This parameter is only relevant if you don't pass a weights argument.\n",
    "activation: name of activation function to use (see activations), or alternatively, elementwise Theano function. If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "weights: list of Numpy arrays to set as initial weights. The list should have 2 elements, of shape (input_dim, output_dim) and (output_dim,) for weights and biases respectively.\n",
    "W_regularizer: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the main weights matrix.\n",
    "b_regularizer: instance of WeightRegularizer, applied to the bias.\n",
    "activity_regularizer: instance of ActivityRegularizer, applied to the network output.\n",
    "W_constraint: instance of the constraints module (eg. maxnorm, nonneg), applied to the main weights matrix.\n",
    "b_constraint: instance of the constraints module, applied to the bias.\n",
    "bias: whether to include a bias (i.e. make the layer affine rather than linear).\n",
    "input_dim: dimensionality of the input (integer). This argument (or alternatively, the keyword argument input_shape) is required when using this layer as the first layer in a model.\n",
    "Input shape\n",
    "\n",
    "nD tensor with shape: (nb_samples, ..., input_dim). The most common situation would be a 2D input with shape (nb_samples, input_dim).\n",
    "\n",
    "Output shape\n",
    "\n",
    "nD tensor with shape: (nb_samples, ..., output_dim). For instance, for a 2D input with shape  (nb_samples, input_dim), the output would have shape (nb_samples, output_dim).\n",
    "\n",
    "[source]\n",
    "\n",
    "Activation\n",
    "\n",
    "keras.layers.core.Activation(activation)\n",
    "Applies an activation function to an output.\n",
    "\n",
    "Arguments\n",
    "\n",
    "activation: name of activation function to use\n",
    "(see: activations), or alternatively, a Theano or TensorFlow operation.\n",
    "Input shape\n",
    "\n",
    "Arbitrary. Use the keyword argument input_shape (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.\n",
    "\n",
    "Output shape\n",
    "\n",
    "Same shape as input.\n",
    "\n",
    "[source]\n",
    "\n",
    "Dropout\n",
    "\n",
    "keras.layers.core.Dropout(p)\n",
    "Applies Dropout to the input. Dropout consists in randomly setting a fraction p of input units to 0 at each update during training time, which helps prevent overfitting.\n",
    "\n",
    "Arguments\n",
    "\n",
    "p: float between 0 and 1. Fraction of the input units to drop.\n",
    "References\n",
    "\n",
    "Dropout: A Simple Way to Prevent Neural Networks from Overfitting\n",
    "[source]\n",
    "\n",
    "Flatten\n",
    "\n",
    "keras.layers.core.Flatten()\n",
    "Flattens the input. Does not affect the batch size.\n",
    "\n",
    "Example\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(64, 3, 3,\n",
    "            border_mode='same',\n",
    "            input_shape=(3, 32, 32)))\n",
    "# now: model.output_shape == (None, 64, 32, 32)\n",
    "\n",
    "model.add(Flatten())\n",
    "# now: model.output_shape == (None, 65536)\n",
    "[source]\n",
    "\n",
    "Reshape\n",
    "\n",
    "keras.layers.core.Reshape(target_shape)\n",
    "Reshapes an output to a certain shape.\n",
    "\n",
    "Arguments\n",
    "\n",
    "target_shape: target shape. Tuple of integers, does not include the samples dimension (batch size).\n",
    "Input shape\n",
    "\n",
    "Arbitrary, although all dimensions in the input shaped must be fixed. Use the keyword argument input_shape (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.\n",
    "\n",
    "Output shape\n",
    "\n",
    "(batch_size,) + target_shape\n",
    "\n",
    "Example\n",
    "\n",
    "# as first layer in a Sequential model\n",
    "model = Sequential()\n",
    "model.add(Reshape((3, 4), input_shape=(12,)))\n",
    "# now: model.output_shape == (None, 3, 4)\n",
    "# note: `None` is the batch dimension\n",
    "\n",
    "# as intermediate layer in a Sequential model\n",
    "model.add(Reshape((6, 2)))\n",
    "# now: model.output_shape == (None, 6, 2)\n",
    "[source]\n",
    "\n",
    "Permute\n",
    "\n",
    "keras.layers.core.Permute(dims)\n",
    "Permutes the dimensions of the input according to a given pattern.\n",
    "\n",
    "Useful for e.g. connecting RNNs and convnets together.\n",
    "\n",
    "Example\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Permute((2, 1), input_shape=(10, 64)))\n",
    "# now: model.output_shape == (None, 64, 10)\n",
    "# note: `None` is the batch dimension\n",
    "Arguments\n",
    "\n",
    "dims: Tuple of integers. Permutation pattern, does not include the samples dimension. Indexing starts at 1. For instance,  (2, 1) permutes the first and second dimension of the input.\n",
    "Input shape\n",
    "\n",
    "Arbitrary. Use the keyword argument input_shape (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.\n",
    "\n",
    "Output shape\n",
    "\n",
    "Same as the input shape, but with the dimensions re-ordered according to the specified pattern.\n",
    "\n",
    "[source]\n",
    "\n",
    "RepeatVector\n",
    "\n",
    "keras.layers.core.RepeatVector(n)\n",
    "Repeats the input n times.\n",
    "\n",
    "Example\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=32))\n",
    "# now: model.output_shape == (None, 32)\n",
    "# note: `None` is the batch dimension\n",
    "\n",
    "model.add(RepeatVector(3))\n",
    "# now: model.output_shape == (None, 3, 32)\n",
    "Arguments\n",
    "\n",
    "n: integer, repetition factor.\n",
    "Input shape\n",
    "\n",
    "2D tensor of shape (nb_samples, features).\n",
    "\n",
    "Output shape\n",
    "\n",
    "3D tensor of shape (nb_samples, n, features).\n",
    "\n",
    "[source]\n",
    "\n",
    "Merge\n",
    "\n",
    "keras.engine.topology.Merge(layers=None, mode='sum', concat_axis=-1, dot_axes=-1, output_shape=None, output_mask=None, arguments=None, node_indices=None, tensor_indices=None, name=None)\n",
    "A Merge layer can be used to merge a list of tensors into a single tensor, following some merge mode.\n",
    "\n",
    "Example\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(32, input_dim=32))\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(32, input_dim=32))\n",
    "\n",
    "merged_model = Sequential()\n",
    "merged_model.add(Merge([model1, model2], mode='concat', concat_axis=1))\n",
    "Arguments\n",
    "\n",
    "layers: Can be a list of Keras tensors or a list of layer instances. Must be more than one layer/tensor.\n",
    "mode: String or lambda/function. If string, must be one\n",
    "of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. If lambda/function, it should take as input a list of tensors and return a single tensor.\n",
    "concat_axis: Integer, axis to use in mode concat.\n",
    "dot_axes: Integer or tuple of integers, axes to use in mode dot or cos.\n",
    "output_shape: Either a shape tuple (tuple of integers), or a lambda/function to compute output_shape (only if merge mode is a lambda/function). If the argument is a tuple, it should be expected output shape, not including the batch size (same convention as the input_shape argument in layers). If the argument is callable, it should take as input a list of shape tuples\n",
    "(1:1 mapping to input tensors) and return a single shape tuple, including the batch size (same convention as the get_output_shape_for method of layers).\n",
    "node_indices: Optional list of integers containing the output node index for each input layer (in case some input layers have multiple output nodes). will default to an array of 0s if not provided.\n",
    "tensor_indices: Optional list of indices of output tensors to consider for merging (in case some input layer node returns multiple tensors).\n",
    "output_mask: Mask or lambda/function to compute the output mask (only if merge mode is a lambda/function). If the latter case, it should take as input a list of masks and return a single mask.\n",
    "[source]\n",
    "\n",
    "Lambda\n",
    "\n",
    "keras.layers.core.Lambda(function, output_shape=None, arguments=None)\n",
    "Used for evaluating an arbitrary Theano / TensorFlow expression on the output of the previous layer.\n",
    "\n",
    "Examples\n",
    "\n",
    "# add a x -> x^2 layer\n",
    "model.add(Lambda(lambda x: x ** 2))\n",
    "# add a layer that returns the concatenation\n",
    "# of the positive part of the input and\n",
    "# the opposite of the negative part\n",
    "\n",
    "def antirectifier(x):\n",
    "    x -= K.mean(x, axis=1, keepdims=True)\n",
    "    x = K.l2_normalize(x, axis=1)\n",
    "    pos = K.relu(x)\n",
    "    neg = K.relu(-x)\n",
    "    return K.concatenate([pos, neg], axis=1)\n",
    "\n",
    "def antirectifier_output_shape(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 2  # only valid for 2D tensors\n",
    "    shape[-1] *= 2\n",
    "    return tuple(shape)\n",
    "\n",
    "model.add(Lambda(antirectifier,\n",
    "         output_shape=antirectifier_output_shape))\n",
    "Arguments\n",
    "\n",
    "function: The function to be evaluated. Takes input tensor as first argument.\n",
    "output_shape: Expected output shape from function. Can be a tuple or function. If a tuple, it only specifies the first dimension onward; sample dimension is assumed either the same as the input: output_shape = (input_shape[0], ) + output_shape or, the input is None and the sample dimension is also None: output_shape = (None, ) + output_shape If a function, it specifies the entire shape as a function of the input shape:  output_shape = f(input_shape)\n",
    "arguments: optional dictionary of keyword arguments to be passed to the function.\n",
    "Input shape\n",
    "\n",
    "Arbitrary. Use the keyword argument input_shape (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.\n",
    "\n",
    "Output shape\n",
    "\n",
    "Specified by output_shape argument.\n",
    "\n",
    "[source]\n",
    "\n",
    "ActivityRegularization\n",
    "\n",
    "keras.layers.core.ActivityRegularization(l1=0.0, l2=0.0)\n",
    "Layer that returns its input unchanged, but applies an update to the cost function based on the activity of the input.\n",
    "\n",
    "Arguments\n",
    "\n",
    "l1: L1 regularization factor (positive float).\n",
    "l2: L2 regularization factor (positive float).\n",
    "Input shape\n",
    "\n",
    "Arbitrary. Use the keyword argument input_shape (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.\n",
    "\n",
    "Output shape\n",
    "\n",
    "Same shape as input.\n",
    "\n",
    "[source]\n",
    "\n",
    "Masking\n",
    "\n",
    "keras.layers.core.Masking(mask_value=0.0)\n",
    "Masks an input sequence by using a mask value to identify timesteps to be skipped.\n",
    "\n",
    "For each timestep in the input tensor (dimension #1 in the tensor), if all values in the input tensor at that timestep are equal to mask_value, then the timestep will masked (skipped) in all downstream layers (as long as they support masking).\n",
    "\n",
    "If any downstream layer does not support masking yet receives such an input mask, an exception will be raised.\n",
    "\n",
    "Example\n",
    "\n",
    "Consider a Numpy data array x of shape (samples, timesteps, features), to be fed to a LSTM layer. You want to mask timestep #3 and #5 because you lack data for these timesteps. You can:\n",
    "\n",
    "set x[:, 3, :] = 0. and x[:, 5, :] = 0.\n",
    "insert a Masking layer with mask_value=0. before the LSTM layer:\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0., input_shape=(timesteps, features)))\n",
    "model.add(LSTM(32))\n",
    "[source]\n",
    "\n",
    "Highway\n",
    "\n",
    "keras.layers.core.Highway(init='glorot_uniform', activation=None, weights=None, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True, input_dim=None)\n",
    "Densely connected highway network, a natural extension of LSTMs to feedforward networks.\n",
    "\n",
    "Arguments\n",
    "\n",
    "init: name of initialization function for the weights of the layer (see initializations), or alternatively, Theano function to use for weights initialization. This parameter is only relevant if you don't pass a weights argument.\n",
    "activation: name of activation function to use (see activations), or alternatively, elementwise Theano function. If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "weights: list of Numpy arrays to set as initial weights. The list should have 2 elements, of shape (input_dim, output_dim) and (output_dim,) for weights and biases respectively.\n",
    "W_regularizer: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the main weights matrix.\n",
    "b_regularizer: instance of WeightRegularizer, applied to the bias.\n",
    "activity_regularizer: instance of ActivityRegularizer, applied to the network output.\n",
    "W_constraint: instance of the constraints module (eg. maxnorm, nonneg), applied to the main weights matrix.\n",
    "b_constraint: instance of the constraints module, applied to the bias.\n",
    "bias: whether to include a bias (i.e. make the layer affine rather than linear).\n",
    "input_dim: dimensionality of the input (integer). This argument (or alternatively, the keyword argument input_shape) is required when using this layer as the first layer in a model.\n",
    "Input shape\n",
    "\n",
    "2D tensor with shape: (nb_samples, input_dim).\n",
    "\n",
    "Output shape\n",
    "\n",
    "2D tensor with shape: (nb_samples, input_dim).\n",
    "\n",
    "References\n",
    "\n",
    "Highway Networks\n",
    "[source]\n",
    "\n",
    "MaxoutDense\n",
    "\n",
    "keras.layers.core.MaxoutDense(output_dim, nb_feature=4, init='glorot_uniform', weights=None, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True, input_dim=None)\n",
    "A dense maxout layer.\n",
    "\n",
    "A MaxoutDense layer takes the element-wise maximum of nb_feature Dense(input_dim, output_dim) linear layers. This allows the layer to learn a convex, piecewise linear activation function over the inputs.\n",
    "\n",
    "Note that this is a linear layer; if you wish to apply activation function (you shouldn't need to --they are universal function approximators), an Activation layer must be added after.\n",
    "\n",
    "Arguments\n",
    "\n",
    "output_dim: int > 0.\n",
    "nb_feature: number of Dense layers to use internally.\n",
    "init: name of initialization function for the weights of the layer (see initializations), or alternatively, Theano function to use for weights initialization. This parameter is only relevant if you don't pass a weights argument.\n",
    "weights: list of Numpy arrays to set as initial weights. The list should have 2 elements, of shape (input_dim, output_dim) and (output_dim,) for weights and biases respectively.\n",
    "W_regularizer: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the main weights matrix.\n",
    "b_regularizer: instance of WeightRegularizer, applied to the bias.\n",
    "activity_regularizer: instance of ActivityRegularizer, applied to the network output.\n",
    "W_constraint: instance of the constraints module (eg. maxnorm, nonneg), applied to the main weights matrix.\n",
    "b_constraint: instance of the constraints module, applied to the bias.\n",
    "bias: whether to include a bias (i.e. make the layer affine rather than linear).\n",
    "input_dim: dimensionality of the input (integer). This argument (or alternatively, the keyword argument input_shape) is required when using this layer as the first layer in a model.\n",
    "Input shape\n",
    "\n",
    "2D tensor with shape: (nb_samples, input_dim).\n",
    "\n",
    "Output shape\n",
    "\n",
    "2D tensor with shape: (nb_samples, output_dim).\n",
    "\n",
    "References\n",
    "\n",
    "Maxout Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Docs » Layers » Convolutional Layers  Edit on GitHub\n",
    "[source]\n",
    "\n",
    "Convolution1D\n",
    "\n",
    "keras.layers.convolutional.Convolution1D(nb_filter, filter_length, init='glorot_uniform', activation=None, weights=None, border_mode='valid', subsample_length=1, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True, input_dim=None, input_length=None)\n",
    "Convolution operator for filtering neighborhoods of one-dimensional inputs. When using this layer as the first layer in a model, either provide the keyword argument input_dim (int, e.g. 128 for sequences of 128-dimensional vectors), or input_shape (tuple of integers, e.g. (10, 128) for sequences of 10 vectors of 128-dimensional vectors).\n",
    "\n",
    "Example\n",
    "\n",
    "# apply a convolution 1d of length 3 to a sequence with 10 timesteps,\n",
    "# with 64 output filters\n",
    "model = Sequential()\n",
    "model.add(Convolution1D(64, 3, border_mode='same', input_shape=(10, 32)))\n",
    "# now model.output_shape == (None, 10, 64)\n",
    "\n",
    "# add a new conv1d on top\n",
    "model.add(Convolution1D(32, 3, border_mode='same'))\n",
    "# now model.output_shape == (None, 10, 32)\n",
    "Arguments\n",
    "\n",
    "nb_filter: Number of convolution kernels to use (dimensionality of the output).\n",
    "filter_length: The extension (spatial or temporal) of each filter.\n",
    "init: name of initialization function for the weights of the layer (see initializations), or alternatively, Theano function to use for weights initialization. This parameter is only relevant if you don't pass a weights argument.\n",
    "activation: name of activation function to use (see activations), or alternatively, elementwise Theano function. If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "weights: list of numpy arrays to set as initial weights.\n",
    "border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)\n",
    "subsample_length: factor by which to subsample output.\n",
    "W_regularizer: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the main weights matrix.\n",
    "b_regularizer: instance of WeightRegularizer, applied to the bias.\n",
    "activity_regularizer: instance of ActivityRegularizer, applied to the network output.\n",
    "W_constraint: instance of the constraints module (eg. maxnorm, nonneg), applied to the main weights matrix.\n",
    "b_constraint: instance of the constraints module, applied to the bias.\n",
    "bias: whether to include a bias (i.e. make the layer affine rather than linear).\n",
    "input_dim: Number of channels/dimensions in the input. Either this argument or the keyword argument input_shapemust be provided when using this layer as the first layer in a model.\n",
    "input_length: Length of input sequences, when it is constant. This argument is required if you are going to connect  Flatten then Dense layers upstream (without it, the shape of the dense outputs cannot be computed).\n",
    "Input shape\n",
    "\n",
    "3D tensor with shape: (samples, steps, input_dim).\n",
    "\n",
    "Output shape\n",
    "\n",
    "3D tensor with shape: (samples, new_steps, nb_filter). steps value might have changed due to padding.\n",
    "\n",
    "[source]\n",
    "\n",
    "AtrousConvolution1D\n",
    "\n",
    "keras.layers.convolutional.AtrousConvolution1D(nb_filter, filter_length, init='glorot_uniform', activation=None, weights=None, border_mode='valid', subsample_length=1, atrous_rate=1, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True)\n",
    "Atrous Convolution operator for filtering neighborhoods of one-dimensional inputs. A.k.a dilated convolution or convolution with holes. When using this layer as the first layer in a model, either provide the keyword argument  input_dim (int, e.g. 128 for sequences of 128-dimensional vectors), or input_shape (tuples of integers, e.g. (10, 128) for sequences of 10 vectors of 128-dimensional vectors).\n",
    "\n",
    "Example\n",
    "\n",
    "# apply an atrous convolution 1d with atrous rate 2 of length 3 to a sequence with 10 timesteps,\n",
    "# with 64 output filters\n",
    "model = Sequential()\n",
    "model.add(AtrousConvolution1D(64, 3, atrous_rate=2, border_mode='same', input_shape=(10, 32)))\n",
    "# now model.output_shape == (None, 10, 64)\n",
    "\n",
    "# add a new atrous conv1d on top\n",
    "model.add(AtrousConvolution1D(32, 3, atrous_rate=2, border_mode='same'))\n",
    "# now model.output_shape == (None, 10, 32)\n",
    "Arguments\n",
    "\n",
    "nb_filter: Number of convolution kernels to use (dimensionality of the output).\n",
    "filter_length: The extension (spatial or temporal) of each filter.\n",
    "init: name of initialization function for the weights of the layer (see initializations), or alternatively, Theano function to use for weights initialization. This parameter is only relevant if you don't pass a weights argument.\n",
    "activation: name of activation function to use (see activations), or alternatively, elementwise Theano function. If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "weights: list of numpy arrays to set as initial weights.\n",
    "border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)\n",
    "subsample_length: factor by which to subsample output.\n",
    "atrous_rate: Factor for kernel dilation. Also called filter_dilation elsewhere.\n",
    "W_regularizer: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the main weights matrix.\n",
    "b_regularizer: instance of WeightRegularizer, applied to the bias.\n",
    "activity_regularizer: instance of ActivityRegularizer, applied to the network output.\n",
    "W_constraint: instance of the constraints module (eg. maxnorm, nonneg), applied to the main weights matrix.\n",
    "b_constraint: instance of the constraints module, applied to the bias.\n",
    "bias: whether to include a bias (i.e. make the layer affine rather than linear).\n",
    "input_dim: Number of channels/dimensions in the input. Either this argument or the keyword argument input_shapemust be provided when using this layer as the first layer in a model.\n",
    "input_length: Length of input sequences, when it is constant. This argument is required if you are going to connect  Flatten then Dense layers upstream (without it, the shape of the dense outputs cannot be computed).\n",
    "Input shape\n",
    "\n",
    "3D tensor with shape: (samples, steps, input_dim).\n",
    "\n",
    "Output shape\n",
    "\n",
    "3D tensor with shape: (samples, new_steps, nb_filter). steps value might have changed due to padding.\n",
    "\n",
    "[source]\n",
    "\n",
    "Convolution2D\n",
    "\n",
    "keras.layers.convolutional.Convolution2D(nb_filter, nb_row, nb_col, init='glorot_uniform', activation=None, weights=None, border_mode='valid', subsample=(1, 1), dim_ordering='default', W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True)\n",
    "Convolution operator for filtering windows of two-dimensional inputs. When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers, does not include the sample axis), e.g.  input_shape=(3, 128, 128) for 128x128 RGB pictures.\n",
    "\n",
    "Examples\n",
    "\n",
    "# apply a 3x3 convolution with 64 output filters on a 256x256 image:\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', input_shape=(3, 256, 256)))\n",
    "# now model.output_shape == (None, 64, 256, 256)\n",
    "\n",
    "# add a 3x3 convolution on top, with 32 output filters:\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='same'))\n",
    "# now model.output_shape == (None, 32, 256, 256)\n",
    "Arguments\n",
    "\n",
    "nb_filter: Number of convolution filters to use.\n",
    "nb_row: Number of rows in the convolution kernel.\n",
    "nb_col: Number of columns in the convolution kernel.\n",
    "init: name of initialization function for the weights of the layer (see initializations), or alternatively, Theano function to use for weights initialization. This parameter is only relevant if you don't pass a weights argument.\n",
    "activation: name of activation function to use (see activations), or alternatively, elementwise Theano function. If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "weights: list of numpy arrays to set as initial weights.\n",
    "border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)\n",
    "subsample: tuple of length 2. Factor by which to subsample output. Also called strides elsewhere.\n",
    "W_regularizer: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the main weights matrix.\n",
    "b_regularizer: instance of WeightRegularizer, applied to the bias.\n",
    "activity_regularizer: instance of ActivityRegularizer, applied to the network output.\n",
    "W_constraint: instance of the constraints module (eg. maxnorm, nonneg), applied to the main weights matrix.\n",
    "b_constraint: instance of the constraints module, applied to the bias.\n",
    "dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension (the depth) is at index 1, in 'tf' mode is it at index 3. It defaults to the image_dim_ordering value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"tf\".\n",
    "bias: whether to include a bias (i.e. make the layer affine rather than linear).\n",
    "Input shape\n",
    "\n",
    "4D tensor with shape: (samples, channels, rows, cols) if dim_ordering='th' or 4D tensor with shape: (samples, rows, cols, channels) if dim_ordering='tf'.\n",
    "\n",
    "Output shape\n",
    "\n",
    "4D tensor with shape: (samples, nb_filter, new_rows, new_cols) if dim_ordering='th' or 4D tensor with shape: (samples, new_rows, new_cols, nb_filter) if dim_ordering='tf'. rows and cols values might have changed due to padding.\n",
    "\n",
    "[source]\n",
    "\n",
    "AtrousConvolution2D\n",
    "\n",
    "keras.layers.convolutional.AtrousConvolution2D(nb_filter, nb_row, nb_col, init='glorot_uniform', activation=None, weights=None, border_mode='valid', subsample=(1, 1), atrous_rate=(1, 1), dim_ordering='default', W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True)\n",
    "Atrous Convolution operator for filtering windows of two-dimensional inputs. A.k.a dilated convolution or convolution with holes. When using this layer as the first layer in a model, provide the keyword argument  input_shape (tuple of integers, does not include the sample axis), e.g. input_shape=(3, 128, 128) for 128x128 RGB pictures.\n",
    "\n",
    "Examples\n",
    "\n",
    "# apply a 3x3 convolution with atrous rate 2x2 and 64 output filters on a 256x256 image:\n",
    "model = Sequential()\n",
    "model.add(AtrousConvolution2D(64, 3, 3, atrous_rate=(2,2), border_mode='valid', input_shape=(3, 256, 256)))\n",
    "# now the actual kernel size is dilated from 3x3 to 5x5 (3+(3-1)*(2-1)=5)\n",
    "# thus model.output_shape == (None, 64, 252, 252)\n",
    "Arguments\n",
    "\n",
    "nb_filter: Number of convolution filters to use.\n",
    "nb_row: Number of rows in the convolution kernel.\n",
    "nb_col: Number of columns in the convolution kernel.\n",
    "init: name of initialization function for the weights of the layer (see initializations), or alternatively, Theano function to use for weights initialization. This parameter is only relevant if you don't pass a weights argument.\n",
    "activation: name of activation function to use (see activations), or alternatively, elementwise Theano function. If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "weights: list of numpy arrays to set as initial weights.\n",
    "border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)\n",
    "subsample: tuple of length 2. Factor by which to subsample output. Also called strides elsewhere.\n",
    "atrous_rate: tuple of length 2. Factor for kernel dilation. Also called filter_dilation elsewhere.\n",
    "W_regularizer: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the main weights matrix.\n",
    "b_regularizer: instance of WeightRegularizer, applied to the bias.\n",
    "activity_regularizer: instance of ActivityRegularizer, applied to the network output.\n",
    "W_constraint: instance of the constraints module (eg. maxnorm, nonneg), applied to the main weights matrix.\n",
    "b_constraint: instance of the constraints module, applied to the bias.\n",
    "dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension (the depth) is at index 1, in 'tf' mode is it at index 3. It defaults to the image_dim_ordering value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"tf\".\n",
    "bias: whether to include a bias (i.e. make the layer affine rather than linear).\n",
    "Input shape\n",
    "\n",
    "4D tensor with shape: (samples, channels, rows, cols) if dim_ordering='th' or 4D tensor with shape: (samples, rows, cols, channels) if dim_ordering='tf'.\n",
    "\n",
    "Output shape\n",
    "\n",
    "4D tensor with shape: (samples, nb_filter, new_rows, new_cols) if dim_ordering='th' or 4D tensor with shape: (samples, new_rows, new_cols, nb_filter) if dim_ordering='tf'. rows and cols values might have changed due to padding.\n",
    "\n",
    "References\n",
    "\n",
    "Multi-Scale Context Aggregation by Dilated Convolutions\n",
    "[source]\n",
    "\n",
    "SeparableConvolution2D\n",
    "\n",
    "keras.layers.convolutional.SeparableConvolution2D(nb_filter, nb_row, nb_col, init='glorot_uniform', activation=None, weights=None, border_mode='valid', subsample=(1, 1), depth_multiplier=1, dim_ordering='default', depthwise_regularizer=None, pointwise_regularizer=None, b_regularizer=None, activity_regularizer=None, depthwise_constraint=None, pointwise_constraint=None, b_constraint=None, bias=True)\n",
    "Separable convolution operator for 2D inputs.\n",
    "\n",
    "Separable convolutions consist in first performing a depthwise spatial convolution (which acts on each input channel separately) followed by a pointwise convolution which mixes together the resulting output channels. The  depth_multiplier argument controls how many output channels are generated per input channel in the depthwise step.\n",
    "\n",
    "Intuitively, separable convolutions can be understood as a way to factorize a convolution kernel into two smaller kernels, or as an extreme version of an Inception block.\n",
    "\n",
    "When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers, does not include the sample axis), e.g. input_shape=(3, 128, 128) for 128x128 RGB pictures.\n",
    "\n",
    "Theano warning\n",
    "\n",
    "This layer is only available with the TensorFlow backend for the time being.\n",
    "\n",
    "Arguments\n",
    "\n",
    "nb_filter: Number of convolution filters to use.\n",
    "nb_row: Number of rows in the convolution kernel.\n",
    "nb_col: Number of columns in the convolution kernel.\n",
    "init: name of initialization function for the weights of the layer (see initializations), or alternatively, Theano function to use for weights initialization. This parameter is only relevant if you don't pass a weights argument.\n",
    "activation: name of activation function to use (see activations), or alternatively, elementwise Theano function. If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "weights: list of numpy arrays to set as initial weights.\n",
    "border_mode: 'valid' or 'same'.\n",
    "subsample: tuple of length 2. Factor by which to subsample output. Also called strides elsewhere.\n",
    "depth_multiplier: how many output channel to use per input channel for the depthwise convolution step.\n",
    "depthwise_regularizer: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the depthwise weights matrix.\n",
    "pointwise_regularizer: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the pointwise weights matrix.\n",
    "b_regularizer: instance of WeightRegularizer, applied to the bias.\n",
    "activity_regularizer: instance of ActivityRegularizer, applied to the network output.\n",
    "depthwise_constraint: instance of the constraints module (eg. maxnorm, nonneg), applied to the depthwise weights matrix.\n",
    "pointwise_constraint: instance of the constraints module (eg. maxnorm, nonneg), applied to the pointwise weights matrix.\n",
    "b_constraint: instance of the constraints module, applied to the bias.\n",
    "dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension (the depth) is at index 1, in 'tf' mode is it at index 3. It defaults to the image_dim_ordering value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"tf\".\n",
    "bias: whether to include a bias (i.e. make the layer affine rather than linear).\n",
    "Input shape\n",
    "\n",
    "4D tensor with shape: (samples, channels, rows, cols) if dim_ordering='th' or 4D tensor with shape: (samples, rows, cols, channels) if dim_ordering='tf'.\n",
    "\n",
    "Output shape\n",
    "\n",
    "4D tensor with shape: (samples, nb_filter, new_rows, new_cols) if dim_ordering='th' or 4D tensor with shape: (samples, new_rows, new_cols, nb_filter) if dim_ordering='tf'. rows and cols values might have changed due to padding.\n",
    "\n",
    "[source]\n",
    "\n",
    "Deconvolution2D\n",
    "\n",
    "keras.layers.convolutional.Deconvolution2D(nb_filter, nb_row, nb_col, output_shape, init='glorot_uniform', activation=None, weights=None, border_mode='valid', subsample=(1, 1), dim_ordering='default', W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True)\n",
    "Transposed convolution operator for filtering windows of two-dimensional inputs. The need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution. [1]\n",
    "\n",
    "When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers, does not include the sample axis), e.g. input_shape=(3, 128, 128) for 128x128 RGB pictures.\n",
    "\n",
    "To pass the correct output_shape to this layer, one could use a test model to predict and observe the actual output shape.\n",
    "\n",
    "Examples\n",
    "\n",
    "# apply a 3x3 transposed convolution with stride 1x1 and 3 output filters on a 12x12 image:\n",
    "model = Sequential()\n",
    "model.add(Deconvolution2D(3, 3, 3, output_shape=(None, 3, 14, 14), border_mode='valid', input_shape=(3, 12, 12)))\n",
    "# Note that you will have to change the output_shape depending on the backend used.\n",
    "\n",
    "# we can predict with the model and print the shape of the array.\n",
    "dummy_input = np.ones((32, 3, 12, 12))\n",
    "# For TensorFlow dummy_input = np.ones((32, 12, 12, 3))\n",
    "preds = model.predict(dummy_input)\n",
    "print(preds.shape)\n",
    "# Theano GPU: (None, 3, 13, 13)\n",
    "# Theano CPU: (None, 3, 14, 14)\n",
    "# TensorFlow: (None, 14, 14, 3)\n",
    "\n",
    "# apply a 3x3 transposed convolution with stride 2x2 and 3 output filters on a 12x12 image:\n",
    "model = Sequential()\n",
    "model.add(Deconvolution2D(3, 3, 3, output_shape=(None, 3, 25, 25), subsample=(2, 2), border_mode='valid', input_shape=(3, 12, 12)))\n",
    "model.summary()\n",
    "\n",
    "# we can predict with the model and print the shape of the array.\n",
    "dummy_input = np.ones((32, 3, 12, 12))\n",
    "# For TensorFlow dummy_input = np.ones((32, 12, 12, 3))\n",
    "preds = model.predict(dummy_input)\n",
    "print(preds.shape)\n",
    "# Theano GPU: (None, 3, 25, 25)\n",
    "# Theano CPU: (None, 3, 25, 25)\n",
    "# TensorFlow: (None, 25, 25, 3)\n",
    "Arguments\n",
    "\n",
    "nb_filter: Number of transposed convolution filters to use.\n",
    "nb_row: Number of rows in the transposed convolution kernel.\n",
    "nb_col: Number of columns in the transposed convolution kernel.\n",
    "output_shape: Output shape of the transposed convolution operation. tuple of integers (nb_samples, nb_filter, nb_output_rows, nb_output_cols) Formula for calculation of the output shape [1], [2]: o = s (i - 1) + a + k - 2p, \\quad a \\in {0, \\ldots, s - 1}\n",
    "where: i - input size (rows or cols), k - kernel size (nb_filter), s - stride (subsample for rows or cols respectively), p - padding size, a - user-specified quantity used to distinguish between the s different possible output sizes. Because a is not specified explicitly and Theano and Tensorflow use different values, it is better to use a dummy input and observe the actual output shape of a layer as specified in the examples.\n",
    "init: name of initialization function for the weights of the layer (see initializations), or alternatively, Theano function to use for weights initialization. This parameter is only relevant if you don't pass a weights argument.\n",
    "activation: name of activation function to use (see activations), or alternatively, elementwise Theano/TensorFlow function. If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "weights: list of numpy arrays to set as initial weights.\n",
    "border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)\n",
    "subsample: tuple of length 2. Factor by which to oversample output. Also called strides elsewhere.\n",
    "W_regularizer: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the main weights matrix.\n",
    "b_regularizer: instance of WeightRegularizer, applied to the bias.\n",
    "activity_regularizer: instance of ActivityRegularizer, applied to the network output.\n",
    "W_constraint: instance of the constraints module (eg. maxnorm, nonneg), applied to the main weights matrix.\n",
    "b_constraint: instance of the constraints module, applied to the bias.\n",
    "dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension (the depth) is at index 1, in 'tf' mode is it at index 3. It defaults to the image_dim_ordering value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"tf\".\n",
    "bias: whether to include a bias (i.e. make the layer affine rather than linear).\n",
    "Input shape\n",
    "\n",
    "4D tensor with shape: (samples, channels, rows, cols) if dim_ordering='th' or 4D tensor with shape: (samples, rows, cols, channels) if dim_ordering='tf'.\n",
    "\n",
    "Output shape\n",
    "\n",
    "4D tensor with shape: (samples, nb_filter, new_rows, new_cols) if dim_ordering='th' or 4D tensor with shape: (samples, new_rows, new_cols, nb_filter) if dim_ordering='tf'. rows and cols values might have changed due to padding.\n",
    "\n",
    "References\n",
    "\n",
    "[1] A guide to convolution arithmetic for deep learning [2] Transposed convolution arithmetic [3] Deconvolutional Networks\n",
    "\n",
    "[source]\n",
    "\n",
    "Convolution3D\n",
    "\n",
    "keras.layers.convolutional.Convolution3D(nb_filter, kernel_dim1, kernel_dim2, kernel_dim3, init='glorot_uniform', activation=None, weights=None, border_mode='valid', subsample=(1, 1, 1), dim_ordering='default', W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True)\n",
    "Convolution operator for filtering windows of three-dimensional inputs. When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers, does not include the sample axis), e.g.  input_shape=(3, 10, 128, 128) for 10 frames of 128x128 RGB pictures.\n",
    "\n",
    "Arguments\n",
    "\n",
    "nb_filter: Number of convolution filters to use.\n",
    "kernel_dim1: Length of the first dimension in the convolution kernel.\n",
    "kernel_dim2: Length of the second dimension in the convolution kernel.\n",
    "kernel_dim3: Length of the third dimension in the convolution kernel.\n",
    "init: name of initialization function for the weights of the layer (see initializations), or alternatively, Theano function to use for weights initialization. This parameter is only relevant if you don't pass a weights argument.\n",
    "activation: name of activation function to use (see activations), or alternatively, elementwise Theano function. If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "weights: list of Numpy arrays to set as initial weights.\n",
    "border_mode: 'valid', 'same' or 'full'. ('full' requires the Theano backend.)\n",
    "subsample: tuple of length 3. Factor by which to subsample output. Also called strides elsewhere.\n",
    "Note: 'subsample' is implemented by slicing the output of conv3d with strides=(1,1,1).\n",
    "W_regularizer: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the main weights matrix.\n",
    "b_regularizer: instance of WeightRegularizer, applied to the bias.\n",
    "activity_regularizer: instance of ActivityRegularizer, applied to the network output.\n",
    "W_constraint: instance of the constraints module (eg. maxnorm, nonneg), applied to the main weights matrix.\n",
    "b_constraint: instance of the constraints module, applied to the bias.\n",
    "dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension (the depth) is at index 1, in 'tf' mode is it at index 4. It defaults to the image_dim_ordering value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"tf\".\n",
    "bias: whether to include a bias (i.e. make the layer affine rather than linear).\n",
    "Input shape\n",
    "\n",
    "5D tensor with shape: (samples, channels, conv_dim1, conv_dim2, conv_dim3) if dim_ordering='th' or 5D tensor with shape: (samples, conv_dim1, conv_dim2, conv_dim3, channels) if dim_ordering='tf'.\n",
    "\n",
    "Output shape\n",
    "\n",
    "5D tensor with shape: (samples, nb_filter, new_conv_dim1, new_conv_dim2, new_conv_dim3) if dim_ordering='th' or 5D tensor with shape: (samples, new_conv_dim1, new_conv_dim2, new_conv_dim3, nb_filter) if dim_ordering='tf'. new_conv_dim1, new_conv_dim2 and new_conv_dim3 values might have changed due to padding.\n",
    "\n",
    "[source]\n",
    "\n",
    "Cropping1D\n",
    "\n",
    "keras.layers.convolutional.Cropping1D(cropping=(1, 1))\n",
    "Cropping layer for 1D input (e.g. temporal sequence). It crops along the time dimension (axis 1).\n",
    "\n",
    "Arguments\n",
    "\n",
    "cropping: tuple of int (length 2) How many units should be trimmed off at the beginning and end of the cropping dimension (axis 1).\n",
    "Input shape\n",
    "\n",
    "3D tensor with shape (samples, axis_to_crop, features)\n",
    "\n",
    "Output shape\n",
    "\n",
    "3D tensor with shape (samples, cropped_axis, features)\n",
    "\n",
    "[source]\n",
    "\n",
    "Cropping2D\n",
    "\n",
    "keras.layers.convolutional.Cropping2D(cropping=((0, 0), (0, 0)), dim_ordering='default')\n",
    "Cropping layer for 2D input (e.g. picture). It crops along spatial dimensions, i.e. width and height.\n",
    "\n",
    "Arguments\n",
    "\n",
    "cropping: tuple of tuple of int (length 2) How many units should be trimmed off at the beginning and end of the 2 cropping dimensions (width, height).\n",
    "dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension (the depth) is at index 1, in 'tf' mode is it at index 3. It defaults to the image_dim_ordering value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"tf\".\n",
    "Input shape\n",
    "\n",
    "4D tensor with shape: (samples, depth, first_axis_to_crop, second_axis_to_crop)\n",
    "\n",
    "Output shape\n",
    "\n",
    "4D tensor with shape: (samples, depth, first_cropped_axis, second_cropped_axis)\n",
    "\n",
    "Examples\n",
    "\n",
    "# Crop the input 2D images or feature maps\n",
    "model = Sequential()\n",
    "model.add(Cropping2D(cropping=((2, 2), (4, 4)), input_shape=(3, 28, 28)))\n",
    "# now model.output_shape == (None, 3, 24, 20)\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same))\n",
    "model.add(Cropping2D(cropping=((2, 2), (2, 2))))\n",
    "# now model.output_shape == (None, 64, 20, 16)\n",
    "\n",
    "[source]\n",
    "\n",
    "Cropping3D\n",
    "\n",
    "keras.layers.convolutional.Cropping3D(cropping=((1, 1), (1, 1), (1, 1)), dim_ordering='default')\n",
    "Cropping layer for 3D data (e.g. spatial or spatio-temporal).\n",
    "\n",
    "Arguments\n",
    "\n",
    "cropping: tuple of tuple of int (length 3) How many units should be trimmed off at the beginning and end of the 3 cropping dimensions (kernel_dim1, kernel_dim2, kernerl_dim3).\n",
    "dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension (the depth) is at index 1, in 'tf' mode is it at index 4. It defaults to the image_dim_ordering value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"tf\".\n",
    "Input shape\n",
    "\n",
    "5D tensor with shape: (samples, depth, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop)\n",
    "\n",
    "Output shape\n",
    "\n",
    "5D tensor with shape: (samples, depth, first_cropped_axis, second_cropped_axis, third_cropped_axis)\n",
    "\n",
    "[source]\n",
    "\n",
    "UpSampling1D\n",
    "\n",
    "keras.layers.convolutional.UpSampling1D(length=2)\n",
    "Repeat each temporal step length times along the time axis.\n",
    "\n",
    "Arguments\n",
    "\n",
    "length: integer. Upsampling factor.\n",
    "Input shape\n",
    "\n",
    "3D tensor with shape: (samples, steps, features).\n",
    "\n",
    "Output shape\n",
    "\n",
    "3D tensor with shape: (samples, upsampled_steps, features).\n",
    "\n",
    "[source]\n",
    "\n",
    "UpSampling2D\n",
    "\n",
    "keras.layers.convolutional.UpSampling2D(size=(2, 2), dim_ordering='default')\n",
    "Repeat the rows and columns of the data by size[0] and size[1] respectively.\n",
    "\n",
    "Arguments\n",
    "\n",
    "size: tuple of 2 integers. The upsampling factors for rows and columns.\n",
    "dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension (the depth) is at index 1, in 'tf' mode is it at index 3. It defaults to the image_dim_ordering value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"tf\".\n",
    "Input shape\n",
    "\n",
    "4D tensor with shape: (samples, channels, rows, cols) if dim_ordering='th' or 4D tensor with shape: (samples, rows, cols, channels) if dim_ordering='tf'.\n",
    "\n",
    "Output shape\n",
    "\n",
    "4D tensor with shape: (samples, channels, upsampled_rows, upsampled_cols) if dim_ordering='th' or 4D tensor with shape: (samples, upsampled_rows, upsampled_cols, channels) if dim_ordering='tf'.\n",
    "\n",
    "[source]\n",
    "\n",
    "UpSampling3D\n",
    "\n",
    "keras.layers.convolutional.UpSampling3D(size=(2, 2, 2), dim_ordering='default')\n",
    "Repeat the first, second and third dimension of the data by size[0], size[1] and size[2] respectively.\n",
    "\n",
    "Arguments\n",
    "\n",
    "size: tuple of 3 integers. The upsampling factors for dim1, dim2 and dim3.\n",
    "dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension (the depth) is at index 1, in 'tf' mode is it at index 4. It defaults to the image_dim_ordering value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"tf\".\n",
    "Input shape\n",
    "\n",
    "5D tensor with shape: (samples, channels, dim1, dim2, dim3) if dim_ordering='th' or 5D tensor with shape: (samples, dim1, dim2, dim3, channels) if dim_ordering='tf'.\n",
    "\n",
    "Output shape\n",
    "\n",
    "5D tensor with shape: (samples, channels, upsampled_dim1, upsampled_dim2, upsampled_dim3) if dim_ordering='th' or 5D tensor with shape: (samples, upsampled_dim1, upsampled_dim2, upsampled_dim3, channels) if dim_ordering='tf'.\n",
    "\n",
    "[source]\n",
    "\n",
    "ZeroPadding1D\n",
    "\n",
    "keras.layers.convolutional.ZeroPadding1D(padding=1)\n",
    "Zero-padding layer for 1D input (e.g. temporal sequence).\n",
    "\n",
    "Arguments\n",
    "\n",
    "padding: int, or tuple of int (length 2), or dictionary.\n",
    "If int: How many zeros to add at the beginning and end of the padding dimension (axis 1).\n",
    "If tuple of int (length 2) How many zeros to add at the beginning and at the end of the padding dimension, in order '(left_pad, right_pad)'.\n",
    "If dictionary: should contain the keys {'left_pad', 'right_pad'}. If any key is missing, default value of 0 will be used for the missing key.\n",
    "Input shape\n",
    "\n",
    "3D tensor with shape (samples, axis_to_pad, features)\n",
    "\n",
    "Output shape\n",
    "\n",
    "3D tensor with shape (samples, padded_axis, features)\n",
    "\n",
    "[source]\n",
    "\n",
    "ZeroPadding2D\n",
    "\n",
    "keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), dim_ordering='default')\n",
    "Zero-padding layer for 2D input (e.g. picture).\n",
    "\n",
    "Arguments\n",
    "\n",
    "padding: tuple of int (length 2), or tuple of int (length 4), or dictionary.\n",
    "If tuple of int (length 2): How many zeros to add at the beginning and end of the 2 padding dimensions (rows and cols).\n",
    "If tuple of int (length 4): How many zeros to add at the beginning and at the end of the 2 padding dimensions (rows and cols), in the order '(top_pad, bottom_pad, left_pad, right_pad)'.\n",
    "If dictionary: should contain the keys {'top_pad', 'bottom_pad', 'left_pad', 'right_pad'}. If any key is missing, default value of 0 will be used for the missing key.\n",
    "dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension (the depth) is at index 1, in 'tf' mode is it at index 3. It defaults to the image_dim_ordering value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"tf\".\n",
    "Input shape\n",
    "\n",
    "4D tensor with shape: (samples, channels, rows, cols) if dim_ordering='th' or 4D tensor with shape: (samples, rows, cols, channels) if dim_ordering='tf'.\n",
    "\n",
    "Output shape\n",
    "\n",
    "4D tensor with shape: (samples, channels, padded_rows, padded_cols) if dim_ordering='th' or 4D tensor with shape: (samples, padded_rows, padded_cols, channels) if dim_ordering='tf'.\n",
    "\n",
    "[source]\n",
    "\n",
    "ZeroPadding3D\n",
    "\n",
    "keras.layers.convolutional.ZeroPadding3D(padding=(1, 1, 1), dim_ordering='default')\n",
    "Zero-padding layer for 3D data (spatial or spatio-temporal).\n",
    "\n",
    "Arguments\n",
    "\n",
    "padding: tuple of int (length 3) How many zeros to add at the beginning and end of the 3 padding dimensions (axis 3, 4 and 5). Currently only symmetric padding is supported.\n",
    "dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension (the depth) is at index 1, in 'tf' mode is it at index 4. It defaults to the image_dim_ordering value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"tf\".\n",
    "Input shape\n",
    "\n",
    "5D tensor with shape: (samples, depth, first_axis_to_pad, second_axis_to_pad, third_axis_to_pad)\n",
    "\n",
    "Output shape\n",
    "\n",
    "5D tensor with shape: (samples, depth, first_padded_axis, second_padded_axis, third_axis_to_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Docs » Layers » Pooling Layers  Edit on GitHub\n",
    "[source]\n",
    "\n",
    "MaxPooling1D\n",
    "\n",
    "keras.layers.pooling.MaxPooling1D(pool_length=2, stride=None, border_mode='valid')\n",
    "Max pooling operation for temporal data.\n",
    "\n",
    "Input shape\n",
    "\n",
    "3D tensor with shape: (samples, steps, features).\n",
    "\n",
    "Output shape\n",
    "\n",
    "3D tensor with shape: (samples, downsampled_steps, features).\n",
    "\n",
    "Arguments\n",
    "\n",
    "pool_length: size of the region to which max pooling is applied\n",
    "stride: integer, or None. factor by which to downscale. 2 will halve the input. If None, it will default to pool_length.\n",
    "border_mode: 'valid' or 'same'.\n",
    "[source]\n",
    "\n",
    "MaxPooling2D\n",
    "\n",
    "keras.layers.pooling.MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='default')\n",
    "Max pooling operation for spatial data.\n",
    "\n",
    "Arguments\n",
    "\n",
    "pool_size: tuple of 2 integers, factors by which to downscale (vertical, horizontal). (2, 2) will halve the image in each dimension.\n",
    "strides: tuple of 2 integers, or None. Strides values. If None, it will default to pool_size.\n",
    "border_mode: 'valid' or 'same'.\n",
    "dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension (the depth) is at index 1, in 'tf' mode is it at index 3. It defaults to the image_dim_ordering value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"tf\".\n",
    "Input shape\n",
    "\n",
    "4D tensor with shape: (samples, channels, rows, cols) if dim_ordering='th' or 4D tensor with shape: (samples, rows, cols, channels) if dim_ordering='tf'.\n",
    "\n",
    "Output shape\n",
    "\n",
    "4D tensor with shape: (nb_samples, channels, pooled_rows, pooled_cols) if dim_ordering='th' or 4D tensor with shape: (samples, pooled_rows, pooled_cols, channels) if dim_ordering='tf'.\n",
    "\n",
    "[source]\n",
    "\n",
    "MaxPooling3D\n",
    "\n",
    "keras.layers.pooling.MaxPooling3D(pool_size=(2, 2, 2), strides=None, border_mode='valid', dim_ordering='default')\n",
    "Max pooling operation for 3D data (spatial or spatio-temporal).\n",
    "\n",
    "Arguments\n",
    "\n",
    "pool_size: tuple of 3 integers, factors by which to downscale (dim1, dim2, dim3). (2, 2, 2) will halve the size of the 3D input in each dimension.\n",
    "strides: tuple of 3 integers, or None. Strides values.\n",
    "border_mode: 'valid' or 'same'.\n",
    "dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension (the depth) is at index 1, in 'tf' mode is it at index 4. It defaults to the image_dim_ordering value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"tf\".\n",
    "Input shape\n",
    "\n",
    "5D tensor with shape: (samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3) if dim_ordering='th' or 5D tensor with shape: (samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels) if dim_ordering='tf'.\n",
    "\n",
    "Output shape\n",
    "\n",
    "5D tensor with shape: (nb_samples, channels, pooled_dim1, pooled_dim2, pooled_dim3) if dim_ordering='th' or 5D tensor with shape: (samples, pooled_dim1, pooled_dim2, pooled_dim3, channels) if dim_ordering='tf'.\n",
    "\n",
    "[source]\n",
    "\n",
    "AveragePooling1D\n",
    "\n",
    "keras.layers.pooling.AveragePooling1D(pool_length=2, stride=None, border_mode='valid')\n",
    "Average pooling for temporal data.\n",
    "\n",
    "Arguments\n",
    "\n",
    "pool_length: factor by which to downscale. 2 will halve the input.\n",
    "stride: integer, or None. Stride value. If None, it will default to pool_length.\n",
    "border_mode: 'valid' or 'same'.\n",
    "Input shape\n",
    "\n",
    "3D tensor with shape: (samples, steps, features).\n",
    "\n",
    "Output shape\n",
    "\n",
    "3D tensor with shape: (samples, downsampled_steps, features).\n",
    "\n",
    "[source]\n",
    "\n",
    "AveragePooling2D\n",
    "\n",
    "keras.layers.pooling.AveragePooling2D(pool_size=(2, 2), strides=None, border_mode='valid', dim_ordering='default')\n",
    "Average pooling operation for spatial data.\n",
    "\n",
    "Arguments\n",
    "\n",
    "pool_size: tuple of 2 integers, factors by which to downscale (vertical, horizontal). (2, 2) will halve the image in each dimension.\n",
    "strides: tuple of 2 integers, or None. Strides values. If None, it will default to pool_size.\n",
    "border_mode: 'valid' or 'same'.\n",
    "dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension (the depth) is at index 1, in 'tf' mode is it at index 3. It defaults to the image_dim_ordering value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"tf\".\n",
    "Input shape\n",
    "\n",
    "4D tensor with shape: (samples, channels, rows, cols) if dim_ordering='th' or 4D tensor with shape: (samples, rows, cols, channels) if dim_ordering='tf'.\n",
    "\n",
    "Output shape\n",
    "\n",
    "4D tensor with shape: (nb_samples, channels, pooled_rows, pooled_cols) if dim_ordering='th' or 4D tensor with shape: (samples, pooled_rows, pooled_cols, channels) if dim_ordering='tf'.\n",
    "\n",
    "[source]\n",
    "\n",
    "AveragePooling3D\n",
    "\n",
    "keras.layers.pooling.AveragePooling3D(pool_size=(2, 2, 2), strides=None, border_mode='valid', dim_ordering='default')\n",
    "Average pooling operation for 3D data (spatial or spatio-temporal).\n",
    "\n",
    "Arguments\n",
    "\n",
    "pool_size: tuple of 3 integers, factors by which to downscale (dim1, dim2, dim3). (2, 2, 2) will halve the size of the 3D input in each dimension.\n",
    "strides: tuple of 3 integers, or None. Strides values.\n",
    "border_mode: 'valid' or 'same'.\n",
    "dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension (the depth) is at index 1, in 'tf' mode is it at index 4. It defaults to the image_dim_ordering value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"tf\".\n",
    "Input shape\n",
    "\n",
    "5D tensor with shape: (samples, channels, len_pool_dim1, len_pool_dim2, len_pool_dim3) if dim_ordering='th' or 5D tensor with shape: (samples, len_pool_dim1, len_pool_dim2, len_pool_dim3, channels) if dim_ordering='tf'.\n",
    "\n",
    "Output shape\n",
    "\n",
    "5D tensor with shape: (nb_samples, channels, pooled_dim1, pooled_dim2, pooled_dim3) if dim_ordering='th' or 5D tensor with shape: (samples, pooled_dim1, pooled_dim2, pooled_dim3, channels) if dim_ordering='tf'.\n",
    "\n",
    "[source]\n",
    "\n",
    "GlobalMaxPooling1D\n",
    "\n",
    "keras.layers.pooling.GlobalMaxPooling1D()\n",
    "Global max pooling operation for temporal data.\n",
    "\n",
    "Input shape\n",
    "\n",
    "3D tensor with shape: (samples, steps, features).\n",
    "\n",
    "Output shape\n",
    "\n",
    "2D tensor with shape: (samples, features).\n",
    "\n",
    "[source]\n",
    "\n",
    "GlobalAveragePooling1D\n",
    "\n",
    "keras.layers.pooling.GlobalAveragePooling1D()\n",
    "Global average pooling operation for temporal data.\n",
    "\n",
    "Input shape\n",
    "\n",
    "3D tensor with shape: (samples, steps, features).\n",
    "\n",
    "Output shape\n",
    "\n",
    "2D tensor with shape: (samples, features).\n",
    "\n",
    "[source]\n",
    "\n",
    "GlobalMaxPooling2D\n",
    "\n",
    "keras.layers.pooling.GlobalMaxPooling2D(dim_ordering='default')\n",
    "Global max pooling operation for spatial data.\n",
    "\n",
    "Arguments\n",
    "\n",
    "dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension (the depth) is at index 1, in 'tf' mode is it at index 3. It defaults to the image_dim_ordering value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"tf\".\n",
    "Input shape\n",
    "\n",
    "4D tensor with shape: (samples, channels, rows, cols) if dim_ordering='th' or 4D tensor with shape: (samples, rows, cols, channels) if dim_ordering='tf'.\n",
    "\n",
    "Output shape\n",
    "\n",
    "2D tensor with shape: (nb_samples, channels)\n",
    "\n",
    "[source]\n",
    "\n",
    "GlobalAveragePooling2D\n",
    "\n",
    "keras.layers.pooling.GlobalAveragePooling2D(dim_ordering='default')\n",
    "Global average pooling operation for spatial data.\n",
    "\n",
    "Arguments\n",
    "\n",
    "dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension (the depth) is at index 1, in 'tf' mode is it at index 3. It defaults to the image_dim_ordering value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"tf\".\n",
    "Input shape\n",
    "\n",
    "4D tensor with shape: (samples, channels, rows, cols) if dim_ordering='th' or 4D tensor with shape: (samples, rows, cols, channels) if dim_ordering='tf'.\n",
    "\n",
    "Output shape\n",
    "\n",
    "2D tensor with shape: (nb_samples, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Docs » Layers » Locally-connected Layers  Edit on GitHub\n",
    "[source]\n",
    "\n",
    "LocallyConnected1D\n",
    "\n",
    "keras.layers.local.LocallyConnected1D(nb_filter, filter_length, init='glorot_uniform', activation=None, weights=None, border_mode='valid', subsample_length=1, W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True, input_dim=None, input_length=None)\n",
    "The LocallyConnected1D layer works similarly to the Convolution1D layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input. When using this layer as the first layer in a model, either provide the keyword argument input_dim (int, e.g. 128 for sequences of 128-dimensional vectors), or input_shape (tuple of integers, e.g. input_shape=(10, 128) for sequences of 10 vectors of 128-dimensional vectors). Also, note that this layer can only be used with a fully-specified input shape (None dimensions not allowed).\n",
    "\n",
    "Example\n",
    "\n",
    "# apply a unshared weight convolution 1d of length 3 to a sequence with\n",
    "# 10 timesteps, with 64 output filters\n",
    "model = Sequential()\n",
    "model.add(LocallyConnected1D(64, 3, input_shape=(10, 32)))\n",
    "# now model.output_shape == (None, 8, 64)\n",
    "# add a new conv1d on top\n",
    "model.add(LocallyConnected1D(32, 3))\n",
    "# now model.output_shape == (None, 6, 32)\n",
    "Arguments\n",
    "\n",
    "nb_filter: Dimensionality of the output.\n",
    "filter_length: The extension (spatial or temporal) of each filter.\n",
    "init: name of initialization function for the weights of the layer (see initializations), or alternatively, Theano function to use for weights initialization. This parameter is only relevant if you don't pass a weights argument.\n",
    "activation: name of activation function to use (see activations), or alternatively, elementwise Theano function. If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "weights: list of numpy arrays to set as initial weights.\n",
    "border_mode: Only support 'valid'. Please make good use of ZeroPadding1D to achieve same output length.\n",
    "subsample_length: factor by which to subsample output.\n",
    "W_regularizer: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the main weights matrix.\n",
    "b_regularizer: instance of WeightRegularizer, applied to the bias.\n",
    "activity_regularizer: instance of ActivityRegularizer, applied to the network output.\n",
    "W_constraint: instance of the constraints module (eg. maxnorm, nonneg), applied to the main weights matrix.\n",
    "b_constraint: instance of the constraints module, applied to the bias.\n",
    "bias: whether to include a bias (i.e. make the layer affine rather than linear).\n",
    "input_dim: Number of channels/dimensions in the input. Either this argument or the keyword argument input_shapemust be provided when using this layer as the first layer in a model.\n",
    "input_length: Length of input sequences, when it is constant. This argument is required if you are going to connect  Flatten then Dense layers upstream (without it, the shape of the dense outputs cannot be computed).\n",
    "Input shape\n",
    "\n",
    "3D tensor with shape: (samples, steps, input_dim).\n",
    "\n",
    "Output shape\n",
    "\n",
    "3D tensor with shape: (samples, new_steps, nb_filter). steps value might have changed due to padding.\n",
    "\n",
    "[source]\n",
    "\n",
    "LocallyConnected2D\n",
    "\n",
    "keras.layers.local.LocallyConnected2D(nb_filter, nb_row, nb_col, init='glorot_uniform', activation=None, weights=None, border_mode='valid', subsample=(1, 1), dim_ordering='default', W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None, bias=True)\n",
    "The LocallyConnected2D layer works similarly to the Convolution2D layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input. When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers, does not include the sample axis), e.g. input_shape=(3, 128, 128) for 128x128 RGB pictures. Also, note that this layer can only be used with a fully-specified input shape (None dimensions not allowed).\n",
    "\n",
    "Examples\n",
    "\n",
    "# apply a 3x3 unshared weights convolution with 64 output filters on a 32x32 image:\n",
    "model = Sequential()\n",
    "model.add(LocallyConnected2D(64, 3, 3, input_shape=(3, 32, 32)))\n",
    "# now model.output_shape == (None, 64, 30, 30)\n",
    "# notice that this layer will consume (30*30)*(3*3*3*64) + (30*30)*64 parameters\n",
    "\n",
    "# add a 3x3 unshared weights convolution on top, with 32 output filters:\n",
    "model.add(LocallyConnected2D(32, 3, 3))\n",
    "# now model.output_shape == (None, 32, 28, 28)\n",
    "Arguments\n",
    "\n",
    "nb_filter: Number of convolution filters to use.\n",
    "nb_row: Number of rows in the convolution kernel.\n",
    "nb_col: Number of columns in the convolution kernel.\n",
    "init: name of initialization function for the weights of the layer (see initializations), or alternatively, Theano function to use for weights initialization. This parameter is only relevant if you don't pass a weights argument.\n",
    "activation: name of activation function to use (see activations), or alternatively, elementwise Theano function. If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
    "weights: list of numpy arrays to set as initial weights.\n",
    "border_mode: Only support 'valid'. Please make good use of ZeroPadding2D to achieve same output shape.\n",
    "subsample: tuple of length 2. Factor by which to subsample output. Also called strides elsewhere.\n",
    "W_regularizer: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the main weights matrix.\n",
    "b_regularizer: instance of WeightRegularizer, applied to the bias.\n",
    "activity_regularizer: instance of ActivityRegularizer, applied to the network output.\n",
    "W_constraint: instance of the constraints module (eg. maxnorm, nonneg), applied to the main weights matrix.\n",
    "b_constraint: instance of the constraints module, applied to the bias.\n",
    "dim_ordering: 'th' or 'tf'. In 'th' mode, the channels dimension (the depth) is at index 1, in 'tf' mode is it at index 3.\n",
    "bias: whether to include a bias (i.e. make the layer affine rather than linear).\n",
    "Input shape\n",
    "\n",
    "4D tensor with shape: (samples, channels, rows, cols) if dim_ordering='th' or 4D tensor with shape: (samples, rows, cols, channels) if dim_ordering='tf'.\n",
    "\n",
    "Output shape\n",
    "\n",
    "4D tensor with shape: (samples, nb_filter, new_rows, new_cols) if dim_ordering='th' or 4D tensor with shape: (samples, new_rows, new_cols, nb_filter) if dim_ordering='tf'. rows and cols values might have changed due to padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Docs » Layers » Recurrent Layers  Edit on GitHub\n",
    "[source]\n",
    "\n",
    "Recurrent\n",
    "\n",
    "keras.layers.recurrent.Recurrent(weights=None, return_sequences=False, go_backwards=False, stateful=False, unroll=False, consume_less='cpu', input_dim=None, input_length=None)\n",
    "Abstract base class for recurrent layers. Do not use in a model -- it's not a valid layer! Use its children classes LSTM,  GRU and SimpleRNN instead.\n",
    "\n",
    "All recurrent layers (LSTM, GRU, SimpleRNN) also follow the specifications of this class and accept the keyword arguments listed below.\n",
    "\n",
    "Example\n",
    "\n",
    "# as the first layer in a Sequential model\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(10, 64)))\n",
    "# now model.output_shape == (None, 32)\n",
    "# note: `None` is the batch dimension.\n",
    "\n",
    "# the following is identical:\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_dim=64, input_length=10))\n",
    "\n",
    "# for subsequent layers, not need to specify the input size:\n",
    "model.add(LSTM(16))\n",
    "Arguments\n",
    "\n",
    "weights: list of Numpy arrays to set as initial weights. The list should have 3 elements, of shapes: [(input_dim, output_dim), (output_dim, output_dim), (output_dim,)].\n",
    "return_sequences: Boolean. Whether to return the last output in the output sequence, or the full sequence.\n",
    "go_backwards: Boolean (default False). If True, process the input sequence backwards.\n",
    "stateful: Boolean (default False). If True, the last state for each sample at index i in a batch will be used as initial state for the sample of index i in the following batch.\n",
    "unroll: Boolean (default False). If True, the network will be unrolled, else a symbolic loop will be used. When using TensorFlow, the network is always unrolled, so this argument does not do anything. Unrolling can speed-up a RNN, although it tends to be more memory-intensive. Unrolling is only suitable for short sequences.\n",
    "consume_less: one of \"cpu\", \"mem\", or \"gpu\" (LSTM/GRU only). If set to \"cpu\", the RNN will use an implementation that uses fewer, larger matrix products, thus running faster on CPU but consuming more memory. If set to \"mem\", the RNN will use more matrix products, but smaller ones, thus running slower (may actually be faster on GPU) while consuming less memory. If set to \"gpu\" (LSTM/GRU only), the RNN will combine the input gate, the forget gate and the output gate into a single matrix, enabling more time-efficient parallelization on the GPU. Note: RNN dropout must be shared for all gates, resulting in a slightly reduced regularization.\n",
    "input_dim: dimensionality of the input (integer). This argument (or alternatively, the keyword argument input_shape) is required when using this layer as the first layer in a model.\n",
    "input_length: Length of input sequences, to be specified when it is constant. This argument is required if you are going to connect  Flatten then Dense layers upstream (without it, the shape of the dense outputs cannot be computed). Note that if the recurrent layer is not the first layer in your model, you would need to specify the input length at the level of the first layer (e.g. via the input_shape argument)\n",
    "Input shape\n",
    "\n",
    "3D tensor with shape (nb_samples, timesteps, input_dim).\n",
    "\n",
    "Output shape\n",
    "\n",
    "if return_sequences: 3D tensor with shape  (nb_samples, timesteps, output_dim).\n",
    "else, 2D tensor with shape (nb_samples, output_dim).\n",
    "Masking\n",
    "\n",
    "This layer supports masking for input data with a variable number of timesteps. To introduce masks to your data, use an Embedding layer with the mask_zero parameter set to True.\n",
    "\n",
    "Note on performance\n",
    "\n",
    "You are likely to see better performance with RNNs in Theano compared to TensorFlow. Additionally, when using TensorFlow, it is often preferable to set unroll=True for better performance.\n",
    "\n",
    "Note on using statefulness in RNNs\n",
    "\n",
    "You can set RNN layers to be 'stateful', which means that the states computed for the samples in one batch will be reused as initial states for the samples in the next batch. This assumes a one-to-one mapping between samples in different successive batches.\n",
    "\n",
    "To enable statefulness: - specify stateful=True in the layer constructor. - specify a fixed batch size for your model, by passing if sequential model: a batch_input_shape=(...) to the first layer in your model. else for functional model with 1 or more Input layers: a batch_shape=(...) to all the first layers in your model. This is the expected shape of your inputs including the batch size. It should be a tuple of integers, e.g. (32, 10, 100).\n",
    "\n",
    "To reset the states of your model, call .reset_states() on either a specific layer, or on your entire model.\n",
    "\n",
    "[source]\n",
    "\n",
    "SimpleRNN\n",
    "\n",
    "keras.layers.recurrent.SimpleRNN(output_dim, init='glorot_uniform', inner_init='orthogonal', activation='tanh', W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)\n",
    "Fully-connected RNN where the output is to be fed back to input.\n",
    "\n",
    "Arguments\n",
    "\n",
    "output_dim: dimension of the internal projections and the final output.\n",
    "init: weight initialization function. Can be the name of an existing function (str), or a Theano function (see: initializations).\n",
    "inner_init: initialization function of the inner cells.\n",
    "activation: activation function. Can be the name of an existing function (str), or a Theano function (see: activations).\n",
    "W_regularizer: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the input weights matrices.\n",
    "U_regularizer: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the recurrent weights matrices.\n",
    "b_regularizer: instance of WeightRegularizer, applied to the bias.\n",
    "dropout_W: float between 0 and 1. Fraction of the input units to drop for input gates.\n",
    "dropout_U: float between 0 and 1. Fraction of the input units to drop for recurrent connections.\n",
    "References\n",
    "\n",
    "A Theoretically Grounded Application of Dropout in Recurrent Neural Networks\n",
    "[source]\n",
    "\n",
    "GRU\n",
    "\n",
    "keras.layers.recurrent.GRU(output_dim, init='glorot_uniform', inner_init='orthogonal', activation='tanh', inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)\n",
    "Gated Recurrent Unit - Cho et al. 2014.\n",
    "\n",
    "Arguments\n",
    "\n",
    "output_dim: dimension of the internal projections and the final output.\n",
    "init: weight initialization function. Can be the name of an existing function (str), or a Theano function (see: initializations).\n",
    "inner_init: initialization function of the inner cells.\n",
    "activation: activation function. Can be the name of an existing function (str), or a Theano function (see: activations).\n",
    "inner_activation: activation function for the inner cells.\n",
    "W_regularizer: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the input weights matrices.\n",
    "U_regularizer: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the recurrent weights matrices.\n",
    "b_regularizer: instance of WeightRegularizer, applied to the bias.\n",
    "dropout_W: float between 0 and 1. Fraction of the input units to drop for input gates.\n",
    "dropout_U: float between 0 and 1. Fraction of the input units to drop for recurrent connections.\n",
    "References\n",
    "\n",
    "On the Properties of Neural Machine Translation: Encoder-Decoder Approaches\n",
    "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling\n",
    "A Theoretically Grounded Application of Dropout in Recurrent Neural Networks\n",
    "[source]\n",
    "\n",
    "LSTM\n",
    "\n",
    "keras.layers.recurrent.LSTM(output_dim, init='glorot_uniform', inner_init='orthogonal', forget_bias_init='one', activation='tanh', inner_activation='hard_sigmoid', W_regularizer=None, U_regularizer=None, b_regularizer=None, dropout_W=0.0, dropout_U=0.0)\n",
    "Long-Short Term Memory unit - Hochreiter 1997.\n",
    "\n",
    "For a step-by-step description of the algorithm, see this tutorial.\n",
    "\n",
    "Arguments\n",
    "\n",
    "output_dim: dimension of the internal projections and the final output.\n",
    "init: weight initialization function. Can be the name of an existing function (str), or a Theano function (see: initializations).\n",
    "inner_init: initialization function of the inner cells.\n",
    "forget_bias_init: initialization function for the bias of the forget gate. Jozefowicz et al. recommend initializing with ones.\n",
    "activation: activation function. Can be the name of an existing function (str), or a Theano function (see: activations).\n",
    "inner_activation: activation function for the inner cells.\n",
    "W_regularizer: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the input weights matrices.\n",
    "U_regularizer: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the recurrent weights matrices.\n",
    "b_regularizer: instance of WeightRegularizer, applied to the bias.\n",
    "dropout_W: float between 0 and 1. Fraction of the input units to drop for input gates.\n",
    "dropout_U: float between 0 and 1. Fraction of the input units to drop for recurrent connections.\n",
    "References\n",
    "\n",
    "Long short-term memory (original 1997 paper)\n",
    "Learning to forget: Continual prediction with LSTM\n",
    "Supervised sequence labeling with recurrent neural networks\n",
    "A Theoretically Grounded Application of Dropout in Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Docs » Layers » Embedding Layers  Edit on GitHub\n",
    "[source]\n",
    "\n",
    "Embedding\n",
    "\n",
    "keras.layers.embeddings.Embedding(input_dim, output_dim, init='uniform', input_length=None, W_regularizer=None, activity_regularizer=None, W_constraint=None, mask_zero=False, weights=None, dropout=0.0)\n",
    "Turn positive integers (indexes) into dense vectors of fixed size. eg. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]\n",
    "\n",
    "This layer can only be used as the first layer in a model.\n",
    "\n",
    "Example\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(1000, 64, input_length=10))\n",
    "  # the model will take as input an integer matrix of size (batch, input_length).\n",
    "  # the largest integer (i.e. word index) in the input should be no larger than 999 (vocabulary size).\n",
    "  # now model.output_shape == (None, 10, 64), where None is the batch dimension.\n",
    "\n",
    "  input_array = np.random.randint(1000, size=(32, 10))\n",
    "\n",
    "  model.compile('rmsprop', 'mse')\n",
    "  output_array = model.predict(input_array)\n",
    "  assert output_array.shape == (32, 10, 64)\n",
    "Arguments\n",
    "\n",
    "input_dim: int > 0. Size of the vocabulary, ie. 1 + maximum integer index occurring in the input data.\n",
    "output_dim: int >= 0. Dimension of the dense embedding.\n",
    "init: name of initialization function for the weights of the layer (see: initializations), or alternatively, Theano function to use for weights initialization. This parameter is only relevant if you don't pass a weights argument.\n",
    "weights: list of Numpy arrays to set as initial weights. The list should have 1 element, of shape (input_dim, output_dim).\n",
    "W_regularizer: instance of the regularizers module (eg. L1 or L2 regularization), applied to the embedding matrix.\n",
    "W_constraint: instance of the constraints module (eg. maxnorm, nonneg), applied to the embedding matrix.\n",
    "mask_zero: Whether or not the input value 0 is a special \"padding\" value that should be masked out. This is useful for recurrent layers which may take variable length input. If this is True then all subsequent layers in the model need to support masking or an exception will be raised. If mask_zero is set to True, as a consequence, index 0 cannot be used in the vocabulary (input_dim should equal |vocabulary| + 2).\n",
    "input_length: Length of input sequences, when it is constant. This argument is required if you are going to connect  Flatten then Dense layers upstream (without it, the shape of the dense outputs cannot be computed).\n",
    "dropout: float between 0 and 1. Fraction of the embeddings to drop.\n",
    "Input shape\n",
    "\n",
    "2D tensor with shape: (nb_samples, sequence_length).\n",
    "\n",
    "Output shape\n",
    "\n",
    "3D tensor with shape: (nb_samples, sequence_length, output_dim).\n",
    "\n",
    "References\n",
    "\n",
    "A Theoretically Grounded Application of Dropout in Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Docs » Layers » Advanced Activations Layers  Edit on GitHub\n",
    "[source]\n",
    "\n",
    "LeakyReLU\n",
    "\n",
    "keras.layers.advanced_activations.LeakyReLU(alpha=0.3)\n",
    "Special version of a Rectified Linear Unit that allows a small gradient when the unit is not active: f(x) = alpha * x for x < 0, f(x) = x for x >= 0.\n",
    "\n",
    "Input shape\n",
    "\n",
    "Arbitrary. Use the keyword argument input_shape (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.\n",
    "\n",
    "Output shape\n",
    "\n",
    "Same shape as the input.\n",
    "\n",
    "Arguments\n",
    "\n",
    "alpha: float >= 0. Negative slope coefficient.\n",
    "[source]\n",
    "\n",
    "PReLU\n",
    "\n",
    "keras.layers.advanced_activations.PReLU(init='zero', weights=None, shared_axes=None)\n",
    "Parametric Rectified Linear Unit: f(x) = alphas * x for x < 0, f(x) = x for x >= 0, where alphas is a learned array with the same shape as x.\n",
    "\n",
    "Input shape\n",
    "\n",
    "Arbitrary. Use the keyword argument input_shape (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.\n",
    "\n",
    "Output shape\n",
    "\n",
    "Same shape as the input.\n",
    "\n",
    "Arguments\n",
    "\n",
    "init: initialization function for the weights.\n",
    "weights: initial weights, as a list of a single Numpy array.\n",
    "shared_axes: the axes along which to share learnable parameters for the activation function. For example, if the incoming feature maps are from a 2D convolution with output shape (batch, height, width, channels), and you wish to share parameters across space so that each filter only has one set of parameters, set shared_axes=[1, 2].\n",
    "References\n",
    "\n",
    "Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\n",
    "[source]\n",
    "\n",
    "ELU\n",
    "\n",
    "keras.layers.advanced_activations.ELU(alpha=1.0)\n",
    "Exponential Linear Unit: f(x) =  alpha * (exp(x) - 1.) for x < 0, f(x) = x for x >= 0.\n",
    "\n",
    "Input shape\n",
    "\n",
    "Arbitrary. Use the keyword argument input_shape (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.\n",
    "\n",
    "Output shape\n",
    "\n",
    "Same shape as the input.\n",
    "\n",
    "Arguments\n",
    "\n",
    "alpha: scale for the negative factor.\n",
    "References\n",
    "\n",
    "Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)\n",
    "[source]\n",
    "\n",
    "ParametricSoftplus\n",
    "\n",
    "keras.layers.advanced_activations.ParametricSoftplus(alpha_init=0.2, beta_init=5.0, weights=None, shared_axes=None)\n",
    "Parametric Softplus: alpha * log(1 + exp(beta * x))\n",
    "\n",
    "Input shape\n",
    "\n",
    "Arbitrary. Use the keyword argument input_shape (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.\n",
    "\n",
    "Output shape\n",
    "\n",
    "Same shape as the input.\n",
    "\n",
    "Arguments\n",
    "\n",
    "alpha_init: float. Initial value of the alpha weights.\n",
    "beta_init: float. Initial values of the beta weights.\n",
    "weights: initial weights, as a list of 2 numpy arrays.\n",
    "shared_axes: the axes along which to share learnable parameters for the activation function. For example, if the incoming feature maps are from a 2D convolution with output shape (batch, height, width, channels), and you wish to share parameters across space so that each filter only has one set of parameters, set shared_axes=[1, 2].\n",
    "References\n",
    "\n",
    "Inferring Nonlinear Neuronal Computation Based on Physiologically Plausible Inputs\n",
    "[source]\n",
    "\n",
    "ThresholdedReLU\n",
    "\n",
    "keras.layers.advanced_activations.ThresholdedReLU(theta=1.0)\n",
    "Thresholded Rectified Linear Unit: f(x) = x for x > theta f(x) = 0 otherwise.\n",
    "\n",
    "Input shape\n",
    "\n",
    "Arbitrary. Use the keyword argument input_shape (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.\n",
    "\n",
    "Output shape\n",
    "\n",
    "Same shape as the input.\n",
    "\n",
    "Arguments\n",
    "\n",
    "theta: float >= 0. Threshold location of activation.\n",
    "References\n",
    "\n",
    "Zero-Bias Autoencoders and the Benefits of Co-Adapting Features\n",
    "[source]\n",
    "\n",
    "SReLU\n",
    "\n",
    "keras.layers.advanced_activations.SReLU(t_left_init='zero', a_left_init='glorot_uniform', t_right_init='glorot_uniform', a_right_init='one', shared_axes=None)\n",
    "S-shaped Rectified Linear Unit.\n",
    "\n",
    "Input shape\n",
    "\n",
    "Arbitrary. Use the keyword argument input_shape (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.\n",
    "\n",
    "Output shape\n",
    "\n",
    "Same shape as the input.\n",
    "\n",
    "Arguments\n",
    "\n",
    "t_left_init: initialization function for the left part intercept\n",
    "a_left_init: initialization function for the left part slope\n",
    "t_right_init: initialization function for the right part intercept\n",
    "a_right_init: initialization function for the right part slope\n",
    "shared_axes: the axes along which to share learnable parameters for the activation function. For example, if the incoming feature maps are from a 2D convolution with output shape (batch, height, width, channels), and you wish to share parameters across space so that each filter only has one set of parameters, set shared_axes=[1, 2].\n",
    "References\n",
    "\n",
    "Deep Learning with S-shaped Rectified Linear Activation Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Docs » Layers » Normalization Layers  Edit on GitHub\n",
    "[source]\n",
    "\n",
    "BatchNormalization\n",
    "\n",
    "keras.layers.normalization.BatchNormalization(epsilon=0.001, mode=0, axis=-1, momentum=0.99, weights=None, beta_init='zero', gamma_init='one', gamma_regularizer=None, beta_regularizer=None)\n",
    "Normalize the activations of the previous layer at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1.\n",
    "\n",
    "Arguments\n",
    "\n",
    "epsilon: small float > 0. Fuzz parameter. Theano expects epsilon >= 1e-5.\n",
    "mode: integer, 0, 1 or 2.\n",
    "0: feature-wise normalization. Each feature map in the input will be normalized separately. The axis on which to normalize is specified by the axis argument. Note that if the input is a 4D image tensor using Theano conventions (samples, channels, rows, cols) then you should set axis to 1 to normalize along the channels axis. During training we use per-batch statistics to normalize the data, and during testing we use running averages computed during the training phase.\n",
    "1: sample-wise normalization. This mode assumes a 2D input.\n",
    "2: feature-wise normalization, like mode 0, but using per-batch statistics to normalize the data during both testing and training.\n",
    "axis: integer, axis along which to normalize in mode 0. For instance, if your input tensor has shape (samples, channels, rows, cols), set axis to 1 to normalize per feature map (channels axis).\n",
    "momentum: momentum in the computation of the exponential average of the mean and standard deviation of the data, for feature-wise normalization.\n",
    "weights: Initialization weights. List of 2 Numpy arrays, with shapes:  [(input_shape,), (input_shape,)] Note that the order of this list is [gamma, beta, mean, std]\n",
    "beta_init: name of initialization function for shift parameter (see initializations), or alternatively, Theano/TensorFlow function to use for weights initialization. This parameter is only relevant if you don't pass a weights argument.\n",
    "gamma_init: name of initialization function for scale parameter (see initializations), or alternatively, Theano/TensorFlow function to use for weights initialization. This parameter is only relevant if you don't pass a weights argument.\n",
    "gamma_regularizer: instance of WeightRegularizer (eg. L1 or L2 regularization), applied to the gamma vector.\n",
    "beta_regularizer: instance of WeightRegularizer, applied to the beta vector.\n",
    "Input shape\n",
    "\n",
    "Arbitrary. Use the keyword argument input_shape (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.\n",
    "\n",
    "Output shape\n",
    "\n",
    "Same shape as input.\n",
    "\n",
    "References\n",
    "\n",
    "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
