{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title:  \"텐서플로우, 티아노, 케라스 오프라인 설치 (주피터 포함)\"\n",
    "author: Taeyoung, Kim\n",
    "date:   2017-03-11 12:00:00\n",
    "categories: Lecture\n",
    "comments: true\n",
    "image: http://tykimos.github.com/Keras/warehouse/2017-3-15_Keras_Offline_Install_1.png\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본 강좌에서는 텐서플로우, 티아노, 케라스를 오프라인으로 설치를 해보겠습니다. 파이썬 기반의 패키지들은 온라인에서 쉽게 설치가 가능하나 오프라인에서는 설치가 조금 까다롭습니다. 망분리된 서버나 워크스테이션에서 딥러닝 모델을 사용하려면 오프라인 설치가 필요합니다. 크게 다음과 같은 과정으로 설치를 해보겠습니다. \n",
    "\n",
    "1. 설치 파일 다운로드\n",
    "1. 설치 환경 정리\n",
    "1. 비주얼 스튜디어 설치\n",
    "1. 아나콘다 설치\n",
    "1. 텐서플로우(Tensorflow) 설치\n",
    "1. 티아노(Theano) 설치\n",
    "1. 케라스(Keras) 설치\n",
    "1. CUDA 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 설치 파일 다운로드\n",
    "\n",
    "설치하고자 하는 환경에 해당하는 파일을 다운로드 받습니다. 고용량이라 파일 다운로드 링크는 아래 댓글 창에 이메일이나 연락처를 남겨주시면 보내드리도록 하겠습니다. \n",
    "\n",
    "* 원도우 7 64비트 환경 : tf_th_keras_cpu_gpu_win7_x64.zip (약 6GB)\n",
    "\n",
    "압축 파일을 풀면 아래와 같은 폴더 및 파일들이 있습니다.\n",
    "\n",
    "* Anaconda3-4.2.0-Windows-x86_64.exe\n",
    "* cuda_8.0.61_windows.exe\n",
    "* cudatools_4.0.17_win_64.msi\n",
    "* cudnn-8.0-windows7-x64-v5.0-ga.zip\n",
    "* [폴더] Keras\n",
    "* [폴더] packages\n",
    "* requirements.txt\n",
    "* Theano\n",
    "* vs2015.com_enu.iso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 설치 환경 정리\n",
    "\n",
    "기존에 설치된 프로그램과 충돌이 날 수 있으므로 설치를 하기 전에 기존 프로그램을 삭제합니다. \n",
    "\n",
    "#### Anaconda 2 삭제\n",
    "\n",
    "* Anaconda 2가 설치되어 있다면 Anaconda 2를 삭제합니다.\n",
    "* 제어판 > 프로그램 및 기능(또는 프로그램 추가/제거)에서 python 2.7.13(Anaconda 4.3.0 64-bit)을 선택하여 삭제할 수 있습니다.\n",
    "\n",
    "#### python 삭제\n",
    "\n",
    "* Anaconda이외의 다른 파이썬이 설치되어 있다면 삭제합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Visual studio community 2015 설치\n",
    "\n",
    "1. vs2015.com_enu.iso 파일을 실행시켜 Visaul studio 2015를 설치합니다. iso 파일을 수 있어야 합니다.\n",
    "\n",
    "2. 설치가 완료되면 아래 두 개 항목이 시스템 변수로 잘 설정되어 있는 지 확인합니다. '제어판 > 시스템 > 고급 시스템 설정 > 고급 > 환경 변수'의 메뉴로 확인할 수 있습니다. 만약 없을 경우 추가합니다. \n",
    "    * Path : C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\bin\n",
    "    * VS140COMNTOOLS : C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools\\\n",
    "\n",
    "\n",
    "\n",
    "3. Anaconda 3 설치\n",
    "- CD#2의 설치파일(Anaconda3-4.2.0-Windows-x86_64.exe)을 실행시켜 Anaconda 3을 설치\n",
    "- 사용자는 all user로 선택하고, 모든 항목을 check 한 후 설치 진행\n",
    "- 설치가 완료되면 시스템 변수 Path에서 아래 세 개의 경로가 추가되어있는지 확인(없으면 추가)\n",
    "C:\\Program Files\\Anaconda3\n",
    "C:\\Program Files\\Anaconda3\\Scripts\n",
    "C:\\Program Files\\Anaconda3\\Library\\bin\n",
    "4. 파이썬 패키지 설치\n",
    "- CD#2의 packages 폴더와 requirements.txt 파일을 로컬에 복사한 후, packages폴더의 상위\n",
    "폴더에서 CMD 창을 실행\n",
    "- CMD 창에서 다음과 같이 명령어를 입력하여 패키지를 설치\n",
    "pip install --no-index --find-links=./packages -r requirements.txt\n",
    "- Theano 폴더의 상위 폴더에서 CMD를 실행시켜 다음과 같이 명령어를 실행\n",
    "cd Theano\n",
    "python setup.py install\n",
    "- keras 폴더의 상위 폴더에서 CMD를 실행시켜 다음과 같이 명령어를 실행\n",
    "cd keras\n",
    "python setup.py install\n",
    "- CMD 창에서 다음과 같이 실행하여 정상적으로 설치된 것을 확인\n",
    "python [Enter]\n",
    "import keras [Enter]\n",
    "- “Using Theano backend.” 또는 “Using Tensorflow backend.”라는 문구가 출력되면 정상적으로\n",
    "설치된 것\n",
    "** pydot, find_graphviz() 에러가 발생하면 설치되어 있는 keras, theano를 (pip uninstall keras\n",
    "theano) 로 삭제한 후 다시 설치 (pip install --no-index --find-links=./packages keras theano)\n",
    "5. Tensorflow 설치\n",
    "- CD#2의 packages폴더의 상위 폴더에서 CMD 창을 실행\n",
    "- CPU만 사용할 경우, 다음과 같이 명령어 실행\n",
    "pip install --no-index --find-links=./packages tensorflow\n",
    "- GPU를 사용할 경우,\n",
    "pip install --no-index --find-links=./packages tensorflow-gpu\n",
    "- CMD 창에서 다음과 같이 실행하여 정상적으로 설치된 것을 확인\n",
    "python [Enter]\n",
    "import tensorflow as tf [Enter]\n",
    "hello = tf.constant(‘Hello, Tensorflow’) [Enter]\n",
    "sess = tf.Session() [Enter]\n",
    "print(sess.run(hello)) [Enter]\n",
    "- “Hello, Tensorflow”라는 문구가 출력되면 정상적으로 설치된 것\n",
    "======= 이후 절차는 GPU를 사용하는 경우에만 진행할 것 =======\n",
    "6. CUDA 설치\n",
    "- CD#2의 설치파일(cuda_8.0.61_windows.exe)을 실행시켜 CUDA를 설치\n",
    "- CD#2의 설치파일(cudatools_4.0.17_win_64.msi)을 실행시켜 CUDA toolkit 설치\n",
    "7. cuDNN 설치\n",
    "- CD#2의 파일(cudnn-8.0-windows7-x64-v5.0-ga.zip)을 압축 해제함\n",
    "- 아래 그림과 같이 파일을 복사/붙여넣기 함(아래 그림의 cudnn-7.5를 cudnn-8.0으로 가정)\n",
    "- 설치가 완료되면 시스템 변수 Path에서 아래 경로가 추가되어있는지 확인(없으면 추가)\n",
    "C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\bin\n",
    "C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\libnvvp\n",
    "\n",
    "케라스에서는 이미지 파일을 쉽게 학습시킬 수 있도록 ImageDataGenerator 클래스를 제공합니다. ImageDataGenerator 클래스는 데이터 증강 (data augmentation)을 위해 막강한 기능을 제공하는 데, 이 기능들은 다른 강좌에세 다루기로 하고, 본 강좌에서는 특정 폴더에 이미지를 분류 해놓았을 때 이를 학습시키기 위한 데이터셋으로 만들어주는 기능을 사용해보겠습니다.\n",
    "\n",
    "먼저 ImageDataGenerator 클래스를 이용하여 객체를 생성한 뒤 flow_from_directory() 함수를 호출하여 제네레이터(generator)를 생성합니다. flow_from_directory() 함수의 주요인자는 다음과 같습니다.\n",
    "\n",
    "- 첫번재 인자 : 이미지 경로를 지정합니다.\n",
    "- target_size : 패치 이미지 크기를 지정합니다. 폴더에 있는 원본 이미지 크기가 다르더라도 target_size에 지정된 크기로 자동 조절됩니다.\n",
    "- batch_size : 배치 크기를 지정합니다.\n",
    "- class_mode : 분류 방식에 대해서 지정합니다.\n",
    "    - categorical : 2D one-hot 부호화된 라벨이 반환됩니다.\n",
    "    - binary : 1D 이진 라벨이 반환됩니다.\n",
    "    - sparse : 1D 정수 라벨이 반환됩니다.\n",
    "    - None : 라벨이 반환되지 않습니다.\n",
    "\n",
    "본 예제에서는 패치 이미지 크기를 24 x 24로 하였으니 target_size도 (24, 24)로 셋팅하였습니다. 훈련 데이터 수가 클래스당 15개이니 배치 크기를 3으로 지정하여 총 5번 배치를 수행하면 하나의 epoch가 수행될 수 있도록 하였습니다. 다중 클래스 문제이므로 class_mode는 'categorical'로 지정하였습니다. 그리고 제네레이터는 훈련용과 검증용으로 두 개를 만들었습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RuntimeError: TensorBoard callback only works with the TensorFlow backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 images belonging to 3 classes.\n",
      "Found 15 images belonging to 3 classes.\n",
      "INFO:tensorflow:Summary name convolution2d_1_W:0 is illegal; using convolution2d_1_W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "INFO:tensorflow:Summary name convolution2d_1_W:0 is illegal; using convolution2d_1_W_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_1_W:0 is illegal; using convolution2d_1_W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_1_W:0 is illegal; using convolution2d_1_W_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_1_b:0 is illegal; using convolution2d_1_b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_1_b:0 is illegal; using convolution2d_1_b_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_1_b:0 is illegal; using convolution2d_1_b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_1_b:0 is illegal; using convolution2d_1_b_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_2_W:0 is illegal; using convolution2d_2_W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_2_W:0 is illegal; using convolution2d_2_W_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_2_W:0 is illegal; using convolution2d_2_W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_2_W:0 is illegal; using convolution2d_2_W_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_2_b:0 is illegal; using convolution2d_2_b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_2_b:0 is illegal; using convolution2d_2_b_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_2_b:0 is illegal; using convolution2d_2_b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_2_b:0 is illegal; using convolution2d_2_b_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_3_W:0 is illegal; using convolution2d_3_W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_3_W:0 is illegal; using convolution2d_3_W_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_3_W:0 is illegal; using convolution2d_3_W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_3_W:0 is illegal; using convolution2d_3_W_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_3_b:0 is illegal; using convolution2d_3_b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_3_b:0 is illegal; using convolution2d_3_b_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_3_b:0 is illegal; using convolution2d_3_b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_3_b:0 is illegal; using convolution2d_3_b_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_1_W:0 is illegal; using dense_1_W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_1_W:0 is illegal; using dense_1_W_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_1_W:0 is illegal; using dense_1_W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_1_W:0 is illegal; using dense_1_W_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_1_b:0 is illegal; using dense_1_b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_1_b:0 is illegal; using dense_1_b_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_1_b:0 is illegal; using dense_1_b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_1_b:0 is illegal; using dense_1_b_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_2_W:0 is illegal; using dense_2_W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_2_W:0 is illegal; using dense_2_W_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_2_W:0 is illegal; using dense_2_W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_2_W:0 is illegal; using dense_2_W_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_2_b:0 is illegal; using dense_2_b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_2_b:0 is illegal; using dense_2_b_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_2_b:0 is illegal; using dense_2_b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_2_b:0 is illegal; using dense_2_b_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "45/45 [==============================] - 0s - loss: 8.5139 - acc: 0.3778 - val_loss: 7.7609 - val_acc: 0.4000\n",
      "Epoch 2/200\n",
      "45/45 [==============================] - 0s - loss: 7.5305 - acc: 0.4444 - val_loss: 6.6558 - val_acc: 0.4667\n",
      "Epoch 3/200\n",
      "45/45 [==============================] - 0s - loss: 5.5426 - acc: 0.6000 - val_loss: 5.6512 - val_acc: 0.5333\n",
      "Epoch 4/200\n",
      "45/45 [==============================] - 0s - loss: 5.4888 - acc: 0.6000 - val_loss: 5.7667 - val_acc: 0.5333\n",
      "Epoch 5/200\n",
      "45/45 [==============================] - 0s - loss: 5.1460 - acc: 0.6222 - val_loss: 5.2414 - val_acc: 0.3333\n",
      "Epoch 6/200\n",
      "45/45 [==============================] - 0s - loss: 2.1311 - acc: 0.4222 - val_loss: 1.6423 - val_acc: 0.2000\n",
      "Epoch 7/200\n",
      "45/45 [==============================] - 0s - loss: 1.0828 - acc: 0.3556 - val_loss: 1.1054 - val_acc: 0.2667\n",
      "Epoch 8/200\n",
      "45/45 [==============================] - 0s - loss: 1.0840 - acc: 0.3556 - val_loss: 1.0991 - val_acc: 0.3333\n",
      "Epoch 9/200\n",
      "45/45 [==============================] - 0s - loss: 1.0881 - acc: 0.3556 - val_loss: 1.0991 - val_acc: 0.3333\n",
      "Epoch 10/200\n",
      "45/45 [==============================] - 0s - loss: 1.0758 - acc: 0.3556 - val_loss: 1.0991 - val_acc: 0.3333\n",
      "Epoch 11/200\n",
      "45/45 [==============================] - 0s - loss: 1.0631 - acc: 0.3778 - val_loss: 1.0990 - val_acc: 0.3333\n",
      "Epoch 12/200\n",
      "45/45 [==============================] - 0s - loss: 1.0571 - acc: 0.3778 - val_loss: 1.0989 - val_acc: 0.3333\n",
      "Epoch 13/200\n",
      "45/45 [==============================] - 0s - loss: 1.0761 - acc: 0.3778 - val_loss: 1.0985 - val_acc: 0.3333\n",
      "Epoch 14/200\n",
      "45/45 [==============================] - 0s - loss: 1.0767 - acc: 0.3556 - val_loss: 1.0991 - val_acc: 0.3333\n",
      "Epoch 15/200\n",
      "45/45 [==============================] - 0s - loss: 1.0992 - acc: 0.3333 - val_loss: 1.0990 - val_acc: 0.3333\n",
      "Epoch 16/200\n",
      "45/45 [==============================] - 0s - loss: 1.0992 - acc: 0.3333 - val_loss: 1.0990 - val_acc: 0.3333\n",
      "Epoch 17/200\n",
      "45/45 [==============================] - 0s - loss: 1.0991 - acc: 0.3333 - val_loss: 1.0990 - val_acc: 0.3333\n",
      "Epoch 18/200\n",
      "45/45 [==============================] - 0s - loss: 1.0991 - acc: 0.3333 - val_loss: 1.0990 - val_acc: 0.3333\n",
      "Epoch 19/200\n",
      "45/45 [==============================] - 0s - loss: 1.0991 - acc: 0.3333 - val_loss: 1.0990 - val_acc: 0.3333\n",
      "Epoch 20/200\n",
      "45/45 [==============================] - 0s - loss: 1.0991 - acc: 0.3333 - val_loss: 1.0990 - val_acc: 0.3333\n",
      "Epoch 21/200\n",
      "45/45 [==============================] - 0s - loss: 1.0991 - acc: 0.3333 - val_loss: 1.0990 - val_acc: 0.3333\n",
      "Epoch 22/200\n",
      "45/45 [==============================] - 0s - loss: 1.0991 - acc: 0.3333 - val_loss: 1.0990 - val_acc: 0.3333\n",
      "Epoch 23/200\n",
      "45/45 [==============================] - 0s - loss: 1.0991 - acc: 0.3333 - val_loss: 1.0989 - val_acc: 0.3333\n",
      "Epoch 24/200\n",
      "45/45 [==============================] - 0s - loss: 1.0991 - acc: 0.3333 - val_loss: 1.0989 - val_acc: 0.3333\n",
      "Epoch 25/200\n",
      "45/45 [==============================] - 0s - loss: 1.0990 - acc: 0.3333 - val_loss: 1.0989 - val_acc: 0.3333\n",
      "Epoch 26/200\n",
      "45/45 [==============================] - 0s - loss: 1.0990 - acc: 0.3333 - val_loss: 1.0989 - val_acc: 0.3333\n",
      "Epoch 27/200\n",
      "45/45 [==============================] - 0s - loss: 1.0990 - acc: 0.3333 - val_loss: 1.0989 - val_acc: 0.3333\n",
      "Epoch 28/200\n",
      "45/45 [==============================] - 0s - loss: 1.0990 - acc: 0.3333 - val_loss: 1.0989 - val_acc: 0.3333\n",
      "Epoch 29/200\n",
      "45/45 [==============================] - 0s - loss: 1.0990 - acc: 0.3333 - val_loss: 1.0989 - val_acc: 0.3333\n",
      "Epoch 30/200\n",
      "45/45 [==============================] - 0s - loss: 1.0990 - acc: 0.3333 - val_loss: 1.0989 - val_acc: 0.3333\n",
      "Epoch 31/200\n",
      "45/45 [==============================] - 0s - loss: 1.0990 - acc: 0.3333 - val_loss: 1.0989 - val_acc: 0.3333\n",
      "Epoch 32/200\n",
      "45/45 [==============================] - 0s - loss: 1.0990 - acc: 0.3333 - val_loss: 1.0989 - val_acc: 0.3333\n",
      "Epoch 33/200\n",
      "45/45 [==============================] - 0s - loss: 1.0990 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 34/200\n",
      "45/45 [==============================] - 0s - loss: 1.0990 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 35/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 36/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 37/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 38/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 39/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 40/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 41/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 42/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 43/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 44/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 45/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 46/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 47/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 48/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 49/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 50/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 51/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 52/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 53/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 54/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 55/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 56/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 57/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 58/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 59/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 60/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 61/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 62/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 63/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 64/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 65/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 66/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 67/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 68/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 69/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 70/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 71/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 72/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 73/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 74/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 75/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 76/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 77/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 78/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 79/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 80/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 81/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 82/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 83/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 84/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 85/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 86/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 87/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 88/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 89/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 90/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 91/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 92/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 93/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 94/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 95/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 96/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 97/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 98/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 99/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 100/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 101/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 102/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 103/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 104/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 105/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 106/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 107/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 108/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 109/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 110/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 111/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 112/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 113/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 114/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 115/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 116/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 117/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 118/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 119/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 120/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 121/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 122/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 123/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 124/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 125/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 126/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 127/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 128/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 129/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 130/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 131/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 132/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 133/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 134/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 135/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 136/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 137/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 138/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 139/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 140/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 141/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 142/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 143/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 144/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 145/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 146/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 147/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 148/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 149/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 150/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 151/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 152/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 153/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 154/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 155/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 156/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 157/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 158/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 159/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 160/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 161/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 162/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 163/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 164/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 165/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 166/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 167/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 168/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 169/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 170/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 171/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 172/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 173/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 174/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 175/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 176/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 177/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 178/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 179/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 180/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 181/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 182/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 183/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 184/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 185/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 186/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 187/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 188/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 189/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 190/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 191/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 192/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 193/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 194/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 195/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 196/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 197/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 198/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 199/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 200/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "-- Evaluate --\n",
      "acc: 33.33%\n",
      "-- Predict --\n",
      "[[0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 랜덤시드 고정시키기\n",
    "np.random.seed(5)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 데이터셋 불러오기\n",
    "train_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'warehouse/handwriting_shape/train',\n",
    "        target_size=(24, 24),\n",
    "        batch_size=3,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'warehouse/handwriting_shape/validation',\n",
    "        target_size=(24, 24),    \n",
    "        batch_size=3,\n",
    "        class_mode='categorical')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "\n",
    "# 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(12, 3, 3, border_mode='same', input_shape=(3, 24, 24), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(2, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(3, 2, 2, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# 텐서보드 연동하기\n",
    "tensorboard_callback = TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True, write_images=True)\n",
    "\n",
    "# 모델 학습시키기\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=45,\n",
    "        nb_epoch=200,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=15,\n",
    "        callbacks=[tensorboard_callback])\n",
    "\n",
    "# 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "\n",
    "scores = model.evaluate_generator(\n",
    "            validation_generator, \n",
    "            val_samples = 15)\n",
    "\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# 모델 예측하기\n",
    "print(\"-- Predict --\")\n",
    "\n",
    "output = model.predict_generator(\n",
    "            validation_generator, \n",
    "            val_samples = 15)\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 결론\n",
    "\n",
    "본 강좌에서는 이미지 분류 문제를 직접 정의해보고 데이터셋도 직접 만들어봤습니다. 이미지 분류 문제에 높은 성능을 보이고 있는 컨볼루션 신경망 모델을 이용하여 직접 만든 데이터셋으로 학습 및 평가를 해보았습니다. 학습 결과는 좋게 나왔지만 이 모델은 한 사람이 그린 것에 대해서만 학습이 되어 있어서 다른 사람에 그린 모양은 잘 분류를 못할 것 같습니다. 이후 강좌에서는 다른 사람이 그린 모양으로 평가해보고 어떻게 모델 성능을 높일 수 있을 지 알아보겠습니다.\n",
    "\n",
    "그리고 실제 문제에 적용하기 전에 데이터셋을 직접 만들어보거나 좀 더 쉬운 문제로 추상화해서 프로토타이핑 하시는 것을 권장드립니다. 객담도말된 결핵 이미지 판별하는 모델을 만들 때, 결핵 이미지를 바로 사용하지 않고, MNIST의 손글씨 중 '1'과 '7'을 결핵이라고 보고, 나머지는 결핵이 아닌 것으로 학습시켜봤었습니다. 결핵균이 간균 (막대모양)이라 적절한 프로토타이핑이었습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "### 같이 보기\n",
    "\n",
    "* [강좌 목차](https://tykimos.github.io/Keras/2017/01/27/Keras_Lecture_Plan/)\n",
    "* 이전 : [딥러닝 모델 이야기/컨볼루션 신경망 레이어 이야기](https://tykimos.github.io/Keras/2017/01/27/CNN_Layer_Talk/)\n",
    "* 다음 : [딥러닝 모델 이야기/순환 신경망 레이어 이야기]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
