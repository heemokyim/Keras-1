{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title:  \"텐서보드 사용해보기\"\n",
    "author: Taeyoung, Kim\n",
    "date:   2017-03-11 12:00:00\n",
    "categories: Keras\n",
    "comments: true\n",
    "image: http://tykimos.github.com/Keras/warehouse/2017-3-8_CNN_Getting_Started_4.png\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본 강좌에서는 텐서보드(TensorBoard)를 사용해서 학습 과정을 시각화하는 방법에 대해서 알아보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 학습 과정을 시각화하는 이유\n",
    "\n",
    "학습 과정을 시각화하면 .... 볼 수 있어서 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 케라스 전용 시각화 툴\n",
    "\n",
    "손으로 그린 삼각형, 사각형, 원 이미지를 만들기 위해서는 여러가지 방법이 있을 수 있겠네요. 테블릿을 이용할 수도 있고, 종이에 그려서 사진으로 찍을 수도 있습니다. 저는 그림 그리는 툴을 이용해서 만들어봤습니다. 이미지 사이즈는 24 x 24 정도로 해봤습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 텐서보드(TensorBoard)란\n",
    "\n",
    "케라스에서는 이미지 파일을 쉽게 학습시킬 수 있도록 ImageDataGenerator 클래스를 제공합니다. ImageDataGenerator 클래스는 데이터 증강 (data augmentation)을 위해 막강한 기능을 제공하는 데, 이 기능들은 다른 강좌에세 다루기로 하고, 본 강좌에서는 특정 폴더에 이미지를 분류 해놓았을 때 이를 학습시키기 위한 데이터셋으로 만들어주는 기능을 사용해보겠습니다.\n",
    "\n",
    "먼저 ImageDataGenerator 클래스를 이용하여 객체를 생성한 뒤 flow_from_directory() 함수를 호출하여 제네레이터(generator)를 생성합니다. flow_from_directory() 함수의 주요인자는 다음과 같습니다.\n",
    "\n",
    "- 첫번재 인자 : 이미지 경로를 지정합니다.\n",
    "- target_size : 패치 이미지 크기를 지정합니다. 폴더에 있는 원본 이미지 크기가 다르더라도 target_size에 지정된 크기로 자동 조절됩니다.\n",
    "- batch_size : 배치 크기를 지정합니다.\n",
    "- class_mode : 분류 방식에 대해서 지정합니다.\n",
    "    - categorical : 2D one-hot 부호화된 라벨이 반환됩니다.\n",
    "    - binary : 1D 이진 라벨이 반환됩니다.\n",
    "    - sparse : 1D 정수 라벨이 반환됩니다.\n",
    "    - None : 라벨이 반환되지 않습니다.\n",
    "\n",
    "본 예제에서는 패치 이미지 크기를 24 x 24로 하였으니 target_size도 (24, 24)로 셋팅하였습니다. 훈련 데이터 수가 클래스당 15개이니 배치 크기를 3으로 지정하여 총 5번 배치를 수행하면 하나의 epoch가 수행될 수 있도록 하였습니다. 다중 클래스 문제이므로 class_mode는 'categorical'로 지정하였습니다. 그리고 제네레이터는 훈련용과 검증용으로 두 개를 만들었습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 케라스와 텐서보드를 연동하는 법\n",
    "\n",
    "Tensorboard basic visualizations.\n",
    "\n",
    "    keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)\n",
    "\n",
    "This callback writes a log for TensorBoard, which allows you to visualize dynamic graphs of your training and test metrics, as well as activation histograms for the different layers in your model.\n",
    "\n",
    "TensorBoard is a visualization tool provided with TensorFlow.\n",
    "\n",
    "If you have installed TensorFlow with pip, you should be able to launch TensorBoard from the command line:\n",
    "\n",
    "tensorboard --logdir=/full_path_to_your_logs\n",
    "You can find more information about TensorBoard - __here.\n",
    "\n",
    "Arguments\n",
    "\n",
    "* log_dir : the path of the directory where to save the log files to be parsed by Tensorboard\n",
    "* histogram_freq: frequency (in epochs) at which to compute activation histograms for the layers of the model. If set to 0, histograms won't be computed.\n",
    "* write_graph: whether to visualize the graph in Tensorboard. The log file can become quite large when write_graph is set to True.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RuntimeError: TensorBoard callback only works with the TensorFlow backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 images belonging to 3 classes.\n",
      "Found 15 images belonging to 3 classes.\n",
      "INFO:tensorflow:Summary name convolution2d_1_W:0 is illegal; using convolution2d_1_W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "INFO:tensorflow:Summary name convolution2d_1_W:0 is illegal; using convolution2d_1_W_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_1_W:0 is illegal; using convolution2d_1_W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_1_W:0 is illegal; using convolution2d_1_W_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_1_b:0 is illegal; using convolution2d_1_b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_1_b:0 is illegal; using convolution2d_1_b_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_1_b:0 is illegal; using convolution2d_1_b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_1_b:0 is illegal; using convolution2d_1_b_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_2_W:0 is illegal; using convolution2d_2_W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_2_W:0 is illegal; using convolution2d_2_W_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_2_W:0 is illegal; using convolution2d_2_W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_2_W:0 is illegal; using convolution2d_2_W_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_2_b:0 is illegal; using convolution2d_2_b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_2_b:0 is illegal; using convolution2d_2_b_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_2_b:0 is illegal; using convolution2d_2_b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_2_b:0 is illegal; using convolution2d_2_b_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_3_W:0 is illegal; using convolution2d_3_W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_3_W:0 is illegal; using convolution2d_3_W_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_3_W:0 is illegal; using convolution2d_3_W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_3_W:0 is illegal; using convolution2d_3_W_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_3_b:0 is illegal; using convolution2d_3_b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_3_b:0 is illegal; using convolution2d_3_b_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_3_b:0 is illegal; using convolution2d_3_b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name convolution2d_3_b:0 is illegal; using convolution2d_3_b_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_1_W:0 is illegal; using dense_1_W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_1_W:0 is illegal; using dense_1_W_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_1_W:0 is illegal; using dense_1_W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_1_W:0 is illegal; using dense_1_W_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_1_b:0 is illegal; using dense_1_b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_1_b:0 is illegal; using dense_1_b_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_1_b:0 is illegal; using dense_1_b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_1_b:0 is illegal; using dense_1_b_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_2_W:0 is illegal; using dense_2_W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_2_W:0 is illegal; using dense_2_W_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_2_W:0 is illegal; using dense_2_W_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_2_W:0 is illegal; using dense_2_W_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_2_b:0 is illegal; using dense_2_b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_2_b:0 is illegal; using dense_2_b_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_2_b:0 is illegal; using dense_2_b_0 instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dense_2_b:0 is illegal; using dense_2_b_0 instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "45/45 [==============================] - 0s - loss: 8.5139 - acc: 0.3778 - val_loss: 7.7609 - val_acc: 0.4000\n",
      "Epoch 2/200\n",
      "45/45 [==============================] - 0s - loss: 7.5305 - acc: 0.4444 - val_loss: 6.6558 - val_acc: 0.4667\n",
      "Epoch 3/200\n",
      "45/45 [==============================] - 0s - loss: 5.5426 - acc: 0.6000 - val_loss: 5.6512 - val_acc: 0.5333\n",
      "Epoch 4/200\n",
      "45/45 [==============================] - 0s - loss: 5.4888 - acc: 0.6000 - val_loss: 5.7667 - val_acc: 0.5333\n",
      "Epoch 5/200\n",
      "45/45 [==============================] - 0s - loss: 5.1460 - acc: 0.6222 - val_loss: 5.2414 - val_acc: 0.3333\n",
      "Epoch 6/200\n",
      "45/45 [==============================] - 0s - loss: 2.1311 - acc: 0.4222 - val_loss: 1.6423 - val_acc: 0.2000\n",
      "Epoch 7/200\n",
      "45/45 [==============================] - 0s - loss: 1.0828 - acc: 0.3556 - val_loss: 1.1054 - val_acc: 0.2667\n",
      "Epoch 8/200\n",
      "45/45 [==============================] - 0s - loss: 1.0840 - acc: 0.3556 - val_loss: 1.0991 - val_acc: 0.3333\n",
      "Epoch 9/200\n",
      "45/45 [==============================] - 0s - loss: 1.0881 - acc: 0.3556 - val_loss: 1.0991 - val_acc: 0.3333\n",
      "Epoch 10/200\n",
      "45/45 [==============================] - 0s - loss: 1.0758 - acc: 0.3556 - val_loss: 1.0991 - val_acc: 0.3333\n",
      "Epoch 11/200\n",
      "45/45 [==============================] - 0s - loss: 1.0631 - acc: 0.3778 - val_loss: 1.0990 - val_acc: 0.3333\n",
      "Epoch 12/200\n",
      "45/45 [==============================] - 0s - loss: 1.0571 - acc: 0.3778 - val_loss: 1.0989 - val_acc: 0.3333\n",
      "Epoch 13/200\n",
      "45/45 [==============================] - 0s - loss: 1.0761 - acc: 0.3778 - val_loss: 1.0985 - val_acc: 0.3333\n",
      "Epoch 14/200\n",
      "45/45 [==============================] - 0s - loss: 1.0767 - acc: 0.3556 - val_loss: 1.0991 - val_acc: 0.3333\n",
      "Epoch 15/200\n",
      "45/45 [==============================] - 0s - loss: 1.0992 - acc: 0.3333 - val_loss: 1.0990 - val_acc: 0.3333\n",
      "Epoch 16/200\n",
      "45/45 [==============================] - 0s - loss: 1.0992 - acc: 0.3333 - val_loss: 1.0990 - val_acc: 0.3333\n",
      "Epoch 17/200\n",
      "45/45 [==============================] - 0s - loss: 1.0991 - acc: 0.3333 - val_loss: 1.0990 - val_acc: 0.3333\n",
      "Epoch 18/200\n",
      "45/45 [==============================] - 0s - loss: 1.0991 - acc: 0.3333 - val_loss: 1.0990 - val_acc: 0.3333\n",
      "Epoch 19/200\n",
      "45/45 [==============================] - 0s - loss: 1.0991 - acc: 0.3333 - val_loss: 1.0990 - val_acc: 0.3333\n",
      "Epoch 20/200\n",
      "45/45 [==============================] - 0s - loss: 1.0991 - acc: 0.3333 - val_loss: 1.0990 - val_acc: 0.3333\n",
      "Epoch 21/200\n",
      "45/45 [==============================] - 0s - loss: 1.0991 - acc: 0.3333 - val_loss: 1.0990 - val_acc: 0.3333\n",
      "Epoch 22/200\n",
      "45/45 [==============================] - 0s - loss: 1.0991 - acc: 0.3333 - val_loss: 1.0990 - val_acc: 0.3333\n",
      "Epoch 23/200\n",
      "45/45 [==============================] - 0s - loss: 1.0991 - acc: 0.3333 - val_loss: 1.0989 - val_acc: 0.3333\n",
      "Epoch 24/200\n",
      "45/45 [==============================] - 0s - loss: 1.0991 - acc: 0.3333 - val_loss: 1.0989 - val_acc: 0.3333\n",
      "Epoch 25/200\n",
      "45/45 [==============================] - 0s - loss: 1.0990 - acc: 0.3333 - val_loss: 1.0989 - val_acc: 0.3333\n",
      "Epoch 26/200\n",
      "45/45 [==============================] - 0s - loss: 1.0990 - acc: 0.3333 - val_loss: 1.0989 - val_acc: 0.3333\n",
      "Epoch 27/200\n",
      "45/45 [==============================] - 0s - loss: 1.0990 - acc: 0.3333 - val_loss: 1.0989 - val_acc: 0.3333\n",
      "Epoch 28/200\n",
      "45/45 [==============================] - 0s - loss: 1.0990 - acc: 0.3333 - val_loss: 1.0989 - val_acc: 0.3333\n",
      "Epoch 29/200\n",
      "45/45 [==============================] - 0s - loss: 1.0990 - acc: 0.3333 - val_loss: 1.0989 - val_acc: 0.3333\n",
      "Epoch 30/200\n",
      "45/45 [==============================] - 0s - loss: 1.0990 - acc: 0.3333 - val_loss: 1.0989 - val_acc: 0.3333\n",
      "Epoch 31/200\n",
      "45/45 [==============================] - 0s - loss: 1.0990 - acc: 0.3333 - val_loss: 1.0989 - val_acc: 0.3333\n",
      "Epoch 32/200\n",
      "45/45 [==============================] - 0s - loss: 1.0990 - acc: 0.3333 - val_loss: 1.0989 - val_acc: 0.3333\n",
      "Epoch 33/200\n",
      "45/45 [==============================] - 0s - loss: 1.0990 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 34/200\n",
      "45/45 [==============================] - 0s - loss: 1.0990 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 35/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 36/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 37/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 38/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 39/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 40/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 41/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 42/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 43/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 44/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 45/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 46/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 47/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 48/200\n",
      "45/45 [==============================] - 0s - loss: 1.0989 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 49/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0988 - val_acc: 0.3333\n",
      "Epoch 50/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 51/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 52/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 53/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 54/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 55/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 56/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 57/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 58/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 59/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 60/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 61/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 62/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 63/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 64/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 65/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 66/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 67/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 68/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 69/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 70/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 71/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 72/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 73/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 74/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 75/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 76/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 77/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 78/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 79/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 80/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 81/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 82/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 83/200\n",
      "45/45 [==============================] - 0s - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 84/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 85/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 86/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 87/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 88/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 89/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3333\n",
      "Epoch 90/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 91/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 92/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 93/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 94/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 95/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 96/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 97/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 98/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 99/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 100/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 101/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 102/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 103/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 104/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 105/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 106/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 107/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 108/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 109/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 110/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 111/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 112/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 113/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 114/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 115/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 116/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 117/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 118/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 119/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 120/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 121/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 122/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 123/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 124/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 125/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 126/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 127/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 128/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 129/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 130/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 131/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 132/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 133/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 134/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 135/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 136/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 137/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 138/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 139/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 140/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 141/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 142/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 143/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 144/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 145/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 146/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 147/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 148/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 149/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 150/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 151/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 152/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 153/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 154/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 155/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 156/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 157/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 158/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 159/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 160/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 161/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 162/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 163/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 164/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 165/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 166/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 167/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 168/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 169/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 170/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 171/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 172/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 173/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 174/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 175/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 176/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 177/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 178/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 179/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 180/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 181/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 182/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 183/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 184/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 185/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 186/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 187/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 188/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 189/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 190/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 191/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 192/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 193/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 194/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 195/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 196/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 197/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 198/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 199/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "Epoch 200/200\n",
      "45/45 [==============================] - 0s - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n",
      "-- Evaluate --\n",
      "acc: 33.33%\n",
      "-- Predict --\n",
      "[[0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]\n",
      " [0.333 0.333 0.334]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 랜덤시드 고정시키기\n",
    "np.random.seed(5)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 데이터셋 불러오기\n",
    "train_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'warehouse/handwriting_shape/train',\n",
    "        target_size=(24, 24),\n",
    "        batch_size=3,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'warehouse/handwriting_shape/validation',\n",
    "        target_size=(24, 24),    \n",
    "        batch_size=3,\n",
    "        class_mode='categorical')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "\n",
    "# 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(12, 3, 3, border_mode='same', input_shape=(3, 24, 24), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(2, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(3, 2, 2, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# 텐서보드 연동하기\n",
    "tensorboard_callback = TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True, write_images=True)\n",
    "\n",
    "# 모델 학습시키기\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=45,\n",
    "        nb_epoch=200,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=15,\n",
    "        callbacks=[tensorboard_callback])\n",
    "\n",
    "# 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "\n",
    "scores = model.evaluate_generator(\n",
    "            validation_generator, \n",
    "            val_samples = 15)\n",
    "\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# 모델 예측하기\n",
    "print(\"-- Predict --\")\n",
    "\n",
    "output = model.predict_generator(\n",
    "            validation_generator, \n",
    "            val_samples = 15)\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 결론\n",
    "\n",
    "본 강좌에서는 이미지 분류 문제를 직접 정의해보고 데이터셋도 직접 만들어봤습니다. 이미지 분류 문제에 높은 성능을 보이고 있는 컨볼루션 신경망 모델을 이용하여 직접 만든 데이터셋으로 학습 및 평가를 해보았습니다. 학습 결과는 좋게 나왔지만 이 모델은 한 사람이 그린 것에 대해서만 학습이 되어 있어서 다른 사람에 그린 모양은 잘 분류를 못할 것 같습니다. 이후 강좌에서는 다른 사람이 그린 모양으로 평가해보고 어떻게 모델 성능을 높일 수 있을 지 알아보겠습니다.\n",
    "\n",
    "그리고 실제 문제에 적용하기 전에 데이터셋을 직접 만들어보거나 좀 더 쉬운 문제로 추상화해서 프로토타이핑 하시는 것을 권장드립니다. 객담도말된 결핵 이미지 판별하는 모델을 만들 때, 결핵 이미지를 바로 사용하지 않고, MNIST의 손글씨 중 '1'과 '7'을 결핵이라고 보고, 나머지는 결핵이 아닌 것으로 학습시켜봤었습니다. 결핵균이 간균 (막대모양)이라 적절한 프로토타이핑이었습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "### 같이 보기\n",
    "\n",
    "* [강좌 목차](https://tykimos.github.io/Keras/2017/01/27/Keras_Lecture_Plan/)\n",
    "* 이전 : [딥러닝 모델 이야기/컨볼루션 신경망 레이어 이야기](https://tykimos.github.io/Keras/2017/01/27/CNN_Layer_Talk/)\n",
    "* 다음 : [딥러닝 모델 이야기/순환 신경망 레이어 이야기]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
