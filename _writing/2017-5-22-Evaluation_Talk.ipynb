{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title:  \"평가 이야기\"\n",
    "author: 김태영\n",
    "date:   2017-05-22 13:00:00\n",
    "categories: Keras\n",
    "comments: true\n",
    "image: http://tykimos.github.com/Keras/warehouse/2017-5-22-Evaluation_Talk_segmentation_7.jpg\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 학습한 모델을 어떤 기준으로 평가를 해야되는 지를 알아보겠습니다. 모델을 평가한다고 하면 `정확도`라는 단어를 떠올리기 쉬운데, 문제에 따라 단순히 정확도로만 평가하기 힘든 경우가 있습니다. 조금 더 알아보면 민감도, 특이도, 재현율 등의 용어가 나오는데, 비전공자에게는 생소하게만 느껴지네요. 몇가지 문제와 모델을 정의하고 여기에 적합한 평가 기준이 무엇인지 알아보겠습니다. 용어는 생소하지만 의미를 알게되면 왜 이런 기준이 생겼는 지 이해가 됩니다. 간단한 예제를 통해 최대한 수식을 없애고 손가락으로 세면서 계산해보겠습니다. 늘 그랬듯이 레고로 놀이해봅시다. 다만 이번에는 그림이 아닌 실사입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 분류 하기\n",
    "\n",
    "자 그럼 첫번째 문제입니다.\n",
    "\n",
    "    아래 레고 블럭 중 상단 돌기의 수가 홀수인 것을 골라 왼쪽으로 나두고, 짝수는 오른쪽으로 나두세요.\n",
    "    \n",
    "어린아이들도 쉽게 풀 수 있는 문제입니다. 총 10개 중 홀수와 짝수는 몇 개 일까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![classification](http://tykimos.github.com/Keras/warehouse/2017-5-22-Evaluation_Talk_classification_1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "홀수가 4개, 짝수가 6개 있습니다. 조금 더 눈썰미가 좋으신 분은 홀수가 녹색, 짝수가 노란색으로 되어 있음을 알아차렸겠죠? 색상은 쉽게 구분이 되도록 맞춘 것뿐이고 문제하고는 상관이 없으니 신경쓰지 않으셔도 됩니다. 모범답안은 다음 그림과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![classification](http://tykimos.github.com/Keras/warehouse/2017-5-22-Evaluation_Talk_classification_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 모델 A가 이렇게 분류를 했다면 우리가 흔히 말하는 정확도로 말하면 이 모델 A의 정확도는 100%입니다. 여기서 `정확도`란 홀수를 홀수라고 맞추고(양성을 양성이라 말하고), 짝수를 짝수라고 맞춘(음성을 음성이라고 말한) 개수라고 가정해봅시다. 만약 모델 B가 다음과 같이 분류하였다면 정확도는 어떻게 될까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![classification](http://tykimos.github.com/Keras/warehouse/2017-5-22-Evaluation_Talk_classification_3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 B는 그냥 모두 홀수라고 분류를 하였네요. 어떠한 상황에도 모두 홀수라고 분류할 것이기에 모델이란 관점에서는 효용가치가 없겠지만, 정확도면에서는 10개 중 4개를 맞추었으니 정확도가 40%나 됩니다. 만약 모델 C가 다음과 같이 분류하였다면 정확도는 어떻게 될까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![classification](http://tykimos.github.com/Keras/warehouse/2017-5-22-Evaluation_Talk_classification_4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 C는 모델 B와는 반대로 모두 짝수라고 분류하였네요. 모델 B와 같이 별로 효용가치가 없어보이지만 정확도는 10개 중에 6개를 맞추었으니 60%나 됩니다. 객관식 시험을 볼때 무조건 한 번호로 모두 찍어도 점수가 어느정도 나오는 원리입니다. 다르게 말하면 0%가 되기가 힘들다는 얘기인데, 만약 이진분류에서 0점 받기란 100점 받는 것과 동일하다고도 볼 수 있습니다. \n",
    "\n",
    "    이진분류 문제에서 정확도가 50%가 나왔다고 해서 좋아하지 마세요. 그건 마치 동전던지기와 같이 랜덤에 가깝습니다.\n",
    "\n",
    "모델 C가 모델 B보다 정확도가 높은 이유는 무엇일까요? 당연한 얘기이지만 짝수 블럭이 홀수 블럭보다 많기 때문이죠. 만약 모델 D가 다음과 같이 분류하였으면 정확도가 어떻게 될까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![classification](http://tykimos.github.com/Keras/warehouse/2017-5-22-Evaluation_Talk_classification_5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "홀수는 2개 맞추었고, 짝수는 6개 맞추었으니 총 8개 맞추어서 80%의 정확도를 가지고 있습니다. 다음 모델 E의 결과를 보고 비교해보도록 합시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![classification](http://tykimos.github.com/Keras/warehouse/2017-5-22-Evaluation_Talk_classification_6.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "홀수는 4개 맞추었고, 짝수도 4개 맞추었습니다. 총 8개 맞추었으니 80%의 정확도를 가지고 있네요. 분류 결과는 다르지만 모델 D와 동일한 정확도를 가지고 있습니다. 정확도는 같지만 모델 D와 모델 E는 어떤 특징이 있을까요?\n",
    "\n",
    "    모델 D는 홀수 블럭을 모두 고르지는 못했지만, 고른 블럭은 모두 홀수입니다.\n",
    "    모델 E는 홀수라고 골라는 블럭 중엔 짝수블럭도 있지만, 홀수 블럭은 모두 골라냈습니다.\n",
    "    \n",
    "푸시고자 하는 문제에 따라 모델 D가 필요하거나 또는 모델 E가 더 유용할 때가 있습니다. 이러한 특징을 평가하기 위해서 정확도 대신에 `민감도`와 `특이도`이라는 것을 사용합니다.\n",
    "\n",
    "    민감도는 양성을 양성이라고 판정을 얼마나 잘하는 지를 나타냅니다. ( = 판정한 것 중 실제 양성 / 전체 양성 )\n",
    "    특이도는 음성을 음성이라고 판정을 얼마나 잘하는 지를 나타냅니다. ( = 판정한 것 중 실제 음성 / 전체 음성 )\n",
    "    \n",
    "여기서 양성을 홀수로, 음성을 짝수로 가정해봅시다. 모델 D는 홀수 블럭 총 4개 중 2개만 골라냈으니, 50%의 민감도를 가지고 있습니다. 반면에 특이도는 짝수 블록 총 6개 중 6개를 다 골라냈으니 100%의 특이도를 가지고 있습니다. 모델 E는 홀수 블럭 총 4개 중 4개를 다 골라냈으니 100%의 민감도를 가지고 있는 반면, 특이도는 짝수 블럭 총 6개 중 4개만 골라냈으니 66.6%의 특이도를 가지고 있습니다. 마지막으로 모델 F의 결과를 보도록 합시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![classification](http://tykimos.github.com/Keras/warehouse/2017-5-22-Evaluation_Talk_classification_7.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "총 10개 블럭 중 홀수 2개, 짝수 4개를 맞추었으므로 60%의 정확도를 가지고 있습니다. 민감도는 총 4개의 홀수 블럭 중 2개를 맞추었으니 50%입니다. 특이도는 총 6개의 짝수 블럭 중 4개를 맞추었으니 66%입니다. 지금까지 본 모델을 표로 비교해보겠습니다.\n",
    "\n",
    "|구분|모델 A|모델 B|모델 C|모델 D|모델 E|모델 F|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|맞춘 홀수|\n",
    "|맞춘 짝수|\n",
    "|정확도|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- 음주 단속 : 운전자가 음주를 했는 지 안 했는 지 검사하는 행위\n",
    "- 신호 위반 단속 : 신호 위반한 운전자를 적발하는 행위\n",
    "\n",
    "얼핏 생각하면 위반을 했는 지 안 했는 지를 알아내는 비슷한 문제인 것 같지만 조금 차이가 납니다. 둘 다 이진 분류 문제이지만 음주 단속은 진단을 하는 것이고, 신호 위반 단속은 검출을 하는 것입니다.\n",
    "\n",
    "### 진단 문제\n",
    "\n",
    "먼저 음주 단속에 대해서 알아보겠습니다. 열명의 운전자가 있고, 5개의 음주 단속 모델이 있다고 가정해봅니다. 운전자의 음주여부 및 각 모델의 결과 테이블은 다음과 같습니다.\n",
    "\n",
    "|운전자|음주여부|모델A|모델B|모델C|모델D|모델E|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|운전자1|O|O|X|O|X|O|\n",
    "|운전자2|X|X|O|O|X|O|\n",
    "|운전자3|X|X|O|X|X|O|\n",
    "|운전자4|O|O|X|O|O|O|\n",
    "|운전자5|O|O|X|O|O|X|\n",
    "|운전자6|X|X|X|X|X|X|\n",
    "|운전자7|X|X|O|O|X|X|\n",
    "|운전자8|O|O|X|O|X|X|\n",
    "|운전자9|X|X|O|X|X|X|\n",
    "|운전자10|X|X|O|X|X|X\n",
    "\n",
    "가장 쉬운 기준인 정확도에 대해서 알아봅시다. 정확도도는 있는 것을 있다고 판단하고, 없는 것을 없다고 판단하는 확률입니다. 모델 1은 전체 10개 중에 10개를 모두 맞추었으니 100%의 정확도를 가지고 있습니다. 모델 2는 전체 10개 중 하나도 못 맞추었으니 0%입니다.  모델3과 모델4는 모두 정확도 80%를 가지고 있습니다. 즉 10개 중 8개를 맞춘 것입니다. 모델3은 6명을 음주로 판단하였네요. 음주 운전자 모두 검출했지만, 음주운전자가 아닌 2명도 음주라고 판단하였습니다. 모델4는 음주 운전자 2명을 놓치고 나머지는 다 맞추었네요. 이 모델3과 모델4는 동일한 정확도를 가지고 있지만, 같은 성능을 내고 있지 않습니다.\n",
    "\n",
    "모델3은 음주가 아닌 운전자도 음주라고 하지만, 음주한 운전자는 모두 잡아냈습니다. 모델3이 음주가 아니라고 하면 정말 아닌 것이죠.\n",
    "모델4는 음주인 운전자를 놓치긴 했지만, 음주하지 않은 운전자는 모두 아니라고 판정하였네요. 모델4이 음주라고 하면 정말 음주인 것입니다.\n",
    "\n",
    "그럼 교통 경찰인 당신은 어떤 모델을 사용해야할까죠? 모델3을 사용할 것 입니다. 음주 운전자를 놓치게 되면 큰 사고로 이어갈 수 있기 때문에 반드시 검출해야하는 것이죠. 그리고 2차 검사가 있기 때문에 음주를 하지 않은 운전자는 2차 검사에서 아니라고 판별이 나올테니 크게 걱정하지 않아도 될 것 입니다.\n",
    "\n",
    "\n",
    "\n",
    "음주 단속 모델은 음주를 한 사람은 양성이라고 판정하고, 음주를 하지 않은 사람은 음성이라고 판정을 잘 하면 됩니다. 이는 양성과 음성을 판별하는 이진 분류 문제입니다. 다음의 케이스가 있을 것 같습니다. \n",
    "\n",
    "음주한 운전자가 A, E, F, H 이렇게 4명이 있다고 가정해봅시다. \n",
    "\n",
    "운전자명 음주 모델1 모델2 모델3 모델4 모델5\n",
    "|\n",
    "\n",
    "\n",
    "### 검출 문제\n",
    "\n",
    "등의 용어도 용어도 나와서 점점 헷갈리기 시작합니다. \n",
    "\n",
    "일단 현재까지 제가 알고 있는 지식선에서 말씀드리겠습니다.\n",
    "- 이진 분류와 다중클래스 분류 문제를 두고 비교를 하셨는데, 이진 분류 결과가 반드시 좋을 것이라고 보기는 힘들 것 같습니다. 사람인 것과 아닌 것을 분류한다고 했을 때, 사람인 것은 특징이 분명한데, 사람이 아닌 것은 특징이 너무 다양하고 특정할 수 없기에 이것을 이진분류로 풀지 않고, 사람 / 동물(사람이 아닌) / 식물 / 배경 / 기타 등으로 나누어서 학습을 시키는 것이 더 좋다는 의견도 들은 적이 있습니다. \n",
    "- 평가방법에서 사용된 정확도 개념을 제가 보기에는 정밀도와 재현율로 평가를 해야되지 않을까 합니다. 다중 클래스인 경우에는 하신 것 처럼 어떤 클래스를 해당 클래스로 제대로 예측했는 지 정확도를 계산하면 될 것 같구요.\n",
    "- 정밀도와 재현율로 평가를 해야된다고 말씀드리는 이유는 본 문제가 양성과 음성을 분류하는 문제가 아닌 양성을 찾아내는 문제 (패턴 인식이나 검색)문제로 보이기 때문입니다. 사실 분류문제에서는 양성을 양성으로 음성을 음성으로 잘 찾아내는 모델을 만들기 위해 민감도/특이도 등의 평가기준을 삼지만, 지금 푸시고자 하는 문제는 음성을 음성으로 잘 찾아내는 능력을 별로 중요하지 않은 것 같고, 내가 양성으로 찾은 것들 중 진짜 양성이 몇 개이냐(정밀도) 그리고 내가 진짜 양성 중에 몇 개나 찾아냈냐 (재현율)이 중요한 평가 기준이 될 것 같습니다\n",
    "\n",
    "집필\n",
    "\n",
    "교통 경찰이 되어 봅시다. 여러 종류의 단속이 있습니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "가장 쉬운 기준인 정확도에 대해서 알아봅시다. 정확도도는 있는 것을 있다고 판단하고, 없는 것을 없다고 판단하는 확률입니다. 모델 1은 전체 10개 중에 10개를 모두 맞추었으니 100%의 정확도를 가지고 있습니다. 모델 2는 전체 10개 중 하나도 못 맞추었으니 0%입니다.  모델3과 모델4는 모두 정확도 80%를 가지고 있습니다. 즉 10개 중 8개를 맞춘 것입니다. 모델3은 6명을 음주로 판단하였네요. 음주 운전자 모두 검출했지만, 음주운전자가 아닌 2명도 음주라고 판단하였습니다. 모델4는 음주 운전자 2명을 놓치고 나머지는 다 맞추었네요. 이 모델3과 모델4는 동일한 정확도를 가지고 있지만, 같은 성능을 내고 있지 않습니다.\n",
    "\n",
    "모델3은 음주가 아닌 운전자도 음주라고 하지만, 음주한 운전자는 모두 잡아냈습니다. 모델3이 음주가 아니라고 하면 정말 아닌 것이죠.\n",
    "모델4는 음주인 운전자를 놓치긴 했지만, 음주하지 않은 운전자는 모두 아니라고 판정하였네요. 모델4이 음주라고 하면 정말 음주인 것입니다.\n",
    "\n",
    "그럼 교통 경찰인 당신은 어떤 모델을 사용해야할까죠? 모델3을 사용할 것 입니다. 음주 운전자를 놓치게 되면 큰 사고로 이어갈 수 있기 때문에 반드시 검출해야하는 것이죠. 그리고 2차 검사가 있기 때문에 음주를 하지 않은 운전자는 2차 검사에서 아니라고 판별이 나올테니 크게 걱정하지 않아도 될 것 입니다.\n",
    "\n",
    "동일한 정확도이지만 \n",
    "\n",
    "컴퓨터 비전 분야에 객체검출에서는 mAP라는 평가 기준을 사용하고 있습니다.\n",
    "\n",
    "영상 상에서 검출이 되었다 안되었다라고 정의하는 것은 오버랩 기준으로 합니다. 0.5보다 크면(intersection-over-union 큰 교차 오버런으로 정의)오버랩입니다.\n",
    "\n",
    "검출되었다는 기준은 i\n",
    "\n",
    "두 영역간의 교집합 넓이와 합집합 넓이의 비율\n",
    "\n",
    "이미지에서 관심 객체 위에 박스를 그린다고 가정 해봅시다. 사람이 보고 관심 객체를 보고 객체를 포함시키는 박스를 그리는 것이 기준값(ground truth)으로 지정합니다. 이를 기준 박스(gourd truth box)라고 합니다. 그리고 우리가 만들고자 하는 모델에 입력 영상을 넣었을 때 객체라고 검출되었을 때 박스를 그리도록 합시다. 이 박스를 예측 박스(prediction box)라고 해봅시다. 이 때 얼마나 객체 검출을 잘 했는 지 평가를 어떻게 할까요?\n",
    "\n",
    "먼저 모델이 객체 검출을 했다는 기준을 어떻게 잡을 까요? 기준값 박스와 예측 박스의 합집합과 교집합 영역(intersection-over-union)이 0.5 이상일 때 검출 되었다고 합니다. 아래 그림을 보도록 합시다. 동일 객체에 여러 예측 박스가 출력이 될 경우, IOU가 가장 높은 예측박스를 선정합니다.\n",
    "\n",
    "모델 결과로 나온 예측 상자는 객체를 객체라고 표시한 것 (진양성, True-Positive) 또는 객체가 아닌 것을 객체라고 표시(가양성, False-Positive)한 것입니다. 기준 박스는 객체를 객체라고 표시(진양성, True-Positive)한 것입니다. 거기에는 객체가 아닌 것(진음성, True-Negative)은 표기되어 있지 않습니다.\n",
    "\n",
    "따라서 예측 된 각 상자는 True-Positive 또는 False-Positive 중 하나입니다. 각 진실 상자는 참 긍정 또는 거짓 부정입니다. 진실한 부정은 없다.\n",
    "그런 다음 평균 정확도는 리콜이 [0, 0.1, ..., 1] 범위 (예 : 평균 11 개의 정밀도 값)에있는 정밀 리콜 곡선의 정밀도 값을 평균화하여 계산됩니다. 좀 더 정확히 말하자면, 각 곡선 점 (p, r)에 대해 p '> p 및 r'> = r 인 다른 곡선 점 (p ', r')이있는 경우 약간 수정 된 PR 곡선을 고려합니다. p를 이들 점의 최대 p '로 대체한다.\n",
    "나에게 아직도 불명확 한 점은 결코 감지되지 않는 GT 박스로 수행되는 것입니다 (확신이 0 인 경우 라 할지라도). 즉, 정확도 리콜 곡선에 결코 도달하지 못할 특정 리콜 값이 있으며 이는 평균 정밀도 계산을 정의되지 않은 값으로 만듭니다.\n",
    "\n",
    "Hence each predicted box is either True-Positive or False-Positive. Each ground-truth box is either True-Positive or False-Negative. There are no True-Negatives.\n",
    "Then the average precision is computed by averaging the precision values on the precision-recall curve where the recall is in the range [0, 0.1, ..., 1] (e.g. average of 11 precision values). To be more precise, we consider a slightly corrected PR curve, where for each curve point (p, r), if there is a different curve point (p', r') such that p' > p and r' >= r, we replace p with maximum p' of those points.\n",
    "What is still unclear to me is what is done with those GT boxes that are never detected (even if the confidence is 0). This means that there are certain recall values that the precision-recall curve will never reach, and this makes the average precision computation above undefined.\n",
    "\n",
    "That is not the only thing that is unclear. Consider a case where there are two predicted boxed (P1, P2) and two ground-truth boxes (T1, T2), where P2 has higher confidence than P1. Both P1 and P2 overlap T1. Since P2 has the higher confidence, it is clear that P2 should be considered the match for T1. What is not given is if P1 also has some IOU overlap with T2, but lower than the IOU with T1, should P1 be given a \"second chance\" to try to match itself to T2, or should it not? – Martin Apr 13 at 13:06\n",
    "\n",
    "\n",
    "mAP is Mean Average Precision.\n",
    "Its use is different in the field of Information Retrieval (Reference [1] [2] )and Multi-Class classification (Object Detection) settings.\n",
    "To calculate it for Object Detection, you calculate the average precision for each class in your data based on your model predictions. Average precision is related to the area under the precision-recall curve for a class. Then Taking the mean of these average individual-class-precision gives you the Mean Average Precision.\n",
    "To calculate Average Precision, see [3]\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "[정밀도와 재현율 참조]\n",
    "https://ko.wikipedia.org/wiki/%EC%A0%95%EB%B0%80%EB%8F%84%EC%99%80_%EC%9E%AC%ED%98%84%EC%9C%A8\n",
    "\n",
    "[다양한 평가 기준 참조]\n",
    "https://docs.microsoft.com/ko-kr/azure/machine-learning/machine-learning-evaluate-model-performance\n",
    "\n",
    "평가 기준을 정하는 것은 모델을 설계하는 데 있어서 중요한 사안인 것 같고, 서로 다른 문제에서 동일 평가 기준으로 비교하는 것이 쉽지 않을 것으로 보입니다.\n",
    "\n",
    "\n",
    "문제에 따라 평가 기준이 다르기도 헙니다. 용어에 대해서 알아보기 전에 어떤 문제를 풀 수 있는 지 비유를 들어서 확인 해보겠습니다.\n",
    "\n",
    "매번 밥먹을 때마다 식당을 고르기가 쉽지 않습니다. 이 때 맛집을 많이 아는 친구가 있으면 편합니다. 많은 능력이 필요하겠지만 먼저 두가지 능력에 대해서 알아보겠습니다.\n",
    "\n",
    "맛집과 아닌집을 구분하는 능력\n",
    "맛집을 찾아내는 능력\n",
    "\n",
    "이 두 개의 능력은 어떤 차이가 있을까요?  본격적으로 알아보기 전에 몇가지 가정을 해봅시다.\n",
    "\n",
    "음식점이 총 100개가 있습니다. \n",
    "이 중에 실제 맛집이 20개가 있습니다.\n",
    "\n",
    "자 그럼, 친구들을 데리고 총 100군데 식당을 가봅시다. \n",
    "\n",
    "어떤 친구는 100군데 모두 맛집이라고 하고,\n",
    "어떤 친구는 100군데 모두 맛집이 아니라고 합니다.\n",
    "어떤 친구는 100군데 중 50군데를 맛집이라고 합니다. 이 50군데에는 진짜 맛집 20개가 다 포함되어 있습니다.\n",
    "\n",
    "\n",
    "\n",
    "케라스에서 만든 모델을 학습할 때는 fit()함수를 사용합니다. \n",
    "\n",
    "    model.fit(x, y, batch_size=32, epochs=10)\n",
    "\n",
    "주요인자는 다음과 같습니다. \n",
    "- x : 입력 데이터\n",
    "- y : 라벨 값\n",
    "- batch_size : 몇 개의 샘플로 가중치를 갱신할 것인지 지정\n",
    "- epochs : 학습 반복 횟수\n",
    "\n",
    "학습에 관련된 인자이므로 시험 공부하는 것에 비유를 해보겠습니다. 먼저 모의고사 1회분을 가지고 학습해봅시다. 이 1회분은 100문항이 있고, 해답지도 제공합니다. 문제를 푼 뒤 해답지와 맞춰보면서 학습이 이루어지기 때문에 해답지가 없으면 학습이 안 됩니다. \n",
    "\n",
    "![img](http://tykimos.github.com/Keras/warehouse/2017-3-25-Dataset_and_Fit_Talk_batch0.png)\n",
    "\n",
    "위의 주요인자은 다음과 같이 비유할 수 있습니다. \n",
    "\n",
    "### x\n",
    "100문항의 문제들입니다.\n",
    "\n",
    "### y\n",
    "100문항의 답들입니다.\n",
    "\n",
    "### batch_size(배치사이즈)\n",
    "배치사이즈는 몇 문항을 풀고 해답을 맞추는 지를 의미합니다. 100문항일 때, 배치사이즈가 100이면 전체를 다 풀고 난 뒤에 해답을 맞춰보는 것입니다. 우리가 해답을 맞춰볼 때 '아하, 이렇게 푸는구나'라고 느끼면서 학습하는 것처럼 모델도 이러한 과정을 통해 가중치가 갱신됩니다. \n",
    "\n",
    "    문제를 푼 뒤 해답과 맞춰봐야 학습이 일어납니다. > 모델의 결과값과 주어진 라벨 값과의 오차를 줄이기 위해, `역전파(Backpropagation)` 알고리즘으로 가중치가 갱신됩니다.\n",
    "\n",
    "전체 문제를 푼 뒤 해답과 맞추므로 이 때 가중치 갱신은 한 번만 일어납니다. \n",
    "\n",
    "![img](http://tykimos.github.com/Keras/warehouse/2017-3-25-Dataset_and_Fit_Talk_batch1.png)\n",
    "\n",
    "배치사이즈가 10이면 열 문제씩 풀어보고 해답 맞춰보는 것입니다. 100문항을 10문제씩 나누어서 10번 해답을 맞추므로 가중치 갱신은 10번 일어납니다.\n",
    "\n",
    "![img](http://tykimos.github.com/Keras/warehouse/2017-3-25-Dataset_and_Fit_Talk_batch2.png)\n",
    "\n",
    "배치사이즈가 1이면 한 문제 풀고 해답 맞춰보고 또 한 문제 풀고 맞춰보고 하는 것입니다. 한 문제를 풀 때마다 가중치 갱신이 일어나므로 횟수는 100번입니다.\n",
    "\n",
    "![img](http://tykimos.github.com/Keras/warehouse/2017-3-25-Dataset_and_Fit_Talk_batch3.png)\n",
    "\n",
    "100문제 다 풀고 해답을 맞히는 것과 1문제씩 풀고 해답을 맞히는 것은 어떤 차이가 있을까요? 언뜻 생각해서는 별 반 차이가 없어 보입니다. 하지만 모의고사 1회분에 비슷한 문항이 있다고 가정했을 때, 배치사이즈가 100일 때는 다 풀어보고 해답을 맞춰보기 때문에 한 문제를 틀릴 경우 이후 유사 문제를 모두 틀릴 경우가 많습니다. 배치사이즈가 1인 경우에는 한 문제씩 풀어보고 해답을 맞춰보기 때문에 유사문제 중 첫 문제를 틀렸다고 하더라도 해답을 보면서 학습하게 되므로 나머지 문제는 맞추게 됩니다. 자 그럼 이 배치사이즈가 어떨 때 학습효과가 좋을까요? 사람이 학습하는 것이랑 비슷합니다. 100문항 다 풀고 해답과 맞추어보려면 문제가 무엇이었는지 다 기억을 해야 맞춰보면서 학습이 되겠죠? 기억력(용량)이 커야합니다. 1문항씩 풀고 해답 맞추면 학습은 꼼꼼히 잘 되겠지만 시간이 너무 걸리겠죠? 그리고 해답지를 보다가 다음 문제의 답을 봐버리는 불상사가 생기겠죠(이것은 컴퓨터에서는 일어나지 않는 일입니다).\n",
    "\n",
    "    배치사이즈가 작을수록 가중치 갱신이 자주 일어납니다.\n",
    "\n",
    "### epchos(에포크)\n",
    "\n",
    "에포크는 모의고사 1회분을 몇 번 풀어볼까 입니다. 즉 100문항의 문제들을 몇 번이나 반복해서 풀어보는 지 정하는 것입니다. 에포크가 20이면 모의고사 1회분을 20번 푸는 것입니다. 처음에는 같은 문제를 반복적으로 풀어보는 것이 무슨 효과가 있는 지 의문이 들었지만 우리가 같은 문제집을 여러 번 풀면서 점차 학습되듯이 모델도 같은 데이터셋으로 반복적으로 가중치를 갱신하면서 모델이 학습됩니다. 같은 문제라도 이전에 풀었을 때랑 지금 풀었을 때랑 학습상태(가중치)가 다르기 때문에 다시 학습이 일어납니다. \n",
    "\n",
    "    같은 문제집이라도 반복해서 풀면 학습이 일어납니다.\n",
    "\n",
    "아래 그래프에서 세로축이 100문항 중 틀린 개수이고, 가로축이 모의고사 풀이 반복횟수입니다. 풀이를 반복할수록 틀린 개수가 적어지는 것을 보실 수 있습니다. 처음에는 틀린 개수가 확 적어지만 반복이 늘어날수록 완만하게 틀린 개수가 줄어듭니다. 우리가 공부할 때도 낮은 점수에서는 공부를 조금하면 점수가 확 오르지만, 높은 점수에서 1~2점 올리는 것이 쉽지 않은 것과 비슷할 수 있습니다.\n",
    "\n",
    "![plot](http://tykimos.github.com/Keras/warehouse/2017-3-25-Dataset_and_Fit_Talk_plot1.png)\n",
    "\n",
    "모의고사 1회분을 20번 푸는 것과 서로 다른 모의고사 20회분을 1번 푸는 것과는 어떤 차이가 있을까요? 이것은 분야에 따라 데이터특성에 따라 다를 것이라고 생각합니다. 잡다한 문제를 많이 푸는 것보다 양질의 문제를 여러 번 푸는 것이 도움이 된다고 생각합니다. 피아노를 배울 때도 기본 곡을 반복적으로 학습하면 다양한 악보도 쉽게 보는 반면 이곡 저곡 연습하면 제대로 익히기 쉽지 않습니다. 이런 문제를 제외하고도 현실적으로 데이터를 구하기가 쉽지 않기 때문에 제한된 데이터셋으로 반복적으로 학습하는 것이 효율적입니다. \n",
    "\n",
    "그럼 이 에포크를 무조건 늘리면 좋을까요? 하나의 문제집만 계속 학습하면 오히려 역효과가 발생할 수 있습니다. 피아노 칠 때 처음에 곡을 연습할 때는 악보를 보면서 치다가 다음엔 악보안보고도 치고, 나중엔 눈감고도 칩니다. 눈감고만 치다보면 악보 보는 법을 까먹게 되고 다른 곡을 치지 못하는 지경에 이릅니다. 연습한 곡은 완벽하게 칠 지 몰라도 다른 곡은 치지 못하는 상태가 됩니다. 우린 이것을 `오버피팅(overfitting)`이라고 부릅니다. 악보보고 잘 치는 정도에서 그만 연습하는 것이 더 좋았을 수 있습니다. 실제로 모델을 학습할 때도 오버피팅이 일어나는 지 체크하다가 조짐이 보이면 학습을 중단합니다.\n",
    "\n",
    "    과유불급"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 데이터셋 이야기\n",
    "\n",
    "이번에는 데이터셋을 어떻게 구성하고 모델을 어떻게 검증할 지 알아보겠습니다.\n",
    "\n",
    "당신이 고등학교 담임선생님이고 수능 볼 학생이 3명이 있다고 가정을 해봅시다. 이 세 명 중 누가 수능을 가장 잘 볼지 알아 맞혀보도록 하겠습니다. 당신에게는 모의고사 5회분과 작년 수능 문제 1회분을 가지고 있습니다. 다음과 같이 비유될 수 있습니다. \n",
    "- 모의고사 5회분 : 훈련셋\n",
    "- 작년 수능 문제 : 시험셋\n",
    "- 학생 3명 : 모델 3개\n",
    "- 올해 수능 문제 : 실제 데이터 (아직 보지 못한 데이터)\n",
    "\n",
    "![img](http://tykimos.github.com/Keras/warehouse/2017-3-25-Dataset_and_Fit_Talk_3.png)\n",
    "\n",
    "참고로 '학습'의 의미는 문제와 해답지를 같이 준 후 문제 푼 뒤 정답과 맞추어서 학습을 하라는 것이고, '평가'의 의미는 문제만 주고 풀게한 뒤 맞는 지 틀린 지 점수만 계산하는 것입니다. 이 과정에서는 학생이 풀이과정을 보지 않고 점수만 매기는 것과 동일하기 때문에 학습이 일어나지 않습니다.\n",
    "\n",
    "### 경우 1\n",
    "올해 수능을 가장 볼 수 있는 학생을 고르는 가장 쉬운 방법은 무엇일까요? 바로 올해 수능 문제로 시험 쳐서 점수가 가장 높은 학생을 고르면 됩니다. 하지만 안타깝게도 올해 수능 문제를 수능 전에 알아낼 수 없습니다.\n",
    "\n",
    "![img](http://tykimos.github.com/Keras/warehouse/2017-3-25-Dataset_and_Fit_Talk_4.png)\n",
    "\n",
    "### 경우 2\n",
    "그럼 모의고사 5회분을 학습시킨 뒤 작년 수능 문제로 평가해서 가장 점수가 높은 학생을 고를까요? 작년 수능 문제로 점수가 높다고 해서 올해 수능도 점수가 높은지는 장담은 못하지만 그나마 해볼 수 있는 평가 방법입니다. 여기서 공정한 평가를 위해서 작년 수능 문제는 학생들에게 학습시키면 안 됩니다. \n",
    "\n",
    "![img](http://tykimos.github.com/Keras/warehouse/2017-3-25-Dataset_and_Fit_Talk_5.png)\n",
    "\n",
    "### 경우 3\n",
    "학생들이 스스로 학습 상태를 확인하고 학습 방법을 바꾸거나 학습을 중단하는 시점을 정할 수 없을까요? 이를 위해서 검증셋이 필요합니다. 학습할 때는 모의고사 1회~4회만 사용하고, 모의고사 5회분을 검증셋으로 두어 학습할 때는 사용하지 않습니다. 이 방식은 두 가지 효과를 얻을 수 있습니다. \n",
    "첫번째로 학습 방법을 바꾼 후 훈련셋으로 학습을 해보고 검증셋으로 평가해볼 수 있습니다. 검증셋으로 가장 높은 평가를 받은 학습 방법이 최적의 학습 방법이라고 생각하면 됩니다. 이러한 학습 방법을 결정하는 파라미터를 `하이퍼파라미터(hyperparameter)`라고 하고 최적의 학습 방법을 찾아가는 것을 하이퍼파라미터 튜닝이라고 합니다.\n",
    "\n",
    "    검증셋이 있다면 스스로 평가하면서 적절한 학습방법을 찾아볼 수 있습니다.\n",
    "\n",
    "![img](http://tykimos.github.com/Keras/warehouse/2017-3-25-Dataset_and_Fit_Talk_6.png)\n",
    "\n",
    "두번째로 얼마정도 반복 학습이 좋을 지를 정하기 위해서 검증셋을 사용할 수 있습니다. 훈련셋을 몇 번 반복해서 학습할 것인가를 정하는 것이 에포크(epochs)라고 했습니다. 초기에는 에포크가 증가될수록 검증셋의 평가 결과도 좋아집니다. 아래 그래프에서 세로축이 100문항 중 틀린 개수이고, 가로축이 모의고사 풀이 반복횟수입니다. 앞서 설명했듯이 풀이를 반복할수록 훈련셋(모의고사 1회~4회)에서는 틀린 개수가 적어짐을 보실 수 있습니다. \n",
    "\n",
    "![plot](http://tykimos.github.com/Keras/warehouse/2017-3-25-Dataset_and_Fit_Talk_plot2.png)\n",
    "\n",
    "이 상태는 아직 학습이 덜 된 상태 즉 학습을 더 하면 성능이 높아질 가능성이 있는 상태입니다. 이를 `언더피팅(underfitting)`이라고 합니다. 담임선생님 입장에서 학생들을 평생 반복 학습만 시킬 수 없으므로 (하교도 해야하고, 퇴근도 해야하고) 학생들의 학습 상태를 보면서 '아직 학습이 덜 되었으니 계속 반복하도록!' 또는 '충분히 학습했으니 그만해도 돼' 라는 판단을 내려야 합니다. 그 판단 기준이 무엇일까요? 에포크를 계속 증가시키다보면 더 이상 검증셋의 평가는 높아지지 않고 오버피팅이 되어 오히려 틀린 개수가 많아집니다. 이 시점이 적정 반복 횟수로 보고 학습을 중단합니다. 이를 `조기종료(early stopping)`이라고 합니다. \n",
    "\n",
    "    검증셋이 있다면 학습 중단 시점을 정할 수 있습니다. \n",
    "    \n",
    "아래 그래프에서는 11번 반복했을 때 이 현상이 나타났습니다. \n",
    "\n",
    "![plot](http://tykimos.github.com/Keras/warehouse/2017-3-25-Dataset_and_Fit_Talk_plot3.png)\n",
    "\n",
    "### 경우 4\n",
    "\n",
    "모의고사 5회로만 검증셋을 사용할 경우 여러 가지 문제가 발생할 수 있습니다. \n",
    "\n",
    "- 모의고사 5회에서 출제가 되지 않는 분야가 있을 수 있습니다.\n",
    "- 모의고사 5회가 작년 수능이나 올해 수능 문제와 많이 다를 수도 있습니다. \n",
    "- 모의고사 5회가 모의고사 1회~4회와 난이도 및 범위가 다를 수도 있습니다. \n",
    "\n",
    "이런 이유로 모의고사 5회로만 검증셋을 사용하기에는 객관적인 평가가 이루어졌다고 보기 힘듭니다. 이 때 사용하는 것이 교차검증(cross-validation) 입니다. 하는 방법은 다음과 같습니다.\n",
    "\n",
    "- 모의고사 1회~4회를 학습한 뒤 모의고사 5회로 평가를 수행합니다. \n",
    "- 학습된 상태를 초기화한 후 다시 모의고사 1, 2, 3, 5회를 학습한 뒤 4회로 검증합니다.\n",
    "- 학습된 상태를 초기화한 후 다시 모의고사 1, 2, 4, 5회를 학습한 뒤 3회로 검증합니다.\n",
    "- 학습된 상태를 초기화한 후 다시 모의고사 1, 3, 4, 5회를 학습한 뒤 2회로 검증합니다.\n",
    "- 학습된 상태를 초기화한 후 다시 모의고사 2, 2, 4, 5회를 학습한 뒤 1회로 검증합니다.\n",
    "\n",
    "다섯 번의 검증결과를 평균 내어 이 평균값으로 성능을 정의합니다. 검증결과의 분산도 의미가 있을 것 같습니다. 검증셋이 다르다고 해서 결과가 많이 차이나는 것보다 평균이 낮더라도 안정적인 결과를 내는 것이 더 좋은 모델일 수 있습니다.\n",
    "\n",
    "![img](http://tykimos.github.com/Keras/warehouse/2017-3-25-Dataset_and_Fit_Talk_7.png)\n",
    "\n",
    "단 교차검증은 계산량이 많기 때문에 데이터수가 많지 않을 때 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q & A\n",
    "\n",
    "Q1) 검증셋이 학습 시에 사용되기 때문에 가중치 갱신에 영향을 미치나요?\n",
    "\n",
    "A1) 아닙니다. 학습 시에 현재 학습된 상태에서 평가로만 사용되므로 가중치 갱신은 일어나지 않습니다.\n",
    "\n",
    "Q2) 교차검증 시에 검증셋을 바꿀 때 마다 학습된 상태를 초기화해야 하나요?\n",
    "\n",
    "A2) 맞습니다. 첫번째 검증 시 모의고사 5회를 사용하였고, 두번째 검증 시 모의고사 4회를 사용할 경우, 첫번째 검증 시에 모의고사 1회~4회를 학습한 상태이기 때문에 만약 초기화하지 않으면 두번째 검증 시에 이미 모의고사 4회를 학습한 상태에서 검증하기 때문에 공정한 평가라고 보기 힘듭니다.\n",
    "\n",
    "![img](http://tykimos.github.com/Keras/warehouse/2017-3-25-Dataset_and_Fit_Talk_8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 결론\n",
    "\n",
    "저는 딥러닝 모델을 처음 접할 때 어떻게 학습되는 지 이해하기가 쉽지 않았습니다. 나중에 이해를 한 뒤에는 사람이 학습하는 방식과 크게 다를 바가 없다는 것을 알게 되었습니다. 그리고 데이터셋을 어떻게 설계할 것인 지, 어떻게 검증을 해야될 것인지도 중요한 요소입니다. 학생이 어떤 학습지로 공부를 해야할 지 어떤 기준으로 평가를 해야할지가 중요한 것 처럼 말입니다. 공부를 잘하는 비법 책도 많은 것 처럼 딥러닝 모델도 학습 방법에 대해서 연구가 많이 되고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "### 같이 보기\n",
    "\n",
    "* [강좌 목차](https://tykimos.github.io/Keras/lecture/)\n",
    "* 이전 : [딥러닝 이야기/케라스 이야기](https://tykimos.github.io/Keras/2017/01/27/Keras_Talk/)\n",
    "* 다음 : [딥러닝 이야기/오프라인 설치](https://tykimos.github.io/Keras/2017/03/15/Keras_Offline_Install/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
