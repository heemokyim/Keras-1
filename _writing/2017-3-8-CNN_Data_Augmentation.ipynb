{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title:  \"컨볼루션 신경망 모델을 위한 데이터 부풀리기\"\n",
    "author: Taeyoung, Kim\n",
    "date:   2017-03-08 23:10:00\n",
    "categories: Lecture\n",
    "comments: true\n",
    "image: http://tykimos.github.com/Keras/warehouse/2017-3-8-CNN_Data_Augmentation_5_combination.png\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본 강좌에서는 컨볼루션 신경망 모델의 성능을 높이기 위한 방법 중 하나인 데이터 부풀리기에 대해서 알아보겠습니다. 훈련셋이 부족하거나 훈련셋이 시험셋의 특성을 충분히 반영하지 못할 때 이 방법을 사용하면 모델의 성능을 크게 향상시킬 수 있습니다. 케라스에서는 데이터 부풀리기를 위한 함수를 제공하기 때문에 파라미터 셋팅만으로 간단히 데이터 부풀리기를 할 수 있습니다.\n",
    "\n",
    "1. 현실적인 문제\n",
    "1. 기존 모델 결과보기\n",
    "1. 데이터 부풀리기\n",
    "1. 개선 모델 결과보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 현실적인 문제\n",
    "\n",
    "[컨볼루션 신경망 모델 만들어보기](https://tykimos.github.io/Keras/2017/03/08/CNN_Getting_Started/) 강좌에서 사용하였던 원, 사각형, 삼각형 데이터셋을 예제로 살펴보겠습니다. 구성은 훈련셋과 시험셋으로 되어 있는 데, 아래 그림은 훈련셋입니다.\n",
    "\n",
    "#### 훈련셋\n",
    "![data](http://tykimos.github.com/Keras/warehouse/2017-3-8-CNN_Data_Augmentation_1.png)\n",
    "\n",
    "그리고 아래 그림은 시험셋입니다. 훈련셋과 시험셋은 모두 한사람(제가) 그린 것이라 거의 비슷합니다. 그래서 그런지 100% 정확도의 좋은 결과를 얻었나 봅니다.\n",
    "\n",
    "#### 시험셋\n",
    "![data](http://tykimos.github.com/Keras/warehouse/2017-3-8-CNN_Data_Augmentation_2.png)\n",
    "\n",
    "100% 정확도를 얻은 모델이니 원, 사각형, 삼각형을 그려주면 다 분류를 해보겠다며 지인에게 자랑을 해봅니다. 그래서 지인이 그려준 시험셋은 다음과 같습니다.\n",
    "\n",
    "#### 도전 시험셋\n",
    "![data](http://tykimos.github.com/Keras/warehouse/2017-3-8-CNN_Data_Augmentation_3.png)\n",
    "\n",
    "막상 시험셋을 받아보니 자신감이 없어지면서 여러가지 생각이 듭니다.\n",
    "\n",
    "- 아, 이것도 원, 사각형, 삼각형이구나\n",
    "- 왜 이런 데이터를 진작에 학습시키지 않았을까?\n",
    "- 새로 받은 시험셋 일부를 학습시켜볼까?\n",
    "- 이렇게 간단한 문제도 개발과 현실과의 차이가 이렇게 나는데, 실제 문제는 더 상황이 좋지 않겠지?\n",
    "\n",
    "결국 하나의 결론에 도달합니다.\n",
    "\n",
    "    개발자가 시험셋을 만들면 안된다.\n",
    "\n",
    "하지만 어떠한 문제에서도 미래에 들어올 데이터에 대해서는 알 수가 없기 때문에, 비슷한 상황일 것 같습니다. 먼저 도전 시험셋으로 시험한 결과를 살펴본 뒤, 한정적인 훈련셋을 이용하여 최대한 발생할 수 있는 경우을 고려하여 훈련셋을 만드는 방법인 `데이터 부풀리기`에 대해서 알아보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 기존 모델 결과보기\n",
    "\n",
    "[컨볼루션 신경망 모델 만들어보기](https://tykimos.github.io/Keras/2017/03/08/CNN_Getting_Started/) 강좌에서 사용했던 모델을 그대로 가지고 왔습니다. 제가 만든 시험셋에서는 결과가 100%나왔는데, 도전 시험셋으론 어떤 결과가 나오는 지 테스트해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 images belonging to 3 classes.\n",
      "Found 15 images belonging to 3 classes.\n",
      "Epoch 1/200\n",
      "15/15 [==============================] - 0s - loss: 0.9365 - acc: 0.5778 - val_loss: 1.7078 - val_acc: 0.3333\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 0s - loss: 0.1786 - acc: 1.0000 - val_loss: 2.8848 - val_acc: 0.4000\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 0s - loss: 0.0233 - acc: 1.0000 - val_loss: 4.3072 - val_acc: 0.4000\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 0s - loss: 0.0148 - acc: 1.0000 - val_loss: 4.3684 - val_acc: 0.4000\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 0s - loss: 0.0338 - acc: 0.9778 - val_loss: 4.7764 - val_acc: 0.4000\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 0s - loss: 9.1348e-04 - acc: 1.0000 - val_loss: 4.7950 - val_acc: 0.4000\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 0s - loss: 3.7592e-04 - acc: 1.0000 - val_loss: 4.7583 - val_acc: 0.4000\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 0s - loss: 1.8625e-04 - acc: 1.0000 - val_loss: 5.3714 - val_acc: 0.3333\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 0s - loss: 1.0065e-04 - acc: 1.0000 - val_loss: 6.1611 - val_acc: 0.3333\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 0s - loss: 7.0697e-05 - acc: 1.0000 - val_loss: 4.0309 - val_acc: 0.4000\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 0s - loss: 4.9265e-05 - acc: 1.0000 - val_loss: 4.3190 - val_acc: 0.5333\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 0s - loss: 3.7569e-05 - acc: 1.0000 - val_loss: 6.6371 - val_acc: 0.4000\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 0s - loss: 2.9858e-05 - acc: 1.0000 - val_loss: 5.3775 - val_acc: 0.4000\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 0s - loss: 2.3786e-05 - acc: 1.0000 - val_loss: 5.6067 - val_acc: 0.4000\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 0s - loss: 1.9294e-05 - acc: 1.0000 - val_loss: 5.7995 - val_acc: 0.4000\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 0s - loss: 1.5511e-05 - acc: 1.0000 - val_loss: 3.0991 - val_acc: 0.6000\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 0s - loss: 1.3030e-05 - acc: 1.0000 - val_loss: 6.5526 - val_acc: 0.4000\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 0s - loss: 1.0758e-05 - acc: 1.0000 - val_loss: 7.0464 - val_acc: 0.3333\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 0s - loss: 8.7422e-06 - acc: 1.0000 - val_loss: 6.5685 - val_acc: 0.4000\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 0s - loss: 7.4043e-06 - acc: 1.0000 - val_loss: 4.8069 - val_acc: 0.4667\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 0s - loss: 6.0996e-06 - acc: 1.0000 - val_loss: 6.5557 - val_acc: 0.4000\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 0s - loss: 5.1870e-06 - acc: 1.0000 - val_loss: 7.3437 - val_acc: 0.2667\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 0s - loss: 4.4982e-06 - acc: 1.0000 - val_loss: 5.0839 - val_acc: 0.4667\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 0s - loss: 3.8412e-06 - acc: 1.0000 - val_loss: 8.6765 - val_acc: 0.2667\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 0s - loss: 3.3538e-06 - acc: 1.0000 - val_loss: 8.2918 - val_acc: 0.2667\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 0s - loss: 2.9617e-06 - acc: 1.0000 - val_loss: 6.2512 - val_acc: 0.4667\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 0s - loss: 2.6624e-06 - acc: 1.0000 - val_loss: 8.2748 - val_acc: 0.3333\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 0s - loss: 2.3749e-06 - acc: 1.0000 - val_loss: 4.5164 - val_acc: 0.5333\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 0s - loss: 2.2027e-06 - acc: 1.0000 - val_loss: 6.4755 - val_acc: 0.4000\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 0s - loss: 1.9418e-06 - acc: 1.0000 - val_loss: 6.7559 - val_acc: 0.3333\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 0s - loss: 1.8067e-06 - acc: 1.0000 - val_loss: 9.9530 - val_acc: 0.2000\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 0s - loss: 1.6411e-06 - acc: 1.0000 - val_loss: 6.1389 - val_acc: 0.4667\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 0s - loss: 1.4914e-06 - acc: 1.0000 - val_loss: 6.6318 - val_acc: 0.3333\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 0s - loss: 1.4001e-06 - acc: 1.0000 - val_loss: 5.1138 - val_acc: 0.5333\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 0s - loss: 1.2901e-06 - acc: 1.0000 - val_loss: 6.7336 - val_acc: 0.4000\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 0s - loss: 1.1961e-06 - acc: 1.0000 - val_loss: 6.8378 - val_acc: 0.3333\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 0s - loss: 1.1338e-06 - acc: 1.0000 - val_loss: 6.0867 - val_acc: 0.5333\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - 0s - loss: 1.0411e-06 - acc: 1.0000 - val_loss: 7.0700 - val_acc: 0.5333\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 0s - loss: 9.7487e-07 - acc: 1.0000 - val_loss: 6.7977 - val_acc: 0.4667\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 0s - loss: 9.1526e-07 - acc: 1.0000 - val_loss: 9.0914 - val_acc: 0.2667\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 0s - loss: 8.7155e-07 - acc: 1.0000 - val_loss: 7.8708 - val_acc: 0.3333\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - 0s - loss: 8.2122e-07 - acc: 1.0000 - val_loss: 7.3363 - val_acc: 0.4000\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 0s - loss: 7.7619e-07 - acc: 1.0000 - val_loss: 6.1912 - val_acc: 0.4000\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 0s - loss: 7.4705e-07 - acc: 1.0000 - val_loss: 6.3050 - val_acc: 0.4000\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 0s - loss: 7.0598e-07 - acc: 1.0000 - val_loss: 8.5954 - val_acc: 0.3333\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 0s - loss: 6.8347e-07 - acc: 1.0000 - val_loss: 8.4777 - val_acc: 0.3333\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 0s - loss: 6.3711e-07 - acc: 1.0000 - val_loss: 7.7412 - val_acc: 0.3333\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 0s - loss: 6.1062e-07 - acc: 1.0000 - val_loss: 8.0671 - val_acc: 0.4000\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 0s - loss: 5.8545e-07 - acc: 1.0000 - val_loss: 4.3985 - val_acc: 0.6000\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 0s - loss: 5.6161e-07 - acc: 1.0000 - val_loss: 6.5770 - val_acc: 0.4000\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 0s - loss: 5.3247e-07 - acc: 1.0000 - val_loss: 6.1320 - val_acc: 0.5333\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 0s - loss: 5.1260e-07 - acc: 1.0000 - val_loss: 7.6921 - val_acc: 0.4000\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 0s - loss: 4.9406e-07 - acc: 1.0000 - val_loss: 7.8810 - val_acc: 0.4000\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 0s - loss: 4.7419e-07 - acc: 1.0000 - val_loss: 7.3085 - val_acc: 0.3333\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 0s - loss: 4.5829e-07 - acc: 1.0000 - val_loss: 8.1769 - val_acc: 0.4000\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 0s - loss: 4.4240e-07 - acc: 1.0000 - val_loss: 8.6934 - val_acc: 0.2667\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 0s - loss: 4.2518e-07 - acc: 1.0000 - val_loss: 9.9815 - val_acc: 0.2667\n",
      "Epoch 58/200\n",
      "15/15 [==============================] - 0s - loss: 4.0796e-07 - acc: 1.0000 - val_loss: 6.6938 - val_acc: 0.4000\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 0s - loss: 3.9736e-07 - acc: 1.0000 - val_loss: 8.7848 - val_acc: 0.3333\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 0s - loss: 3.8809e-07 - acc: 1.0000 - val_loss: 7.5840 - val_acc: 0.4000\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 0s - loss: 3.7352e-07 - acc: 1.0000 - val_loss: 8.4652 - val_acc: 0.3333\n",
      "Epoch 62/200\n",
      "15/15 [==============================] - 0s - loss: 3.6028e-07 - acc: 1.0000 - val_loss: 6.7533 - val_acc: 0.4000\n",
      "Epoch 63/200\n",
      "15/15 [==============================] - 0s - loss: 3.5763e-07 - acc: 1.0000 - val_loss: 6.0865 - val_acc: 0.5333\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 0s - loss: 3.4173e-07 - acc: 1.0000 - val_loss: 9.1457 - val_acc: 0.3333\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 0s - loss: 3.2849e-07 - acc: 1.0000 - val_loss: 6.4459 - val_acc: 0.4667\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 0s - loss: 3.2054e-07 - acc: 1.0000 - val_loss: 7.5177 - val_acc: 0.3333\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 0s - loss: 3.1259e-07 - acc: 1.0000 - val_loss: 7.8855 - val_acc: 0.4000\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 0s - loss: 3.0597e-07 - acc: 1.0000 - val_loss: 9.6188 - val_acc: 0.2667\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 0s - loss: 3.0200e-07 - acc: 1.0000 - val_loss: 7.4025 - val_acc: 0.3333\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 0s - loss: 2.9405e-07 - acc: 1.0000 - val_loss: 6.0132 - val_acc: 0.4667\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 0s - loss: 2.8610e-07 - acc: 1.0000 - val_loss: 6.3674 - val_acc: 0.4667\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 0s - loss: 2.7683e-07 - acc: 1.0000 - val_loss: 6.0739 - val_acc: 0.4667\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 0s - loss: 2.7286e-07 - acc: 1.0000 - val_loss: 7.6238 - val_acc: 0.4000\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 0s - loss: 2.6491e-07 - acc: 1.0000 - val_loss: 7.3846 - val_acc: 0.4667\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 0s - loss: 2.6226e-07 - acc: 1.0000 - val_loss: 7.1065 - val_acc: 0.4000\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 0s - loss: 2.5564e-07 - acc: 1.0000 - val_loss: 8.5819 - val_acc: 0.4000\n",
      "Epoch 77/200\n",
      "15/15 [==============================] - 0s - loss: 2.5564e-07 - acc: 1.0000 - val_loss: 6.6510 - val_acc: 0.5333\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 0s - loss: 2.4637e-07 - acc: 1.0000 - val_loss: 8.4113 - val_acc: 0.3333\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 0s - loss: 2.4107e-07 - acc: 1.0000 - val_loss: 9.6772 - val_acc: 0.2000\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 0s - loss: 2.3842e-07 - acc: 1.0000 - val_loss: 6.8529 - val_acc: 0.4667\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 0s - loss: 2.3180e-07 - acc: 1.0000 - val_loss: 6.5462 - val_acc: 0.4667\n",
      "Epoch 82/200\n",
      "15/15 [==============================] - 0s - loss: 2.2915e-07 - acc: 1.0000 - val_loss: 8.7538 - val_acc: 0.3333\n",
      "Epoch 83/200\n",
      "15/15 [==============================] - 0s - loss: 2.2517e-07 - acc: 1.0000 - val_loss: 6.5390 - val_acc: 0.5333\n",
      "Epoch 84/200\n",
      "15/15 [==============================] - 0s - loss: 2.1855e-07 - acc: 1.0000 - val_loss: 7.4101 - val_acc: 0.4667\n",
      "Epoch 85/200\n",
      "15/15 [==============================] - 0s - loss: 2.1590e-07 - acc: 1.0000 - val_loss: 7.5167 - val_acc: 0.4000\n",
      "Epoch 86/200\n",
      "15/15 [==============================] - 0s - loss: 2.1060e-07 - acc: 1.0000 - val_loss: 8.9298 - val_acc: 0.3333\n",
      "Epoch 87/200\n",
      "15/15 [==============================] - 0s - loss: 2.0928e-07 - acc: 1.0000 - val_loss: 6.8983 - val_acc: 0.4000\n",
      "Epoch 88/200\n",
      "15/15 [==============================] - 0s - loss: 2.0663e-07 - acc: 1.0000 - val_loss: 6.3479 - val_acc: 0.4667\n",
      "Epoch 89/200\n",
      "15/15 [==============================] - 0s - loss: 2.0398e-07 - acc: 1.0000 - val_loss: 7.6414 - val_acc: 0.3333\n",
      "Epoch 90/200\n",
      "15/15 [==============================] - 0s - loss: 2.0266e-07 - acc: 1.0000 - val_loss: 9.1534 - val_acc: 0.3333\n",
      "Epoch 91/200\n",
      "15/15 [==============================] - 0s - loss: 1.9868e-07 - acc: 1.0000 - val_loss: 8.3935 - val_acc: 0.3333\n",
      "Epoch 92/200\n",
      "15/15 [==============================] - 0s - loss: 1.9603e-07 - acc: 1.0000 - val_loss: 7.0420 - val_acc: 0.4667\n",
      "Epoch 93/200\n",
      "15/15 [==============================] - 0s - loss: 1.9471e-07 - acc: 1.0000 - val_loss: 8.7722 - val_acc: 0.4000\n",
      "Epoch 94/200\n",
      "15/15 [==============================] - 0s - loss: 1.9073e-07 - acc: 1.0000 - val_loss: 7.7087 - val_acc: 0.4000\n",
      "Epoch 95/200\n",
      "15/15 [==============================] - 0s - loss: 1.8809e-07 - acc: 1.0000 - val_loss: 5.1896 - val_acc: 0.5333\n",
      "Epoch 96/200\n",
      "15/15 [==============================] - 0s - loss: 1.8809e-07 - acc: 1.0000 - val_loss: 8.4921 - val_acc: 0.3333\n",
      "Epoch 97/200\n",
      "15/15 [==============================] - 0s - loss: 1.8544e-07 - acc: 1.0000 - val_loss: 6.0406 - val_acc: 0.5333\n",
      "Epoch 98/200\n",
      "15/15 [==============================] - 0s - loss: 1.8279e-07 - acc: 1.0000 - val_loss: 6.6502 - val_acc: 0.4000\n",
      "Epoch 99/200\n",
      "15/15 [==============================] - 0s - loss: 1.8146e-07 - acc: 1.0000 - val_loss: 7.4358 - val_acc: 0.4667\n",
      "Epoch 100/200\n",
      "15/15 [==============================] - 0s - loss: 1.7881e-07 - acc: 1.0000 - val_loss: 10.1348 - val_acc: 0.2000\n",
      "Epoch 101/200\n",
      "15/15 [==============================] - 0s - loss: 1.7749e-07 - acc: 1.0000 - val_loss: 8.0344 - val_acc: 0.3333\n",
      "Epoch 102/200\n",
      "15/15 [==============================] - 0s - loss: 1.7484e-07 - acc: 1.0000 - val_loss: 6.8441 - val_acc: 0.4000\n",
      "Epoch 103/200\n",
      "15/15 [==============================] - 0s - loss: 1.7352e-07 - acc: 1.0000 - val_loss: 6.9253 - val_acc: 0.4667\n",
      "Epoch 104/200\n",
      "15/15 [==============================] - 0s - loss: 1.7087e-07 - acc: 1.0000 - val_loss: 8.4310 - val_acc: 0.2667\n",
      "Epoch 105/200\n",
      "15/15 [==============================] - 0s - loss: 1.7087e-07 - acc: 1.0000 - val_loss: 7.4960 - val_acc: 0.3333\n",
      "Epoch 106/200\n",
      "15/15 [==============================] - 0s - loss: 1.7087e-07 - acc: 1.0000 - val_loss: 8.4559 - val_acc: 0.3333\n",
      "Epoch 107/200\n",
      "15/15 [==============================] - 0s - loss: 1.6822e-07 - acc: 1.0000 - val_loss: 8.9127 - val_acc: 0.3333\n",
      "Epoch 108/200\n",
      "15/15 [==============================] - 0s - loss: 1.6557e-07 - acc: 1.0000 - val_loss: 7.0113 - val_acc: 0.4000\n",
      "Epoch 109/200\n",
      "15/15 [==============================] - 0s - loss: 1.6424e-07 - acc: 1.0000 - val_loss: 6.5628 - val_acc: 0.4667\n",
      "Epoch 110/200\n",
      "15/15 [==============================] - 0s - loss: 1.6292e-07 - acc: 1.0000 - val_loss: 7.0876 - val_acc: 0.4667\n",
      "Epoch 111/200\n",
      "15/15 [==============================] - 0s - loss: 1.6027e-07 - acc: 1.0000 - val_loss: 5.3079 - val_acc: 0.6000\n",
      "Epoch 112/200\n",
      "15/15 [==============================] - 0s - loss: 1.6159e-07 - acc: 1.0000 - val_loss: 9.1490 - val_acc: 0.3333\n",
      "Epoch 113/200\n",
      "15/15 [==============================] - 0s - loss: 1.6027e-07 - acc: 1.0000 - val_loss: 7.7677 - val_acc: 0.4000\n",
      "Epoch 114/200\n",
      "15/15 [==============================] - 0s - loss: 1.5762e-07 - acc: 1.0000 - val_loss: 6.0085 - val_acc: 0.4667\n",
      "Epoch 115/200\n",
      "15/15 [==============================] - 0s - loss: 1.5630e-07 - acc: 1.0000 - val_loss: 6.2690 - val_acc: 0.5333\n",
      "Epoch 116/200\n",
      "15/15 [==============================] - 0s - loss: 1.5497e-07 - acc: 1.0000 - val_loss: 6.6973 - val_acc: 0.4000\n",
      "Epoch 117/200\n",
      "15/15 [==============================] - 0s - loss: 1.5497e-07 - acc: 1.0000 - val_loss: 5.8210 - val_acc: 0.5333\n",
      "Epoch 118/200\n",
      "15/15 [==============================] - 0s - loss: 1.5365e-07 - acc: 1.0000 - val_loss: 5.7111 - val_acc: 0.5333\n",
      "Epoch 119/200\n",
      "15/15 [==============================] - 0s - loss: 1.5232e-07 - acc: 1.0000 - val_loss: 7.1594 - val_acc: 0.4667\n",
      "Epoch 120/200\n",
      "15/15 [==============================] - 0s - loss: 1.5232e-07 - acc: 1.0000 - val_loss: 7.8351 - val_acc: 0.4000\n",
      "Epoch 121/200\n",
      "15/15 [==============================] - 0s - loss: 1.5100e-07 - acc: 1.0000 - val_loss: 6.7145 - val_acc: 0.4000\n",
      "Epoch 122/200\n",
      "15/15 [==============================] - 0s - loss: 1.5100e-07 - acc: 1.0000 - val_loss: 5.4476 - val_acc: 0.5333\n",
      "Epoch 123/200\n",
      "15/15 [==============================] - 0s - loss: 1.4967e-07 - acc: 1.0000 - val_loss: 8.6913 - val_acc: 0.3333\n",
      "Epoch 124/200\n",
      "15/15 [==============================] - 0s - loss: 1.4835e-07 - acc: 1.0000 - val_loss: 6.4719 - val_acc: 0.4667\n",
      "Epoch 125/200\n",
      "15/15 [==============================] - 0s - loss: 1.4835e-07 - acc: 1.0000 - val_loss: 7.5996 - val_acc: 0.4000\n",
      "Epoch 126/200\n",
      "15/15 [==============================] - 0s - loss: 1.4570e-07 - acc: 1.0000 - val_loss: 8.5704 - val_acc: 0.3333\n",
      "Epoch 127/200\n",
      "15/15 [==============================] - 0s - loss: 1.4702e-07 - acc: 1.0000 - val_loss: 9.5908 - val_acc: 0.2000\n",
      "Epoch 128/200\n",
      "15/15 [==============================] - 0s - loss: 1.4570e-07 - acc: 1.0000 - val_loss: 7.3213 - val_acc: 0.4000\n",
      "Epoch 129/200\n",
      "15/15 [==============================] - 0s - loss: 1.4570e-07 - acc: 1.0000 - val_loss: 8.4013 - val_acc: 0.2667\n",
      "Epoch 130/200\n",
      "15/15 [==============================] - 0s - loss: 1.4570e-07 - acc: 1.0000 - val_loss: 9.5829 - val_acc: 0.2667\n",
      "Epoch 131/200\n",
      "15/15 [==============================] - 0s - loss: 1.4570e-07 - acc: 1.0000 - val_loss: 7.0515 - val_acc: 0.4000\n",
      "Epoch 132/200\n",
      "15/15 [==============================] - 0s - loss: 1.4438e-07 - acc: 1.0000 - val_loss: 6.1821 - val_acc: 0.4667\n",
      "Epoch 133/200\n",
      "15/15 [==============================] - 0s - loss: 1.4305e-07 - acc: 1.0000 - val_loss: 8.6546 - val_acc: 0.2667\n",
      "Epoch 134/200\n",
      "15/15 [==============================] - 0s - loss: 1.4173e-07 - acc: 1.0000 - val_loss: 8.1292 - val_acc: 0.4000\n",
      "Epoch 135/200\n",
      "15/15 [==============================] - 0s - loss: 1.4040e-07 - acc: 1.0000 - val_loss: 7.8129 - val_acc: 0.4000\n",
      "Epoch 136/200\n",
      "15/15 [==============================] - 0s - loss: 1.3908e-07 - acc: 1.0000 - val_loss: 7.8851 - val_acc: 0.4000\n",
      "Epoch 137/200\n",
      "15/15 [==============================] - 0s - loss: 1.3775e-07 - acc: 1.0000 - val_loss: 7.3387 - val_acc: 0.4000\n",
      "Epoch 138/200\n",
      "15/15 [==============================] - 0s - loss: 1.3775e-07 - acc: 1.0000 - val_loss: 6.1552 - val_acc: 0.5333\n",
      "Epoch 139/200\n",
      "15/15 [==============================] - 0s - loss: 1.3775e-07 - acc: 1.0000 - val_loss: 8.7921 - val_acc: 0.2667\n",
      "Epoch 140/200\n",
      "15/15 [==============================] - 0s - loss: 1.3775e-07 - acc: 1.0000 - val_loss: 6.9132 - val_acc: 0.4667\n",
      "Epoch 141/200\n",
      "15/15 [==============================] - 0s - loss: 1.3643e-07 - acc: 1.0000 - val_loss: 4.8366 - val_acc: 0.6000\n",
      "Epoch 142/200\n",
      "15/15 [==============================] - 0s - loss: 1.3643e-07 - acc: 1.0000 - val_loss: 6.8801 - val_acc: 0.4667\n",
      "Epoch 143/200\n",
      "15/15 [==============================] - 0s - loss: 1.3643e-07 - acc: 1.0000 - val_loss: 7.5726 - val_acc: 0.4000\n",
      "Epoch 144/200\n",
      "15/15 [==============================] - 0s - loss: 1.3643e-07 - acc: 1.0000 - val_loss: 7.8616 - val_acc: 0.3333\n",
      "Epoch 145/200\n",
      "15/15 [==============================] - 0s - loss: 1.3643e-07 - acc: 1.0000 - val_loss: 8.0090 - val_acc: 0.4000\n",
      "Epoch 146/200\n",
      "15/15 [==============================] - 0s - loss: 1.3643e-07 - acc: 1.0000 - val_loss: 6.9453 - val_acc: 0.4667\n",
      "Epoch 147/200\n",
      "15/15 [==============================] - 0s - loss: 1.3643e-07 - acc: 1.0000 - val_loss: 6.6573 - val_acc: 0.4000\n",
      "Epoch 148/200\n",
      "15/15 [==============================] - 0s - loss: 1.3643e-07 - acc: 1.0000 - val_loss: 6.9054 - val_acc: 0.4667\n",
      "Epoch 149/200\n",
      "15/15 [==============================] - 0s - loss: 1.3510e-07 - acc: 1.0000 - val_loss: 8.2618 - val_acc: 0.3333\n",
      "Epoch 150/200\n",
      "15/15 [==============================] - 0s - loss: 1.3378e-07 - acc: 1.0000 - val_loss: 5.5844 - val_acc: 0.4667\n",
      "Epoch 151/200\n",
      "15/15 [==============================] - 0s - loss: 1.3378e-07 - acc: 1.0000 - val_loss: 8.4267 - val_acc: 0.3333\n",
      "Epoch 152/200\n",
      "15/15 [==============================] - 0s - loss: 1.3245e-07 - acc: 1.0000 - val_loss: 8.5789 - val_acc: 0.3333\n",
      "Epoch 153/200\n",
      "15/15 [==============================] - 0s - loss: 1.3245e-07 - acc: 1.0000 - val_loss: 6.7966 - val_acc: 0.4000\n",
      "Epoch 154/200\n",
      "15/15 [==============================] - 0s - loss: 1.3245e-07 - acc: 1.0000 - val_loss: 7.7104 - val_acc: 0.4000\n",
      "Epoch 155/200\n",
      "15/15 [==============================] - 0s - loss: 1.3245e-07 - acc: 1.0000 - val_loss: 7.2500 - val_acc: 0.4667\n",
      "Epoch 156/200\n",
      "15/15 [==============================] - 0s - loss: 1.3245e-07 - acc: 1.0000 - val_loss: 6.7464 - val_acc: 0.4667\n",
      "Epoch 157/200\n",
      "15/15 [==============================] - 0s - loss: 1.3245e-07 - acc: 1.0000 - val_loss: 5.8986 - val_acc: 0.4667\n",
      "Epoch 158/200\n",
      "15/15 [==============================] - 0s - loss: 1.3113e-07 - acc: 1.0000 - val_loss: 6.6668 - val_acc: 0.4000\n",
      "Epoch 159/200\n",
      "15/15 [==============================] - 0s - loss: 1.3113e-07 - acc: 1.0000 - val_loss: 8.0227 - val_acc: 0.3333\n",
      "Epoch 160/200\n",
      "15/15 [==============================] - 0s - loss: 1.3113e-07 - acc: 1.0000 - val_loss: 9.1511 - val_acc: 0.2667\n",
      "Epoch 161/200\n",
      "15/15 [==============================] - 0s - loss: 1.2981e-07 - acc: 1.0000 - val_loss: 10.8003 - val_acc: 0.2000\n",
      "Epoch 162/200\n",
      "15/15 [==============================] - 0s - loss: 1.2981e-07 - acc: 1.0000 - val_loss: 9.7507 - val_acc: 0.2667\n",
      "Epoch 163/200\n",
      "15/15 [==============================] - 0s - loss: 1.2848e-07 - acc: 1.0000 - val_loss: 7.1840 - val_acc: 0.4000\n",
      "Epoch 164/200\n",
      "15/15 [==============================] - 0s - loss: 1.2848e-07 - acc: 1.0000 - val_loss: 7.9759 - val_acc: 0.4000\n",
      "Epoch 165/200\n",
      "15/15 [==============================] - 0s - loss: 1.2848e-07 - acc: 1.0000 - val_loss: 5.7556 - val_acc: 0.5333\n",
      "Epoch 166/200\n",
      "15/15 [==============================] - 0s - loss: 1.2848e-07 - acc: 1.0000 - val_loss: 8.7367 - val_acc: 0.3333\n",
      "Epoch 167/200\n",
      "15/15 [==============================] - 0s - loss: 1.2848e-07 - acc: 1.0000 - val_loss: 9.0883 - val_acc: 0.2667\n",
      "Epoch 168/200\n",
      "15/15 [==============================] - 0s - loss: 1.2848e-07 - acc: 1.0000 - val_loss: 8.8050 - val_acc: 0.3333\n",
      "Epoch 169/200\n",
      "15/15 [==============================] - 0s - loss: 1.2848e-07 - acc: 1.0000 - val_loss: 8.6542 - val_acc: 0.4000\n",
      "Epoch 170/200\n",
      "15/15 [==============================] - 0s - loss: 1.2848e-07 - acc: 1.0000 - val_loss: 9.0846 - val_acc: 0.2667\n",
      "Epoch 171/200\n",
      "15/15 [==============================] - 0s - loss: 1.2848e-07 - acc: 1.0000 - val_loss: 7.8792 - val_acc: 0.4000\n",
      "Epoch 172/200\n",
      "15/15 [==============================] - 0s - loss: 1.2848e-07 - acc: 1.0000 - val_loss: 9.3900 - val_acc: 0.2667\n",
      "Epoch 173/200\n",
      "15/15 [==============================] - 0s - loss: 1.2848e-07 - acc: 1.0000 - val_loss: 8.3994 - val_acc: 0.3333\n",
      "Epoch 174/200\n",
      "15/15 [==============================] - 0s - loss: 1.2848e-07 - acc: 1.0000 - val_loss: 5.0293 - val_acc: 0.5333\n",
      "Epoch 175/200\n",
      "15/15 [==============================] - 0s - loss: 1.2716e-07 - acc: 1.0000 - val_loss: 9.4682 - val_acc: 0.2667\n",
      "Epoch 176/200\n",
      "15/15 [==============================] - 0s - loss: 1.2451e-07 - acc: 1.0000 - val_loss: 7.1405 - val_acc: 0.4000\n",
      "Epoch 177/200\n",
      "15/15 [==============================] - 0s - loss: 1.2451e-07 - acc: 1.0000 - val_loss: 7.9561 - val_acc: 0.4000\n",
      "Epoch 178/200\n",
      "15/15 [==============================] - 0s - loss: 1.2451e-07 - acc: 1.0000 - val_loss: 8.4474 - val_acc: 0.3333\n",
      "Epoch 179/200\n",
      "15/15 [==============================] - 0s - loss: 1.2451e-07 - acc: 1.0000 - val_loss: 7.0330 - val_acc: 0.4000\n",
      "Epoch 180/200\n",
      "15/15 [==============================] - 0s - loss: 1.2451e-07 - acc: 1.0000 - val_loss: 6.5707 - val_acc: 0.4667\n",
      "Epoch 181/200\n",
      "15/15 [==============================] - 0s - loss: 1.2451e-07 - acc: 1.0000 - val_loss: 8.9549 - val_acc: 0.2667\n",
      "Epoch 182/200\n",
      "15/15 [==============================] - 0s - loss: 1.2451e-07 - acc: 1.0000 - val_loss: 6.1415 - val_acc: 0.5333\n",
      "Epoch 183/200\n",
      "15/15 [==============================] - 0s - loss: 1.2451e-07 - acc: 1.0000 - val_loss: 8.3273 - val_acc: 0.3333\n",
      "Epoch 184/200\n",
      "15/15 [==============================] - 0s - loss: 1.2451e-07 - acc: 1.0000 - val_loss: 4.7775 - val_acc: 0.6000\n",
      "Epoch 185/200\n",
      "15/15 [==============================] - 0s - loss: 1.2451e-07 - acc: 1.0000 - val_loss: 6.5140 - val_acc: 0.4667\n",
      "Epoch 186/200\n",
      "15/15 [==============================] - 0s - loss: 1.2451e-07 - acc: 1.0000 - val_loss: 9.1230 - val_acc: 0.2667\n",
      "Epoch 187/200\n",
      "15/15 [==============================] - 0s - loss: 1.2451e-07 - acc: 1.0000 - val_loss: 7.0202 - val_acc: 0.4667\n",
      "Epoch 188/200\n",
      "15/15 [==============================] - 0s - loss: 1.2451e-07 - acc: 1.0000 - val_loss: 5.8180 - val_acc: 0.4667\n",
      "Epoch 189/200\n",
      "15/15 [==============================] - 0s - loss: 1.2451e-07 - acc: 1.0000 - val_loss: 8.6923 - val_acc: 0.3333\n",
      "Epoch 190/200\n",
      "15/15 [==============================] - 0s - loss: 1.2451e-07 - acc: 1.0000 - val_loss: 6.3096 - val_acc: 0.5333\n",
      "Epoch 191/200\n",
      "15/15 [==============================] - 0s - loss: 1.2451e-07 - acc: 1.0000 - val_loss: 5.8932 - val_acc: 0.5333\n",
      "Epoch 192/200\n",
      "15/15 [==============================] - 0s - loss: 1.2318e-07 - acc: 1.0000 - val_loss: 6.0174 - val_acc: 0.5333\n",
      "Epoch 193/200\n",
      "15/15 [==============================] - 0s - loss: 1.2318e-07 - acc: 1.0000 - val_loss: 6.0581 - val_acc: 0.4667\n",
      "Epoch 194/200\n",
      "15/15 [==============================] - 0s - loss: 1.2186e-07 - acc: 1.0000 - val_loss: 9.8399 - val_acc: 0.3333\n",
      "Epoch 195/200\n",
      "15/15 [==============================] - 0s - loss: 1.2186e-07 - acc: 1.0000 - val_loss: 4.8865 - val_acc: 0.5333\n",
      "Epoch 196/200\n",
      "15/15 [==============================] - 0s - loss: 1.2186e-07 - acc: 1.0000 - val_loss: 8.4692 - val_acc: 0.3333\n",
      "Epoch 197/200\n",
      "15/15 [==============================] - 0s - loss: 1.2186e-07 - acc: 1.0000 - val_loss: 7.7113 - val_acc: 0.4000\n",
      "Epoch 198/200\n",
      "15/15 [==============================] - 0s - loss: 1.2186e-07 - acc: 1.0000 - val_loss: 7.4234 - val_acc: 0.4667\n",
      "Epoch 199/200\n",
      "15/15 [==============================] - 0s - loss: 1.2186e-07 - acc: 1.0000 - val_loss: 8.7062 - val_acc: 0.3333\n",
      "Epoch 200/200\n",
      "15/15 [==============================] - 0s - loss: 1.2186e-07 - acc: 1.0000 - val_loss: 8.2059 - val_acc: 0.3333\n",
      "-- Evaluate --\n",
      "acc: 46.67%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /Users/tykimos/.theano/compiledir_Darwin-16.6.0-x86_64-i386-64bit-i386-2.7.10-64/lock_dir/lock\n",
      "INFO:theano.gof.compilelock:Refreshing lock /Users/tykimos/.theano/compiledir_Darwin-16.6.0-x86_64-i386-64bit-i386-2.7.10-64/lock_dir/lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Predict --\n",
      "[[0.000 0.000 1.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.001 0.000 0.999]\n",
      " [0.730 0.001 0.269]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 0.012 0.987]\n",
      " [0.000 0.000 1.000]]\n",
      "{'circle': 0, 'triangle': 2, 'rectangle': 1}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 랜덤시드 고정시키기\n",
    "np.random.seed(3)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 데이터셋 불러오기\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'warehouse/hard_handwriting_shape/train',\n",
    "        target_size=(24, 24),\n",
    "        batch_size=3,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'warehouse/hard_handwriting_shape/test',\n",
    "        target_size=(24, 24),    \n",
    "        batch_size=3,\n",
    "        class_mode='categorical')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "\n",
    "# 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(24,24,3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습시키기\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=15,\n",
    "        epochs=200,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=5)\n",
    "\n",
    "# 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "\n",
    "scores = model.evaluate_generator(\n",
    "            test_generator, \n",
    "            steps = 5)\n",
    "\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# 모델 예측하기\n",
    "print(\"-- Predict --\")\n",
    "\n",
    "output = model.predict_generator(\n",
    "            test_generator, \n",
    "            steps = 5)\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "print(output)\n",
    "\n",
    "print(test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수행결과는 40%입니다. 세개 중 하나 찍는 문제인데도 불구하고 50%로 못 넘깁니다. 오버피팅이 제대로 된 모델이라고 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 데이터 부풀리기\n",
    "\n",
    "케라스에서는 `ImageDataGenerator` 함수를 통해서 데이터 부풀리기 기능을 제공합니다. [keras.io](https://keras.io/preprocessing/image/#imagedatagenerator) 페이지를 보면, 아래와 같은 옵션으로 데이터 부풀리기를 할 수 있습니다.\n",
    "\n",
    "    keras.preprocessing.image.ImageDataGenerator(featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=0.,\n",
    "    width_shift_range=0.,\n",
    "    height_shift_range=0.,\n",
    "    shear_range=0.,\n",
    "    zoom_range=0.,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=None,\n",
    "    preprocessing_function=None,\n",
    "    data_format=K.image_data_format())\n",
    "\n",
    "그럼 훈련셋 중 하나인 삼각형을 골라 데이터 부풀리기를 해보겠습니다. 원본이 되는 삼각형은 다음과 같습니다.\n",
    "\n",
    "![data](http://tykimos.github.com/Keras/warehouse/2017-3-8-CNN_Data_Augmentation_4.png)\n",
    "\n",
    "이 삼각형을 ImageDataGenerator 함수을 이용하여 각 파라미터별로 어떻게 부풀리기를 하는 지 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rotation_range = 90\n",
    "지정된 각도 범위내에서 임의로 원본이미지를 회전시킵니다. 단위는 도이며, 정수형입니다. 예를 들어 90이라면 0도에서 90도 사이에 임의의 각도로 회전시킵니다.\n",
    "![data](http://tykimos.github.com/Keras/warehouse/2017-3-8-CNN_Data_Augmentation_5_rotate.png)\n",
    "                                   \n",
    "#### width_shift_range = 0.1\n",
    "지정된 수평방향 이동 범위내에서 임의로 원본이미지를 이동시킵니다. 수치는 전체 넓이의 비율(실수)로 나타냅니다. 예를 들어 0.1이고 전체 넓이가 100이면, 10픽셀 내외로 좌우 이동시킵니다.\n",
    "![data](http://tykimos.github.com/Keras/warehouse/2017-3-8-CNN_Data_Augmentation_5_width_shift.png)\n",
    "\n",
    "#### height_shift_range = 0.1\n",
    "지정된 수직방향 이동 범위내에서 임의로 원본이미지를 이동시킵니다. 수치는 전체 높이의 비율(실수)로 나타냅니다. 예를 들어 0.1이고 전체 높이가 100이면, 10픽셀 내외로 상하 이동시킵니다.\n",
    "![data](http://tykimos.github.com/Keras/warehouse/2017-3-8-CNN_Data_Augmentation_5_height_shift.png)\n",
    "\n",
    "#### shear_range = 0.5\n",
    "밀림 강도 범위내에서 임의로 원본이미지를 변형시킵니다. 수치는 시계반대방향으로 밀림 강도를 라디안으로 나타냅니다. 예를 들어 0.5이라면, 0.5 라이안내외로 시계반대방향으로 변형시킵니다.\n",
    "![data](http://tykimos.github.com/Keras/warehouse/2017-3-8-CNN_Data_Augmentation_5_shear.png)\n",
    "\n",
    "#### zoom_range = 0.3\n",
    "지정된 확대/축소 범위내에서 임의로 원본이미지를 확대/축소합니다. \"1-수치\"부터 \"1+수치\"사이 범위로 확대/축소를 합니다. 예를 들어 0.3이라면, 0.7배에서 1.3배 크기 변화를 시킵니다.\n",
    "![data](http://tykimos.github.com/Keras/warehouse/2017-3-8-CNN_Data_Augmentation_5_zoom.png)\n",
    "\n",
    "#### horizontal_flip = True\n",
    "수평방향으로 뒤집기를 합니다.\n",
    "![data](http://tykimos.github.com/Keras/warehouse/2017-3-8-CNN_Data_Augmentation_5_horizontal_flip.png)\n",
    "\n",
    "#### vertical_flip = True\n",
    "수직방향으로 뒤집기를 합니다.\n",
    "![data](http://tykimos.github.com/Keras/warehouse/2017-3-8-CNN_Data_Augmentation_5_vertical_flip.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드는 ImageDataGenerator함수를 이용하여 지정된 파라미터로 원본이미지에 대해 데이터 부풀리기를 수행한 후 그 결과를 특정 폴더에 저장하는 코드입니다. 여러 파라미터를 사용하였기 때문에 이를 혼합하여 데이터 부풀리기를 수행합니다. 즉 확대/축소도 하고 좌우 이동도 지정하였다면, 축소하면서 좌로 이동된 이미지도 생성됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 랜덤시드 고정시키기\n",
    "np.random.seed(5)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "# 데이터셋 불러오기\n",
    "data_aug_gen = ImageDataGenerator(rescale=1./255, \n",
    "                                  rotation_range=15,\n",
    "                                  width_shift_range=0.1,\n",
    "                                  height_shift_range=0.1,\n",
    "                                  shear_range=0.5,\n",
    "                                  zoom_range=[0.8, 2.0],\n",
    "                                  horizontal_flip=True,\n",
    "                                  vertical_flip=True,\n",
    "                                  fill_mode='nearest')\n",
    "                                   \n",
    "img = load_img('warehouse/hard_handwriting_shape/train/triangle/triangle001.png')\n",
    "x = img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "i = 0\n",
    "\n",
    "# 이 for는 무한으로 반복되기 때문에 우리가 원하는 반복횟수를 지정하여, 지정된 반복횟수가 되면 빠져나오도록 해야합니다.\n",
    "for batch in train_datagen.flow(x, batch_size=1, save_to_dir='warehouse/preview', save_prefix='tri', save_format='png'):\n",
    "    i += 1\n",
    "    if i > 30: \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 코드로 데이터 부풀리기가 수행된 결과 이미지는 다음과 같습니다. 지인이 만든 도전 시험셋 중 비슷한 것들도 보입니다.\n",
    "\n",
    "![data](http://tykimos.github.com/Keras/warehouse/2017-3-8-CNN_Data_Augmentation_5_combination.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 개선 모델 결과보기\n",
    "\n",
    "데이터 부풀리기를 하기 위해서는 기존 코드에서 아래 코드를 추가합니다. 각 파라미터 설정 값에 따라 결과가 다르기 나오니, 실제 데이터에 있을만한 수준으로 적정값을 지정하셔야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 데이터셋 불러오기\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   rotation_range=15,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   shear_range=0.5,\n",
    "                                   zoom_range=[0.8, 2.0],\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수정된 전체 코드는 다음과 같습니다. 참고로 시험셋은 데이터 부풀리기를 할 필요가 없으니, test_datagen 객체 생성 시에는 별도의 파라미터를 추가하지 않았습니다. 그리고 fit_generator함수에서 steps_per_epoch의 값은 기존 15개에서 더 많은 수 (현재 예는 1500개)로 설정합니다. batch_size * steps_per_epoch가 전체 샘플 수 인데, 데이터 부풀리기를 하지 않을 때는 기존의 15개의 배치사이즈(3개)로 전체 45개를 모두 학습에 사용할 수 있지만, ImageDataGenerator함수를 통해 데이터 부풀리기는 할 때는 하나의 샘플로 여러 개의 결과를 얻기 때문에 요청하는 데로 무한의 샘플이 제공됩니다. 여기서는 100배 정도인 1500개로 설정했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /Users/tykimos/.theano/compiledir_Darwin-16.6.0-x86_64-i386-64bit-i386-2.7.10-64/lock_dir/lock\n",
      "INFO:theano.gof.compilelock:Refreshing lock /Users/tykimos/.theano/compiledir_Darwin-16.6.0-x86_64-i386-64bit-i386-2.7.10-64/lock_dir/lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 images belonging to 3 classes.\n",
      "Found 15 images belonging to 3 classes.\n",
      "Epoch 1/200\n",
      "1500/1500 [==============================] - 24s - loss: 0.4396 - acc: 0.8109 - val_loss: 2.0550 - val_acc: 0.6000\n",
      "Epoch 2/200\n",
      "1500/1500 [==============================] - 33s - loss: 0.1672 - acc: 0.9402 - val_loss: 2.9647 - val_acc: 0.6667\n",
      "Epoch 3/200\n",
      "1500/1500 [==============================] - 32s - loss: 0.1236 - acc: 0.9580 - val_loss: 1.9580 - val_acc: 0.7333\n",
      "Epoch 4/200\n",
      "1500/1500 [==============================] - 34s - loss: 0.0885 - acc: 0.9682 - val_loss: 2.6171 - val_acc: 0.6000\n",
      "Epoch 5/200\n",
      "1500/1500 [==============================] - 32s - loss: 0.0629 - acc: 0.9793 - val_loss: 2.1745 - val_acc: 0.7333\n",
      "Epoch 6/200\n",
      "1500/1500 [==============================] - 34s - loss: 0.0511 - acc: 0.9829 - val_loss: 2.8280 - val_acc: 0.7333\n",
      "Epoch 7/200\n",
      "1500/1500 [==============================] - 33s - loss: 0.0478 - acc: 0.9840 - val_loss: 2.8579 - val_acc: 0.6667\n",
      "Epoch 8/200\n",
      "1500/1500 [==============================] - 34s - loss: 0.0485 - acc: 0.9842 - val_loss: 2.6278 - val_acc: 0.7333\n",
      "Epoch 9/200\n",
      "1500/1500 [==============================] - 34s - loss: 0.0490 - acc: 0.9836 - val_loss: 2.0817 - val_acc: 0.7333\n",
      "Epoch 10/200\n",
      "1500/1500 [==============================] - 37s - loss: 0.0413 - acc: 0.9878 - val_loss: 2.8519 - val_acc: 0.6667\n",
      "Epoch 11/200\n",
      "1500/1500 [==============================] - 37s - loss: 0.0627 - acc: 0.9820 - val_loss: 1.2442 - val_acc: 0.7333\n",
      "Epoch 12/200\n",
      "1500/1500 [==============================] - 37s - loss: 0.0301 - acc: 0.9902 - val_loss: 1.9533 - val_acc: 0.7333\n",
      "Epoch 13/200\n",
      "1500/1500 [==============================] - 38s - loss: 0.0349 - acc: 0.9884 - val_loss: 1.4881 - val_acc: 0.8667\n",
      "Epoch 14/200\n",
      " 150/1500 [==>...........................] - ETA: 34s - loss: 0.0569 - acc: 0.9867"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a30a11bb0648>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         validation_steps=5)\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# 모델 평가하기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tykimos/Projects/Keras/venv/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tykimos/Projects/Keras/venv/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1108\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tykimos/Projects/Keras/venv/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tykimos/Projects/Keras/venv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1888\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1889\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1890\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tykimos/Projects/Keras/venv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1631\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1633\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1634\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tykimos/Projects/Keras/venv/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tykimos/Projects/Keras/venv/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tykimos/Projects/Keras/venv/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 랜덤시드 고정시키기\n",
    "np.random.seed(3)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 데이터셋 불러오기\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   rotation_range=10,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.7,\n",
    "                                   zoom_range=[0.9, 2.2],\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'warehouse/hard_handwriting_shape/train',\n",
    "        target_size=(24, 24),\n",
    "        batch_size=3,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'warehouse/hard_handwriting_shape/test',\n",
    "        target_size=(24, 24),    \n",
    "        batch_size=3,\n",
    "        class_mode='categorical')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "\n",
    "from keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(24,24,3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습시키기\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=15 * 100,\n",
    "        epochs=200,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=5)\n",
    "\n",
    "# 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "\n",
    "scores = model.evaluate_generator(\n",
    "            test_generator, \n",
    "            steps = 5)\n",
    "\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# 모델 예측하기\n",
    "print(\"-- Predict --\")\n",
    "\n",
    "output = model.predict_generator(\n",
    "            test_generator, \n",
    "            steps = 5)\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "print(output)\n",
    "\n",
    "print(test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "73.33%의 정확도를 얻었습니다. 만족할만한 수준은 아니지만, 도전 시험셋으로 기존 모델을 시험했을 때의 결과가 50%를 못 미치는 수준에 비하면 비약적인 개선이 일어났습니다. 이는 동일한 모델을 사용하면서 훈련 데이터만 부풀려서 학습을 시켰을 뿐인데 성능 향상이 일어났습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 결론\n",
    "\n",
    "원, 삼각형, 사각형을 분류하는 간단한 문제에서도 개발 모델이 현실에 적용하기 위해서는 어떠한 어려움이 있는 지 알게되었습니다. 그리고 이를 극복하는 방안으로 데이터 부풀리기 방법에 대해서 알아보고, 각 파라미터 별로 어떻게 데이터를 부풀리는 지 생성된 이미지를 통해 살펴보왔습니다. 훈련셋이 충분하지 않거나 시험셋의 다양한 특성을 반영되어 있지 않다면 데이터 부풀리기 방법은 성능 개선에 큰 도움을 줄 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "### 같이 보기\n",
    "\n",
    "* [강좌 목차](https://tykimos.github.io/Keras/lecture/)\n",
    "* 이전 : [딥러닝 모델 이야기/컨볼루션 신경망 레이어 이야기](https://tykimos.github.io/Keras/2017/01/27/CNN_Layer_Talk/)\n",
    "* 다음 : [딥러닝 모델 이야기/순환 신경망 레이어 이야기]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
