{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title:  \"영상입력 수치예측 모델 레시피\"\n",
    "author: 김태영\n",
    "date:   2017-08-20 01:00:00\n",
    "categories: Lecture\n",
    "comments: true\n",
    "image: http://tykimos.github.com/Keras/warehouse/2017-8-20-Image_Input_Numerical_Prediction_Model_Recipe_4m.png\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영상을 입력해서 수치를 예측하는 모델들에 대해서 알아보겠습니다. 수치예측을 위한 영상 데이터셋 생성을 해보고, 다층퍼셉트론 및 컨볼루션 신경망 모델을 구성 및 학습 시켜보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 데이터셋 준비\n",
    "\n",
    "입력 x에 대해 2를 곱해 두 배 정도 값을 갖는 출력 y가 되도록 데이터셋을 생성해봤습니다. 선형회귀 모델을 사용한다면 Y = w * X + b 일 때, w가 2에 가깝고, b가 0.16에 가깝게 되도록 학습시키는 것이 목표입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "width = 16\n",
    "height = 16\n",
    "\n",
    "def generate_dataset(samples):\n",
    "\n",
    "    ds_x = []\n",
    "    ds_y = []\n",
    "    \n",
    "    for it in range(samples):\n",
    "        \n",
    "        num_pt = np.random.randint(0, width * height)\n",
    "        img = generate_image(num_pt)\n",
    "        \n",
    "        ds_y.append(num_pt)\n",
    "        ds_x.append(img)\n",
    "    \n",
    "    return np.array(ds_x), np.array(ds_y).reshape(samples, 1)\n",
    "    \n",
    "def generate_image(points):\n",
    "    \n",
    "    img = np.zeros((width, height))\n",
    "    pts = np.random.random((points, 2))\n",
    "    \n",
    "    for ipt in pts:\n",
    "        img[int(ipt[0] * width), int(ipt[1] * height)] = 1\n",
    "    \n",
    "    return img.reshape(width, height, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = generate_dataset(1000)\n",
    "x_test, y_test = generate_dataset(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAJPCAYAAABcoIE1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAEAGkigAAIAMJFEAAAAZSKIAAAAy/H/ljz8GfNGcngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108128710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터셋 확인\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "        \n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "    sub_plt = axarr[i/plt_row, i%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_train[i].reshape(width, height))\n",
    "    sub_plt.set_title('R ' + str(y_train[i][0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3372.8568     \n",
      "Epoch 2/1000\n",
      "1000/1000 [==============================] - 0s - loss: 401.6964     \n",
      "Epoch 3/1000\n",
      "1000/1000 [==============================] - 0s - loss: 364.6497     \n",
      "Epoch 4/1000\n",
      "1000/1000 [==============================] - 0s - loss: 361.4119     \n",
      "Epoch 5/1000\n",
      "1000/1000 [==============================] - 0s - loss: 359.2307     \n",
      "Epoch 6/1000\n",
      "1000/1000 [==============================] - 0s - loss: 319.8820     \n",
      "Epoch 7/1000\n",
      "1000/1000 [==============================] - 0s - loss: 317.4093     \n",
      "Epoch 8/1000\n",
      "1000/1000 [==============================] - 0s - loss: 289.0775     \n",
      "Epoch 9/1000\n",
      "1000/1000 [==============================] - 0s - loss: 280.7006     \n",
      "Epoch 10/1000\n",
      "1000/1000 [==============================] - 0s - loss: 267.4577     \n",
      "Epoch 11/1000\n",
      "1000/1000 [==============================] - 0s - loss: 227.0421     \n",
      "Epoch 12/1000\n",
      "1000/1000 [==============================] - 0s - loss: 251.0582     \n",
      "Epoch 13/1000\n",
      "1000/1000 [==============================] - 0s - loss: 210.8836     \n",
      "Epoch 14/1000\n",
      "1000/1000 [==============================] - 0s - loss: 217.6128     \n",
      "Epoch 15/1000\n",
      "1000/1000 [==============================] - 0s - loss: 226.5473     \n",
      "Epoch 16/1000\n",
      "1000/1000 [==============================] - 0s - loss: 208.1102     \n",
      "Epoch 17/1000\n",
      "1000/1000 [==============================] - 0s - loss: 213.6190     \n",
      "Epoch 18/1000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 183.339 - 0s - loss: 206.5200     \n",
      "Epoch 19/1000\n",
      "1000/1000 [==============================] - 0s - loss: 178.3548     \n",
      "Epoch 20/1000\n",
      "1000/1000 [==============================] - 0s - loss: 186.4368     \n",
      "Epoch 21/1000\n",
      "1000/1000 [==============================] - 0s - loss: 221.4508     \n",
      "Epoch 22/1000\n",
      "1000/1000 [==============================] - 0s - loss: 161.1829     \n",
      "Epoch 23/1000\n",
      "1000/1000 [==============================] - 0s - loss: 172.0595     \n",
      "Epoch 24/1000\n",
      "1000/1000 [==============================] - 0s - loss: 170.6339     \n",
      "Epoch 25/1000\n",
      "1000/1000 [==============================] - 0s - loss: 175.2484     \n",
      "Epoch 26/1000\n",
      "1000/1000 [==============================] - 0s - loss: 166.9963     \n",
      "Epoch 27/1000\n",
      "1000/1000 [==============================] - 0s - loss: 142.4754     \n",
      "Epoch 28/1000\n",
      "1000/1000 [==============================] - 0s - loss: 158.0515     \n",
      "Epoch 29/1000\n",
      "1000/1000 [==============================] - 0s - loss: 171.7614     \n",
      "Epoch 30/1000\n",
      "1000/1000 [==============================] - 0s - loss: 122.6285     \n",
      "Epoch 31/1000\n",
      "1000/1000 [==============================] - 0s - loss: 153.4460     \n",
      "Epoch 32/1000\n",
      "1000/1000 [==============================] - 0s - loss: 136.2052     \n",
      "Epoch 33/1000\n",
      "1000/1000 [==============================] - 0s - loss: 145.0766     \n",
      "Epoch 34/1000\n",
      "1000/1000 [==============================] - 0s - loss: 124.8507     \n",
      "Epoch 35/1000\n",
      "1000/1000 [==============================] - 0s - loss: 144.7871     \n",
      "Epoch 36/1000\n",
      "1000/1000 [==============================] - 0s - loss: 105.3452    \n",
      "Epoch 37/1000\n",
      "1000/1000 [==============================] - 0s - loss: 144.4140     \n",
      "Epoch 38/1000\n",
      "1000/1000 [==============================] - 0s - loss: 105.6199    \n",
      "Epoch 39/1000\n",
      "1000/1000 [==============================] - 0s - loss: 111.0480     \n",
      "Epoch 40/1000\n",
      "1000/1000 [==============================] - 0s - loss: 124.6849     \n",
      "Epoch 41/1000\n",
      "1000/1000 [==============================] - 0s - loss: 139.6431     \n",
      "Epoch 42/1000\n",
      "1000/1000 [==============================] - 0s - loss: 105.3742    \n",
      "Epoch 43/1000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 105.069 - 0s - loss: 80.1272      \n",
      "Epoch 44/1000\n",
      "1000/1000 [==============================] - 0s - loss: 120.1141     \n",
      "Epoch 45/1000\n",
      "1000/1000 [==============================] - 0s - loss: 113.2195     \n",
      "Epoch 46/1000\n",
      "1000/1000 [==============================] - 0s - loss: 105.0224     \n",
      "Epoch 47/1000\n",
      "1000/1000 [==============================] - 0s - loss: 110.4470     \n",
      "Epoch 48/1000\n",
      "1000/1000 [==============================] - 0s - loss: 98.3004      \n",
      "Epoch 49/1000\n",
      "1000/1000 [==============================] - 0s - loss: 102.8842     \n",
      "Epoch 50/1000\n",
      "1000/1000 [==============================] - 0s - loss: 101.1025     \n",
      "Epoch 51/1000\n",
      "1000/1000 [==============================] - 0s - loss: 121.5049     \n",
      "Epoch 52/1000\n",
      "1000/1000 [==============================] - 0s - loss: 93.9050     \n",
      "Epoch 53/1000\n",
      "1000/1000 [==============================] - 0s - loss: 94.9020     \n",
      "Epoch 54/1000\n",
      "1000/1000 [==============================] - 0s - loss: 82.7306     \n",
      "Epoch 55/1000\n",
      "1000/1000 [==============================] - 0s - loss: 109.1777     \n",
      "Epoch 56/1000\n",
      "1000/1000 [==============================] - 0s - loss: 97.2783     \n",
      "Epoch 57/1000\n",
      "1000/1000 [==============================] - 0s - loss: 86.3693     \n",
      "Epoch 58/1000\n",
      "1000/1000 [==============================] - 0s - loss: 96.0867      \n",
      "Epoch 59/1000\n",
      "1000/1000 [==============================] - 0s - loss: 84.9783     \n",
      "Epoch 60/1000\n",
      "1000/1000 [==============================] - 0s - loss: 89.8749     \n",
      "Epoch 61/1000\n",
      "1000/1000 [==============================] - 0s - loss: 72.0311     \n",
      "Epoch 62/1000\n",
      "1000/1000 [==============================] - 0s - loss: 101.4611     \n",
      "Epoch 63/1000\n",
      "1000/1000 [==============================] - 0s - loss: 85.6594     \n",
      "Epoch 64/1000\n",
      "1000/1000 [==============================] - 0s - loss: 81.6779     \n",
      "Epoch 65/1000\n",
      "1000/1000 [==============================] - 0s - loss: 74.0723     \n",
      "Epoch 66/1000\n",
      "1000/1000 [==============================] - 0s - loss: 92.1145     \n",
      "Epoch 67/1000\n",
      "1000/1000 [==============================] - 0s - loss: 69.7845     \n",
      "Epoch 68/1000\n",
      "1000/1000 [==============================] - 0s - loss: 75.7446     \n",
      "Epoch 69/1000\n",
      "1000/1000 [==============================] - 0s - loss: 90.0318     \n",
      "Epoch 70/1000\n",
      "1000/1000 [==============================] - 0s - loss: 63.1589     \n",
      "Epoch 71/1000\n",
      "1000/1000 [==============================] - 0s - loss: 77.6442     \n",
      "Epoch 72/1000\n",
      "1000/1000 [==============================] - 0s - loss: 81.0892     \n",
      "Epoch 73/1000\n",
      "1000/1000 [==============================] - 0s - loss: 71.0791     \n",
      "Epoch 74/1000\n",
      "1000/1000 [==============================] - 0s - loss: 71.7400     \n",
      "Epoch 75/1000\n",
      "1000/1000 [==============================] - 0s - loss: 84.1235     \n",
      "Epoch 76/1000\n",
      "1000/1000 [==============================] - 0s - loss: 60.8417     \n",
      "Epoch 77/1000\n",
      "1000/1000 [==============================] - 0s - loss: 74.9303     \n",
      "Epoch 78/1000\n",
      "1000/1000 [==============================] - 0s - loss: 62.6833     \n",
      "Epoch 79/1000\n",
      "1000/1000 [==============================] - 0s - loss: 79.8462     \n",
      "Epoch 80/1000\n",
      "1000/1000 [==============================] - 0s - loss: 58.8884     \n",
      "Epoch 81/1000\n",
      "1000/1000 [==============================] - 0s - loss: 57.5496     \n",
      "Epoch 82/1000\n",
      "1000/1000 [==============================] - 0s - loss: 75.6184     \n",
      "Epoch 83/1000\n",
      "1000/1000 [==============================] - 0s - loss: 68.6624     \n",
      "Epoch 84/1000\n",
      "1000/1000 [==============================] - 0s - loss: 59.7555     \n",
      "Epoch 85/1000\n",
      "1000/1000 [==============================] - 0s - loss: 70.3658     \n",
      "Epoch 86/1000\n",
      "1000/1000 [==============================] - 0s - loss: 63.8998     \n",
      "Epoch 87/1000\n",
      "1000/1000 [==============================] - 0s - loss: 59.1950     \n",
      "Epoch 88/1000\n",
      "1000/1000 [==============================] - 0s - loss: 71.1385     \n",
      "Epoch 89/1000\n",
      "1000/1000 [==============================] - 0s - loss: 62.3575     \n",
      "Epoch 90/1000\n",
      "1000/1000 [==============================] - 0s - loss: 57.2546     \n",
      "Epoch 91/1000\n",
      "1000/1000 [==============================] - 0s - loss: 68.9903     \n",
      "Epoch 92/1000\n",
      "1000/1000 [==============================] - 0s - loss: 61.9487     \n",
      "Epoch 93/1000\n",
      "1000/1000 [==============================] - 0s - loss: 64.2050     \n",
      "Epoch 94/1000\n",
      "1000/1000 [==============================] - 0s - loss: 70.0547     \n",
      "Epoch 95/1000\n",
      "1000/1000 [==============================] - 0s - loss: 54.7733     \n",
      "Epoch 96/1000\n",
      "1000/1000 [==============================] - 0s - loss: 63.5154     \n",
      "Epoch 97/1000\n",
      "1000/1000 [==============================] - 0s - loss: 58.4174     \n",
      "Epoch 98/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 60.0306     \n",
      "Epoch 99/1000\n",
      "1000/1000 [==============================] - 0s - loss: 55.4822     \n",
      "Epoch 100/1000\n",
      "1000/1000 [==============================] - 0s - loss: 58.6683     \n",
      "Epoch 101/1000\n",
      "1000/1000 [==============================] - 0s - loss: 49.2684     \n",
      "Epoch 102/1000\n",
      "1000/1000 [==============================] - 0s - loss: 70.8393     \n",
      "Epoch 103/1000\n",
      "1000/1000 [==============================] - 0s - loss: 52.9041     \n",
      "Epoch 104/1000\n",
      "1000/1000 [==============================] - 0s - loss: 59.0998     \n",
      "Epoch 105/1000\n",
      "1000/1000 [==============================] - 0s - loss: 51.8130     \n",
      "Epoch 106/1000\n",
      "1000/1000 [==============================] - 0s - loss: 55.5622     \n",
      "Epoch 107/1000\n",
      "1000/1000 [==============================] - 0s - loss: 59.9182     \n",
      "Epoch 108/1000\n",
      "1000/1000 [==============================] - 0s - loss: 56.1729     \n",
      "Epoch 109/1000\n",
      "1000/1000 [==============================] - 0s - loss: 50.7031     \n",
      "Epoch 110/1000\n",
      "1000/1000 [==============================] - 0s - loss: 57.5770     \n",
      "Epoch 111/1000\n",
      "1000/1000 [==============================] - 0s - loss: 51.5633     \n",
      "Epoch 112/1000\n",
      "1000/1000 [==============================] - 0s - loss: 53.5305     \n",
      "Epoch 113/1000\n",
      "1000/1000 [==============================] - 0s - loss: 54.1879     \n",
      "Epoch 114/1000\n",
      "1000/1000 [==============================] - 0s - loss: 55.8983     \n",
      "Epoch 115/1000\n",
      "1000/1000 [==============================] - 0s - loss: 57.9214     \n",
      "Epoch 116/1000\n",
      "1000/1000 [==============================] - 0s - loss: 53.8438     \n",
      "Epoch 117/1000\n",
      "1000/1000 [==============================] - 0s - loss: 41.1274     \n",
      "Epoch 118/1000\n",
      "1000/1000 [==============================] - 0s - loss: 55.1242     \n",
      "Epoch 119/1000\n",
      "1000/1000 [==============================] - 0s - loss: 59.1254     \n",
      "Epoch 120/1000\n",
      "1000/1000 [==============================] - 0s - loss: 45.6123     \n",
      "Epoch 121/1000\n",
      "1000/1000 [==============================] - 0s - loss: 48.2122     \n",
      "Epoch 122/1000\n",
      "1000/1000 [==============================] - 0s - loss: 48.2847     \n",
      "Epoch 123/1000\n",
      "1000/1000 [==============================] - 0s - loss: 54.5630     \n",
      "Epoch 124/1000\n",
      "1000/1000 [==============================] - 0s - loss: 47.0683     \n",
      "Epoch 125/1000\n",
      "1000/1000 [==============================] - 0s - loss: 46.6005     \n",
      "Epoch 126/1000\n",
      "1000/1000 [==============================] - 0s - loss: 49.6925     \n",
      "Epoch 127/1000\n",
      "1000/1000 [==============================] - 0s - loss: 55.2284     \n",
      "Epoch 128/1000\n",
      "1000/1000 [==============================] - 0s - loss: 52.2621     \n",
      "Epoch 129/1000\n",
      "1000/1000 [==============================] - 0s - loss: 45.1577     \n",
      "Epoch 130/1000\n",
      "1000/1000 [==============================] - 0s - loss: 49.3334     \n",
      "Epoch 131/1000\n",
      "1000/1000 [==============================] - 0s - loss: 45.1377     \n",
      "Epoch 132/1000\n",
      "1000/1000 [==============================] - 0s - loss: 48.2211     \n",
      "Epoch 133/1000\n",
      "1000/1000 [==============================] - 0s - loss: 43.2721     \n",
      "Epoch 134/1000\n",
      "1000/1000 [==============================] - 0s - loss: 42.5470     \n",
      "Epoch 135/1000\n",
      "1000/1000 [==============================] - 0s - loss: 47.9373     \n",
      "Epoch 136/1000\n",
      "1000/1000 [==============================] - 0s - loss: 48.2095     \n",
      "Epoch 137/1000\n",
      "1000/1000 [==============================] - 0s - loss: 46.5912     \n",
      "Epoch 138/1000\n",
      "1000/1000 [==============================] - 0s - loss: 37.2042     \n",
      "Epoch 139/1000\n",
      "1000/1000 [==============================] - 0s - loss: 47.3004     \n",
      "Epoch 140/1000\n",
      "1000/1000 [==============================] - 0s - loss: 48.9009     \n",
      "Epoch 141/1000\n",
      "1000/1000 [==============================] - 0s - loss: 51.1370     \n",
      "Epoch 142/1000\n",
      "1000/1000 [==============================] - 0s - loss: 42.8133     \n",
      "Epoch 143/1000\n",
      "1000/1000 [==============================] - 0s - loss: 47.1564     \n",
      "Epoch 144/1000\n",
      "1000/1000 [==============================] - 0s - loss: 53.9681     \n",
      "Epoch 145/1000\n",
      "1000/1000 [==============================] - 0s - loss: 36.5306     \n",
      "Epoch 146/1000\n",
      "1000/1000 [==============================] - 0s - loss: 47.2127     \n",
      "Epoch 147/1000\n",
      "1000/1000 [==============================] - 0s - loss: 45.2411     \n",
      "Epoch 148/1000\n",
      "1000/1000 [==============================] - 0s - loss: 43.1416     \n",
      "Epoch 149/1000\n",
      "1000/1000 [==============================] - 0s - loss: 43.8447     \n",
      "Epoch 150/1000\n",
      "1000/1000 [==============================] - 0s - loss: 43.6344     \n",
      "Epoch 151/1000\n",
      "1000/1000 [==============================] - 0s - loss: 45.3526     \n",
      "Epoch 152/1000\n",
      "1000/1000 [==============================] - 0s - loss: 40.8349     \n",
      "Epoch 153/1000\n",
      "1000/1000 [==============================] - 0s - loss: 44.9447     \n",
      "Epoch 154/1000\n",
      "1000/1000 [==============================] - 0s - loss: 30.2811     \n",
      "Epoch 155/1000\n",
      "1000/1000 [==============================] - 0s - loss: 51.4758     \n",
      "Epoch 156/1000\n",
      "1000/1000 [==============================] - 0s - loss: 38.2756     \n",
      "Epoch 157/1000\n",
      "1000/1000 [==============================] - 0s - loss: 34.1291     \n",
      "Epoch 158/1000\n",
      "1000/1000 [==============================] - 0s - loss: 47.8362     \n",
      "Epoch 159/1000\n",
      "1000/1000 [==============================] - 0s - loss: 37.2698     \n",
      "Epoch 160/1000\n",
      "1000/1000 [==============================] - 0s - loss: 40.5175     \n",
      "Epoch 161/1000\n",
      "1000/1000 [==============================] - 0s - loss: 44.6355     \n",
      "Epoch 162/1000\n",
      "1000/1000 [==============================] - 0s - loss: 39.1405     \n",
      "Epoch 163/1000\n",
      "1000/1000 [==============================] - 0s - loss: 44.2812     \n",
      "Epoch 164/1000\n",
      "1000/1000 [==============================] - 0s - loss: 40.3385     \n",
      "Epoch 165/1000\n",
      "1000/1000 [==============================] - 0s - loss: 42.0468     \n",
      "Epoch 166/1000\n",
      "1000/1000 [==============================] - 0s - loss: 39.6703     \n",
      "Epoch 167/1000\n",
      "1000/1000 [==============================] - 0s - loss: 32.0094     \n",
      "Epoch 168/1000\n",
      "1000/1000 [==============================] - 0s - loss: 44.9583     \n",
      "Epoch 169/1000\n",
      "1000/1000 [==============================] - 0s - loss: 38.1172     \n",
      "Epoch 170/1000\n",
      "1000/1000 [==============================] - 0s - loss: 34.7443     \n",
      "Epoch 171/1000\n",
      "1000/1000 [==============================] - 0s - loss: 41.7521     \n",
      "Epoch 172/1000\n",
      "1000/1000 [==============================] - 0s - loss: 40.2772     \n",
      "Epoch 173/1000\n",
      "1000/1000 [==============================] - 0s - loss: 33.9172     \n",
      "Epoch 174/1000\n",
      "1000/1000 [==============================] - 0s - loss: 44.5308     \n",
      "Epoch 175/1000\n",
      "1000/1000 [==============================] - 0s - loss: 30.7818     \n",
      "Epoch 176/1000\n",
      "1000/1000 [==============================] - 0s - loss: 38.8054     \n",
      "Epoch 177/1000\n",
      "1000/1000 [==============================] - 0s - loss: 43.1780     \n",
      "Epoch 178/1000\n",
      "1000/1000 [==============================] - 0s - loss: 36.1964     \n",
      "Epoch 179/1000\n",
      "1000/1000 [==============================] - 0s - loss: 35.4420     \n",
      "Epoch 180/1000\n",
      "1000/1000 [==============================] - 0s - loss: 39.9674     \n",
      "Epoch 181/1000\n",
      "1000/1000 [==============================] - 0s - loss: 30.1142     \n",
      "Epoch 182/1000\n",
      "1000/1000 [==============================] - 0s - loss: 41.8110     \n",
      "Epoch 183/1000\n",
      "1000/1000 [==============================] - 0s - loss: 35.9667     \n",
      "Epoch 184/1000\n",
      "1000/1000 [==============================] - 0s - loss: 36.5478     \n",
      "Epoch 185/1000\n",
      "1000/1000 [==============================] - 0s - loss: 29.3853     \n",
      "Epoch 186/1000\n",
      "1000/1000 [==============================] - 0s - loss: 37.3399     \n",
      "Epoch 187/1000\n",
      "1000/1000 [==============================] - 0s - loss: 33.9095     \n",
      "Epoch 188/1000\n",
      "1000/1000 [==============================] - 0s - loss: 40.0376     \n",
      "Epoch 189/1000\n",
      "1000/1000 [==============================] - 0s - loss: 31.8627     \n",
      "Epoch 190/1000\n",
      "1000/1000 [==============================] - 0s - loss: 39.4018     \n",
      "Epoch 191/1000\n",
      "1000/1000 [==============================] - 0s - loss: 35.0635     \n",
      "Epoch 192/1000\n",
      "1000/1000 [==============================] - 0s - loss: 33.8238     \n",
      "Epoch 193/1000\n",
      "1000/1000 [==============================] - 0s - loss: 33.4878     \n",
      "Epoch 194/1000\n",
      "1000/1000 [==============================] - 0s - loss: 36.0970     \n",
      "Epoch 195/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 29.9053     \n",
      "Epoch 196/1000\n",
      "1000/1000 [==============================] - 0s - loss: 36.4593     \n",
      "Epoch 197/1000\n",
      "1000/1000 [==============================] - 0s - loss: 35.1264     \n",
      "Epoch 198/1000\n",
      "1000/1000 [==============================] - 0s - loss: 35.2862     \n",
      "Epoch 199/1000\n",
      "1000/1000 [==============================] - 0s - loss: 30.7158     \n",
      "Epoch 200/1000\n",
      "1000/1000 [==============================] - 0s - loss: 32.8764     \n",
      "Epoch 201/1000\n",
      "1000/1000 [==============================] - 0s - loss: 33.5015     \n",
      "Epoch 202/1000\n",
      "1000/1000 [==============================] - 0s - loss: 36.5176     \n",
      "Epoch 203/1000\n",
      "1000/1000 [==============================] - 0s - loss: 33.9898     \n",
      "Epoch 204/1000\n",
      "1000/1000 [==============================] - 0s - loss: 31.8381     \n",
      "Epoch 205/1000\n",
      "1000/1000 [==============================] - 0s - loss: 30.6989     \n",
      "Epoch 206/1000\n",
      "1000/1000 [==============================] - 0s - loss: 36.8207     \n",
      "Epoch 207/1000\n",
      "1000/1000 [==============================] - 0s - loss: 32.1711     \n",
      "Epoch 208/1000\n",
      "1000/1000 [==============================] - 0s - loss: 27.9575     \n",
      "Epoch 209/1000\n",
      "1000/1000 [==============================] - 0s - loss: 36.8730     \n",
      "Epoch 210/1000\n",
      "1000/1000 [==============================] - 0s - loss: 30.0692     \n",
      "Epoch 211/1000\n",
      "1000/1000 [==============================] - 0s - loss: 31.4117     \n",
      "Epoch 212/1000\n",
      "1000/1000 [==============================] - 0s - loss: 35.0907     \n",
      "Epoch 213/1000\n",
      "1000/1000 [==============================] - 0s - loss: 27.7915     \n",
      "Epoch 214/1000\n",
      "1000/1000 [==============================] - 0s - loss: 33.0334     \n",
      "Epoch 215/1000\n",
      "1000/1000 [==============================] - 0s - loss: 30.1509     \n",
      "Epoch 216/1000\n",
      "1000/1000 [==============================] - 0s - loss: 35.2077     \n",
      "Epoch 217/1000\n",
      "1000/1000 [==============================] - 0s - loss: 31.0904     \n",
      "Epoch 218/1000\n",
      "1000/1000 [==============================] - 0s - loss: 29.7819     \n",
      "Epoch 219/1000\n",
      "1000/1000 [==============================] - 0s - loss: 31.9365     \n",
      "Epoch 220/1000\n",
      "1000/1000 [==============================] - 0s - loss: 31.7504     \n",
      "Epoch 221/1000\n",
      "1000/1000 [==============================] - 0s - loss: 30.1301     \n",
      "Epoch 222/1000\n",
      "1000/1000 [==============================] - 0s - loss: 31.6523     \n",
      "Epoch 223/1000\n",
      "1000/1000 [==============================] - 0s - loss: 34.7394     \n",
      "Epoch 224/1000\n",
      "1000/1000 [==============================] - 0s - loss: 32.8349     \n",
      "Epoch 225/1000\n",
      "1000/1000 [==============================] - 0s - loss: 30.1755     \n",
      "Epoch 226/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.7190     \n",
      "Epoch 227/1000\n",
      "1000/1000 [==============================] - 0s - loss: 28.2775     \n",
      "Epoch 228/1000\n",
      "1000/1000 [==============================] - 0s - loss: 33.7663     \n",
      "Epoch 229/1000\n",
      "1000/1000 [==============================] - 0s - loss: 28.2528     \n",
      "Epoch 230/1000\n",
      "1000/1000 [==============================] - 0s - loss: 33.9110     \n",
      "Epoch 231/1000\n",
      "1000/1000 [==============================] - 0s - loss: 25.6856     \n",
      "Epoch 232/1000\n",
      "1000/1000 [==============================] - 0s - loss: 32.2528     \n",
      "Epoch 233/1000\n",
      "1000/1000 [==============================] - 0s - loss: 32.0707     \n",
      "Epoch 234/1000\n",
      "1000/1000 [==============================] - 0s - loss: 30.9430     \n",
      "Epoch 235/1000\n",
      "1000/1000 [==============================] - 0s - loss: 28.3705     \n",
      "Epoch 236/1000\n",
      "1000/1000 [==============================] - 0s - loss: 29.2391     \n",
      "Epoch 237/1000\n",
      "1000/1000 [==============================] - 0s - loss: 29.4933     \n",
      "Epoch 238/1000\n",
      "1000/1000 [==============================] - 0s - loss: 28.5274     \n",
      "Epoch 239/1000\n",
      "1000/1000 [==============================] - 0s - loss: 30.4415     \n",
      "Epoch 240/1000\n",
      "1000/1000 [==============================] - 0s - loss: 32.4359     \n",
      "Epoch 241/1000\n",
      "1000/1000 [==============================] - 0s - loss: 24.6154     \n",
      "Epoch 242/1000\n",
      "1000/1000 [==============================] - 0s - loss: 34.1022     \n",
      "Epoch 243/1000\n",
      "1000/1000 [==============================] - 0s - loss: 24.8362     \n",
      "Epoch 244/1000\n",
      "1000/1000 [==============================] - 0s - loss: 25.4203     \n",
      "Epoch 245/1000\n",
      "1000/1000 [==============================] - 0s - loss: 30.3243     \n",
      "Epoch 246/1000\n",
      "1000/1000 [==============================] - 0s - loss: 28.8693     \n",
      "Epoch 247/1000\n",
      "1000/1000 [==============================] - 0s - loss: 26.0139     \n",
      "Epoch 248/1000\n",
      "1000/1000 [==============================] - 0s - loss: 31.7424     \n",
      "Epoch 249/1000\n",
      "1000/1000 [==============================] - 0s - loss: 25.7432     \n",
      "Epoch 250/1000\n",
      "1000/1000 [==============================] - 0s - loss: 31.3293     \n",
      "Epoch 251/1000\n",
      "1000/1000 [==============================] - 0s - loss: 22.5872     \n",
      "Epoch 252/1000\n",
      "1000/1000 [==============================] - 0s - loss: 32.8169     \n",
      "Epoch 253/1000\n",
      "1000/1000 [==============================] - 0s - loss: 24.6288     \n",
      "Epoch 254/1000\n",
      "1000/1000 [==============================] - 0s - loss: 22.9149     \n",
      "Epoch 255/1000\n",
      "1000/1000 [==============================] - 0s - loss: 33.0551     \n",
      "Epoch 256/1000\n",
      "1000/1000 [==============================] - 0s - loss: 26.1300     \n",
      "Epoch 257/1000\n",
      "1000/1000 [==============================] - 0s - loss: 25.1300     \n",
      "Epoch 258/1000\n",
      "1000/1000 [==============================] - 0s - loss: 31.2193     \n",
      "Epoch 259/1000\n",
      "1000/1000 [==============================] - 0s - loss: 27.7204     \n",
      "Epoch 260/1000\n",
      "1000/1000 [==============================] - 0s - loss: 24.1656     \n",
      "Epoch 261/1000\n",
      "1000/1000 [==============================] - 0s - loss: 26.5202     \n",
      "Epoch 262/1000\n",
      "1000/1000 [==============================] - 0s - loss: 28.3581     \n",
      "Epoch 263/1000\n",
      "1000/1000 [==============================] - 0s - loss: 27.1023     \n",
      "Epoch 264/1000\n",
      "1000/1000 [==============================] - 0s - loss: 26.5407     \n",
      "Epoch 265/1000\n",
      "1000/1000 [==============================] - 0s - loss: 32.1973     \n",
      "Epoch 266/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.8206     \n",
      "Epoch 267/1000\n",
      "1000/1000 [==============================] - 0s - loss: 32.2665     \n",
      "Epoch 268/1000\n",
      "1000/1000 [==============================] - 0s - loss: 26.9048     \n",
      "Epoch 269/1000\n",
      "1000/1000 [==============================] - 0s - loss: 23.8102     \n",
      "Epoch 270/1000\n",
      "1000/1000 [==============================] - 0s - loss: 26.1872     \n",
      "Epoch 271/1000\n",
      "1000/1000 [==============================] - 0s - loss: 26.4454     \n",
      "Epoch 272/1000\n",
      "1000/1000 [==============================] - 0s - loss: 27.4221     \n",
      "Epoch 273/1000\n",
      "1000/1000 [==============================] - 0s - loss: 26.5636     \n",
      "Epoch 274/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.6616     \n",
      "Epoch 275/1000\n",
      "1000/1000 [==============================] - 0s - loss: 27.1214     \n",
      "Epoch 276/1000\n",
      "1000/1000 [==============================] - 0s - loss: 29.4463     \n",
      "Epoch 277/1000\n",
      "1000/1000 [==============================] - 0s - loss: 24.5448     \n",
      "Epoch 278/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.7202     \n",
      "Epoch 279/1000\n",
      "1000/1000 [==============================] - 0s - loss: 24.5706     \n",
      "Epoch 280/1000\n",
      "1000/1000 [==============================] - 0s - loss: 28.7400     \n",
      "Epoch 281/1000\n",
      "1000/1000 [==============================] - 0s - loss: 25.4620     \n",
      "Epoch 282/1000\n",
      "1000/1000 [==============================] - 0s - loss: 23.7684     \n",
      "Epoch 283/1000\n",
      "1000/1000 [==============================] - 0s - loss: 28.8810     \n",
      "Epoch 284/1000\n",
      "1000/1000 [==============================] - 0s - loss: 27.0152     \n",
      "Epoch 285/1000\n",
      "1000/1000 [==============================] - 0s - loss: 26.4281     \n",
      "Epoch 286/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.3974     \n",
      "Epoch 287/1000\n",
      "1000/1000 [==============================] - 0s - loss: 28.2384     \n",
      "Epoch 288/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.5096     \n",
      "Epoch 289/1000\n",
      "1000/1000 [==============================] - 0s - loss: 27.1154     \n",
      "Epoch 290/1000\n",
      "1000/1000 [==============================] - 0s - loss: 24.7386     \n",
      "Epoch 291/1000\n",
      "1000/1000 [==============================] - 0s - loss: 33.0089     \n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 17.9837     \n",
      "Epoch 293/1000\n",
      "1000/1000 [==============================] - 0s - loss: 29.2267     \n",
      "Epoch 294/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.7841     \n",
      "Epoch 295/1000\n",
      "1000/1000 [==============================] - 0s - loss: 27.5341     \n",
      "Epoch 296/1000\n",
      "1000/1000 [==============================] - 0s - loss: 23.2506     \n",
      "Epoch 297/1000\n",
      "1000/1000 [==============================] - 0s - loss: 24.2560     \n",
      "Epoch 298/1000\n",
      "1000/1000 [==============================] - 0s - loss: 25.7382     \n",
      "Epoch 299/1000\n",
      "1000/1000 [==============================] - 0s - loss: 23.5163     \n",
      "Epoch 300/1000\n",
      "1000/1000 [==============================] - 0s - loss: 25.6205     \n",
      "Epoch 301/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.9404     \n",
      "Epoch 302/1000\n",
      "1000/1000 [==============================] - 0s - loss: 23.0078     \n",
      "Epoch 303/1000\n",
      "1000/1000 [==============================] - 0s - loss: 26.4939     \n",
      "Epoch 304/1000\n",
      "1000/1000 [==============================] - 0s - loss: 25.1494     \n",
      "Epoch 305/1000\n",
      "1000/1000 [==============================] - 0s - loss: 24.4980     \n",
      "Epoch 306/1000\n",
      "1000/1000 [==============================] - 0s - loss: 26.3338     \n",
      "Epoch 307/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.4925     \n",
      "Epoch 308/1000\n",
      "1000/1000 [==============================] - 0s - loss: 26.3066     \n",
      "Epoch 309/1000\n",
      "1000/1000 [==============================] - 0s - loss: 23.3797     \n",
      "Epoch 310/1000\n",
      "1000/1000 [==============================] - 0s - loss: 23.7827     \n",
      "Epoch 311/1000\n",
      "1000/1000 [==============================] - 0s - loss: 22.7240     \n",
      "Epoch 312/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.7827     \n",
      "Epoch 313/1000\n",
      "1000/1000 [==============================] - 0s - loss: 29.0347     \n",
      "Epoch 314/1000\n",
      "1000/1000 [==============================] - 0s - loss: 26.3386     \n",
      "Epoch 315/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.0836     \n",
      "Epoch 316/1000\n",
      "1000/1000 [==============================] - 0s - loss: 25.5413     \n",
      "Epoch 317/1000\n",
      "1000/1000 [==============================] - 0s - loss: 27.1049     \n",
      "Epoch 318/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.7938     \n",
      "Epoch 319/1000\n",
      "1000/1000 [==============================] - 0s - loss: 25.6916     \n",
      "Epoch 320/1000\n",
      "1000/1000 [==============================] - 0s - loss: 23.3005     \n",
      "Epoch 321/1000\n",
      "1000/1000 [==============================] - 0s - loss: 23.9076     \n",
      "Epoch 322/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.9358     \n",
      "Epoch 323/1000\n",
      "1000/1000 [==============================] - 0s - loss: 25.5993     \n",
      "Epoch 324/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.8430     \n",
      "Epoch 325/1000\n",
      "1000/1000 [==============================] - 0s - loss: 23.5145     \n",
      "Epoch 326/1000\n",
      "1000/1000 [==============================] - 0s - loss: 23.3209     \n",
      "Epoch 327/1000\n",
      "1000/1000 [==============================] - 0s - loss: 26.4515     \n",
      "Epoch 328/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.2080     \n",
      "Epoch 329/1000\n",
      "1000/1000 [==============================] - 0s - loss: 22.4055     \n",
      "Epoch 330/1000\n",
      "1000/1000 [==============================] - 0s - loss: 22.3662     \n",
      "Epoch 331/1000\n",
      "1000/1000 [==============================] - 0s - loss: 27.4274     \n",
      "Epoch 332/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.3381     \n",
      "Epoch 333/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.3320     \n",
      "Epoch 334/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.6476     \n",
      "Epoch 335/1000\n",
      "1000/1000 [==============================] - 0s - loss: 22.8563     \n",
      "Epoch 336/1000\n",
      "1000/1000 [==============================] - 0s - loss: 22.9261     \n",
      "Epoch 337/1000\n",
      "1000/1000 [==============================] - 0s - loss: 24.2241     \n",
      "Epoch 338/1000\n",
      "1000/1000 [==============================] - 0s - loss: 23.6455     \n",
      "Epoch 339/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.3518     \n",
      "Epoch 340/1000\n",
      "1000/1000 [==============================] - 0s - loss: 27.6354     \n",
      "Epoch 341/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.0292     \n",
      "Epoch 342/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.7626     \n",
      "Epoch 343/1000\n",
      "1000/1000 [==============================] - 0s - loss: 24.6424     \n",
      "Epoch 344/1000\n",
      "1000/1000 [==============================] - 0s - loss: 24.6625     \n",
      "Epoch 345/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.9738     \n",
      "Epoch 346/1000\n",
      "1000/1000 [==============================] - 0s - loss: 23.6533     \n",
      "Epoch 347/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.0124     \n",
      "Epoch 348/1000\n",
      "1000/1000 [==============================] - 0s - loss: 23.4709     \n",
      "Epoch 349/1000\n",
      "1000/1000 [==============================] - 0s - loss: 22.0181     \n",
      "Epoch 350/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.3612     \n",
      "Epoch 351/1000\n",
      "1000/1000 [==============================] - 0s - loss: 24.1982     \n",
      "Epoch 352/1000\n",
      "1000/1000 [==============================] - 0s - loss: 24.6177     \n",
      "Epoch 353/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.1114     \n",
      "Epoch 354/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.9195     \n",
      "Epoch 355/1000\n",
      "1000/1000 [==============================] - 0s - loss: 23.1999     \n",
      "Epoch 356/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.1819     \n",
      "Epoch 357/1000\n",
      "1000/1000 [==============================] - 0s - loss: 23.0098     \n",
      "Epoch 358/1000\n",
      "1000/1000 [==============================] - 0s - loss: 24.1275     \n",
      "Epoch 359/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.5245     \n",
      "Epoch 360/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.0562     \n",
      "Epoch 361/1000\n",
      "1000/1000 [==============================] - 0s - loss: 24.2159     \n",
      "Epoch 362/1000\n",
      "1000/1000 [==============================] - 0s - loss: 23.8776     \n",
      "Epoch 363/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.6572     \n",
      "Epoch 364/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.0854     \n",
      "Epoch 365/1000\n",
      "1000/1000 [==============================] - 0s - loss: 26.3029     \n",
      "Epoch 366/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.3762     \n",
      "Epoch 367/1000\n",
      "1000/1000 [==============================] - 0s - loss: 22.8964     \n",
      "Epoch 368/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.5461     \n",
      "Epoch 369/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.9832     \n",
      "Epoch 370/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.7977     \n",
      "Epoch 371/1000\n",
      "1000/1000 [==============================] - 0s - loss: 22.5984     \n",
      "Epoch 372/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.9911     \n",
      "Epoch 373/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.4926     \n",
      "Epoch 374/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.3896     \n",
      "Epoch 375/1000\n",
      "1000/1000 [==============================] - 0s - loss: 22.5173     \n",
      "Epoch 376/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.8588     \n",
      "Epoch 377/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.7476     \n",
      "Epoch 378/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.8211     \n",
      "Epoch 379/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.2012     \n",
      "Epoch 380/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.1702     \n",
      "Epoch 381/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.6170     \n",
      "Epoch 382/1000\n",
      "1000/1000 [==============================] - 0s - loss: 22.8789     \n",
      "Epoch 383/1000\n",
      "1000/1000 [==============================] - 0s - loss: 22.1810     \n",
      "Epoch 384/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.7016     \n",
      "Epoch 385/1000\n",
      "1000/1000 [==============================] - 0s - loss: 23.0276     \n",
      "Epoch 386/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.2362     \n",
      "Epoch 387/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.6850     \n",
      "Epoch 388/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.5237     \n",
      "Epoch 389/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 19.3826     \n",
      "Epoch 390/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.9959     \n",
      "Epoch 391/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.2974     \n",
      "Epoch 392/1000\n",
      "1000/1000 [==============================] - 0s - loss: 24.3401     \n",
      "Epoch 393/1000\n",
      "1000/1000 [==============================] - 0s - loss: 22.6052     \n",
      "Epoch 394/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.8640     \n",
      "Epoch 395/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.7400     \n",
      "Epoch 396/1000\n",
      "1000/1000 [==============================] - 0s - loss: 22.8182     \n",
      "Epoch 397/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.0759     \n",
      "Epoch 398/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.8949     \n",
      "Epoch 399/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.3330     \n",
      "Epoch 400/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.2616     \n",
      "Epoch 401/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.5659     \n",
      "Epoch 402/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.5939     \n",
      "Epoch 403/1000\n",
      "1000/1000 [==============================] - 0s - loss: 22.1745     \n",
      "Epoch 404/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.0857     \n",
      "Epoch 405/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.1044     \n",
      "Epoch 406/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.1542     \n",
      "Epoch 407/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.0864     \n",
      "Epoch 408/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.7970     \n",
      "Epoch 409/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.9563     \n",
      "Epoch 410/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.3519     \n",
      "Epoch 411/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.1856     \n",
      "Epoch 412/1000\n",
      "1000/1000 [==============================] - 0s - loss: 24.4117     \n",
      "Epoch 413/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.7460     \n",
      "Epoch 414/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.6973     \n",
      "Epoch 415/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.7196     \n",
      "Epoch 416/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.6650     \n",
      "Epoch 417/1000\n",
      "1000/1000 [==============================] - 0s - loss: 23.5280     \n",
      "Epoch 418/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.9187     \n",
      "Epoch 419/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.6141     \n",
      "Epoch 420/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.1370     \n",
      "Epoch 421/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.7857     \n",
      "Epoch 422/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.7500     \n",
      "Epoch 423/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.0525     \n",
      "Epoch 424/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.7079     \n",
      "Epoch 425/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.1724     \n",
      "Epoch 426/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.2089     \n",
      "Epoch 427/1000\n",
      "1000/1000 [==============================] - 0s - loss: 22.6620     \n",
      "Epoch 428/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.3701     \n",
      "Epoch 429/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.2951     \n",
      "Epoch 430/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.4464     \n",
      "Epoch 431/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.5168     \n",
      "Epoch 432/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.6118     \n",
      "Epoch 433/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.9626     \n",
      "Epoch 434/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.7474     \n",
      "Epoch 435/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.8993     \n",
      "Epoch 436/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.9007     \n",
      "Epoch 437/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.4125     \n",
      "Epoch 438/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.4256     \n",
      "Epoch 439/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.3480     \n",
      "Epoch 440/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.8491     \n",
      "Epoch 441/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.6592     \n",
      "Epoch 442/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.7823     \n",
      "Epoch 443/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.7153     \n",
      "Epoch 444/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.4155     \n",
      "Epoch 445/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.6851     \n",
      "Epoch 446/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.3517     \n",
      "Epoch 447/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.7738     \n",
      "Epoch 448/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.8019     \n",
      "Epoch 449/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.9966     \n",
      "Epoch 450/1000\n",
      "1000/1000 [==============================] - 0s - loss: 22.9243     \n",
      "Epoch 451/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.9495     \n",
      "Epoch 452/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.9125     \n",
      "Epoch 453/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.4485     \n",
      "Epoch 454/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.9111     \n",
      "Epoch 455/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.9902     \n",
      "Epoch 456/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.6048     \n",
      "Epoch 457/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.2163     \n",
      "Epoch 458/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.6376     \n",
      "Epoch 459/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.4428     \n",
      "Epoch 460/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.9461     \n",
      "Epoch 461/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.9524     \n",
      "Epoch 462/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.1576     \n",
      "Epoch 463/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.7888     \n",
      "Epoch 464/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.3015     \n",
      "Epoch 465/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.4055     \n",
      "Epoch 466/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.2280     \n",
      "Epoch 467/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.3435     \n",
      "Epoch 468/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.4203     \n",
      "Epoch 469/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.0478     \n",
      "Epoch 470/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.2967     \n",
      "Epoch 471/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.8323     \n",
      "Epoch 472/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.2268     \n",
      "Epoch 473/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.9510     \n",
      "Epoch 474/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.4828     \n",
      "Epoch 475/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.2477     \n",
      "Epoch 476/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.0917     \n",
      "Epoch 477/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.0557     \n",
      "Epoch 478/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.9182     \n",
      "Epoch 479/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.0999     \n",
      "Epoch 480/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.2406     \n",
      "Epoch 481/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.1180     \n",
      "Epoch 482/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.1486     \n",
      "Epoch 483/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.4520     \n",
      "Epoch 484/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.1858     \n",
      "Epoch 485/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.4551     \n",
      "Epoch 486/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 16.1386     \n",
      "Epoch 487/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.3588     \n",
      "Epoch 488/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.6046     \n",
      "Epoch 489/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.6263     \n",
      "Epoch 490/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.9552     \n",
      "Epoch 491/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.3115     \n",
      "Epoch 492/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.8326     \n",
      "Epoch 493/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.3821     \n",
      "Epoch 494/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.0915     \n",
      "Epoch 495/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.1801     \n",
      "Epoch 496/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.2272     \n",
      "Epoch 497/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.5109     \n",
      "Epoch 498/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.4547     \n",
      "Epoch 499/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.0292     \n",
      "Epoch 500/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.6008     \n",
      "Epoch 501/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.3910     \n",
      "Epoch 502/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.9515     \n",
      "Epoch 503/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.4872     \n",
      "Epoch 504/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.8311     \n",
      "Epoch 505/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.6593     \n",
      "Epoch 506/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.6047     \n",
      "Epoch 507/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.9786     \n",
      "Epoch 508/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.1388     \n",
      "Epoch 509/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.8242     \n",
      "Epoch 510/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.1135     \n",
      "Epoch 511/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.8841     \n",
      "Epoch 512/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.2742     \n",
      "Epoch 513/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.8192     \n",
      "Epoch 514/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.0423     \n",
      "Epoch 515/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.9475     \n",
      "Epoch 516/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.5165     \n",
      "Epoch 517/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.4466     \n",
      "Epoch 518/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.4301     \n",
      "Epoch 519/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.0215     \n",
      "Epoch 520/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.9621     \n",
      "Epoch 521/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.7171     \n",
      "Epoch 522/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.2997     \n",
      "Epoch 523/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.4120     \n",
      "Epoch 524/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.1429     \n",
      "Epoch 525/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.3222     \n",
      "Epoch 526/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.5690     \n",
      "Epoch 527/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.2371     \n",
      "Epoch 528/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.0125     \n",
      "Epoch 529/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.4938     \n",
      "Epoch 530/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.0364     \n",
      "Epoch 531/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.3904     \n",
      "Epoch 532/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.5772     \n",
      "Epoch 533/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.0369     \n",
      "Epoch 534/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.3732     \n",
      "Epoch 535/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.0107     \n",
      "Epoch 536/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.8704     \n",
      "Epoch 537/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.2673     \n",
      "Epoch 538/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.2613     \n",
      "Epoch 539/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.8715     \n",
      "Epoch 540/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.7953     \n",
      "Epoch 541/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.4642     \n",
      "Epoch 542/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.8679     \n",
      "Epoch 543/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.0484     \n",
      "Epoch 544/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.1669     \n",
      "Epoch 545/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.6952     \n",
      "Epoch 546/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.6129     \n",
      "Epoch 547/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.4349     \n",
      "Epoch 548/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.6052     \n",
      "Epoch 549/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.8590     \n",
      "Epoch 550/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.3073     \n",
      "Epoch 551/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.4661     \n",
      "Epoch 552/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.0557     \n",
      "Epoch 553/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.0333     \n",
      "Epoch 554/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.1313     \n",
      "Epoch 555/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.4244     \n",
      "Epoch 556/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.4072     \n",
      "Epoch 557/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.1921     \n",
      "Epoch 558/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.1928     \n",
      "Epoch 559/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.5421     \n",
      "Epoch 560/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.3246     \n",
      "Epoch 561/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.7308     \n",
      "Epoch 562/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.4216     \n",
      "Epoch 563/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.4676     \n",
      "Epoch 564/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.6016     \n",
      "Epoch 565/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.3852     \n",
      "Epoch 566/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.0671     \n",
      "Epoch 567/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.9103     \n",
      "Epoch 568/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.4749     \n",
      "Epoch 569/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.2028     \n",
      "Epoch 570/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.2399     \n",
      "Epoch 571/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.8963     \n",
      "Epoch 572/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.1792     \n",
      "Epoch 573/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.9193     \n",
      "Epoch 574/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.1493     \n",
      "Epoch 575/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.3744     \n",
      "Epoch 576/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.5245     \n",
      "Epoch 577/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.7879     \n",
      "Epoch 578/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.7272     \n",
      "Epoch 579/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.2163     \n",
      "Epoch 580/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.7396     \n",
      "Epoch 581/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.4135     \n",
      "Epoch 582/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.1084    \n",
      "Epoch 583/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 14.0690     \n",
      "Epoch 584/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.1621     \n",
      "Epoch 585/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.9786     \n",
      "Epoch 586/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.0280     \n",
      "Epoch 587/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.0528     \n",
      "Epoch 588/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.3778     \n",
      "Epoch 589/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.9268     \n",
      "Epoch 590/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.7084     \n",
      "Epoch 591/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.6454     \n",
      "Epoch 592/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.5655     \n",
      "Epoch 593/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.2852     \n",
      "Epoch 594/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.1579     \n",
      "Epoch 595/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.5235     \n",
      "Epoch 596/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.9857     \n",
      "Epoch 597/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.8019     \n",
      "Epoch 598/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.9041     \n",
      "Epoch 599/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.1999     \n",
      "Epoch 600/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.0331     \n",
      "Epoch 601/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.5676     \n",
      "Epoch 602/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.7265     \n",
      "Epoch 603/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.3148     \n",
      "Epoch 604/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.6159     \n",
      "Epoch 605/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.7722     \n",
      "Epoch 606/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.9166     \n",
      "Epoch 607/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.8700     \n",
      "Epoch 608/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.8065     \n",
      "Epoch 609/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.3664     \n",
      "Epoch 610/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.0577     \n",
      "Epoch 611/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.6116     \n",
      "Epoch 612/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.6913     \n",
      "Epoch 613/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.3386     \n",
      "Epoch 614/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.6212     \n",
      "Epoch 615/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.5743     \n",
      "Epoch 616/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.2914     \n",
      "Epoch 617/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.4233     \n",
      "Epoch 618/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.5589     \n",
      "Epoch 619/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.2885     \n",
      "Epoch 620/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.8411     \n",
      "Epoch 621/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.6663     \n",
      "Epoch 622/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.4099     \n",
      "Epoch 623/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.5479     \n",
      "Epoch 624/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.9220     \n",
      "Epoch 625/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.8384     \n",
      "Epoch 626/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.3781     \n",
      "Epoch 627/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.4403     \n",
      "Epoch 628/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.7648     \n",
      "Epoch 629/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.8690     \n",
      "Epoch 630/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.7237      \n",
      "Epoch 631/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.8894     \n",
      "Epoch 632/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.8624     \n",
      "Epoch 633/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.0694     \n",
      "Epoch 634/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.4831     \n",
      "Epoch 635/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.0931     \n",
      "Epoch 636/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.8666     \n",
      "Epoch 637/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.7105     \n",
      "Epoch 638/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.7723     \n",
      "Epoch 639/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.4824     \n",
      "Epoch 640/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.2612     \n",
      "Epoch 641/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.6877     \n",
      "Epoch 642/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.3166    \n",
      "Epoch 643/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.9859     \n",
      "Epoch 644/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.0036     \n",
      "Epoch 645/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.1686     \n",
      "Epoch 646/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.9683     \n",
      "Epoch 647/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.4322    \n",
      "Epoch 648/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.9507     \n",
      "Epoch 649/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.0524     \n",
      "Epoch 650/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.2741     \n",
      "Epoch 651/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.9899     \n",
      "Epoch 652/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.5712     \n",
      "Epoch 653/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.7319      \n",
      "Epoch 654/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.3611     \n",
      "Epoch 655/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.3136     \n",
      "Epoch 656/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.4367     \n",
      "Epoch 657/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.8257     \n",
      "Epoch 658/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.4372     \n",
      "Epoch 659/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.5863     \n",
      "Epoch 660/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.5620     \n",
      "Epoch 661/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.2691     \n",
      "Epoch 662/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.3914     \n",
      "Epoch 663/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.7123     \n",
      "Epoch 664/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.7523     \n",
      "Epoch 665/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.3668     \n",
      "Epoch 666/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.3526     \n",
      "Epoch 667/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.3681    \n",
      "Epoch 668/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.3944     \n",
      "Epoch 669/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.3942     \n",
      "Epoch 670/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.0135     \n",
      "Epoch 671/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.7959     \n",
      "Epoch 672/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.8745     \n",
      "Epoch 673/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.9628     \n",
      "Epoch 674/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.1946     \n",
      "Epoch 675/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.9406     \n",
      "Epoch 676/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.8132     \n",
      "Epoch 677/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.2073     \n",
      "Epoch 678/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.6229     \n",
      "Epoch 679/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.4388      \n",
      "Epoch 680/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 13.3426     \n",
      "Epoch 681/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.0295     \n",
      "Epoch 682/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.2320     \n",
      "Epoch 683/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.5524     \n",
      "Epoch 684/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.3824     \n",
      "Epoch 685/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.0904     \n",
      "Epoch 686/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.8906      \n",
      "Epoch 687/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.0728     \n",
      "Epoch 688/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.8142     \n",
      "Epoch 689/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.3014     \n",
      "Epoch 690/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.4378     \n",
      "Epoch 691/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.7654     \n",
      "Epoch 692/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.3447     \n",
      "Epoch 693/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.1583     \n",
      "Epoch 694/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.4566     \n",
      "Epoch 695/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.3909     \n",
      "Epoch 696/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.1286     \n",
      "Epoch 697/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.5236     \n",
      "Epoch 698/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.2384     \n",
      "Epoch 699/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.3624    \n",
      "Epoch 700/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.3266     \n",
      "Epoch 701/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.2854    \n",
      "Epoch 702/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.8540     \n",
      "Epoch 703/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.3991    \n",
      "Epoch 704/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.9447     \n",
      "Epoch 705/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.7040     \n",
      "Epoch 706/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.4197     \n",
      "Epoch 707/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.8680     \n",
      "Epoch 708/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.3192     \n",
      "Epoch 709/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.1953     \n",
      "Epoch 710/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.0651     \n",
      "Epoch 711/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.7845     \n",
      "Epoch 712/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.7735     \n",
      "Epoch 713/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.3197     \n",
      "Epoch 714/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.9820     \n",
      "Epoch 715/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.0687     \n",
      "Epoch 716/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.1813     \n",
      "Epoch 717/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.9314     \n",
      "Epoch 718/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.3129     \n",
      "Epoch 719/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.4157     \n",
      "Epoch 720/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.3392     \n",
      "Epoch 721/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.7022     \n",
      "Epoch 722/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.6707     \n",
      "Epoch 723/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.1413     \n",
      "Epoch 724/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.5778     \n",
      "Epoch 725/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.8602     \n",
      "Epoch 726/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.7829     \n",
      "Epoch 727/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.9269     \n",
      "Epoch 728/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.8743     \n",
      "Epoch 729/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.6051     \n",
      "Epoch 730/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.4805     \n",
      "Epoch 731/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.9791    \n",
      "Epoch 732/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.7818     \n",
      "Epoch 733/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.2283     \n",
      "Epoch 734/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.3700     \n",
      "Epoch 735/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.2311     \n",
      "Epoch 736/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.2693     \n",
      "Epoch 737/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.3885     \n",
      "Epoch 738/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.8391     \n",
      "Epoch 739/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.3585     \n",
      "Epoch 740/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.5466     \n",
      "Epoch 741/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.2808     \n",
      "Epoch 742/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.2604     \n",
      "Epoch 743/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.9315     \n",
      "Epoch 744/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.6259     \n",
      "Epoch 745/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.4514    \n",
      "Epoch 746/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.6403     \n",
      "Epoch 747/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.5889     \n",
      "Epoch 748/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.8070     \n",
      "Epoch 749/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.6864    \n",
      "Epoch 750/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.1743     \n",
      "Epoch 751/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.9890     \n",
      "Epoch 752/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.8769     \n",
      "Epoch 753/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.5198     \n",
      "Epoch 754/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.2848    \n",
      "Epoch 755/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.8162     \n",
      "Epoch 756/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.6082     \n",
      "Epoch 757/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.2412     \n",
      "Epoch 758/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.8963    \n",
      "Epoch 759/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.0901    \n",
      "Epoch 760/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.8229     \n",
      "Epoch 761/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.3135     \n",
      "Epoch 762/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.6452     \n",
      "Epoch 763/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.3978    \n",
      "Epoch 764/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.2830     \n",
      "Epoch 765/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.9549     \n",
      "Epoch 766/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.9847     \n",
      "Epoch 767/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.8398     \n",
      "Epoch 768/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.5423     \n",
      "Epoch 769/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.3024     \n",
      "Epoch 770/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.6949     \n",
      "Epoch 771/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.2301     \n",
      "Epoch 772/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.9806     \n",
      "Epoch 773/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.9497      \n",
      "Epoch 774/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.8016     \n",
      "Epoch 775/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.5021     \n",
      "Epoch 776/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.8856     \n",
      "Epoch 777/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 10.0487    \n",
      "Epoch 778/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.1870    \n",
      "Epoch 779/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.8452     \n",
      "Epoch 780/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.2121     \n",
      "Epoch 781/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.7056     \n",
      "Epoch 782/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.0161     \n",
      "Epoch 783/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.7237     \n",
      "Epoch 784/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.7393    \n",
      "Epoch 785/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.3851     \n",
      "Epoch 786/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.2251     \n",
      "Epoch 787/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.7524     \n",
      "Epoch 788/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.1181     \n",
      "Epoch 789/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.2295     \n",
      "Epoch 790/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.8570     \n",
      "Epoch 791/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.3025     \n",
      "Epoch 792/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.4748    \n",
      "Epoch 793/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.5522     \n",
      "Epoch 794/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.9044     \n",
      "Epoch 795/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.2047     \n",
      "Epoch 796/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.0456     \n",
      "Epoch 797/1000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 11.13 - 0s - loss: 9.7348      \n",
      "Epoch 798/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.6970    \n",
      "Epoch 799/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.7444     \n",
      "Epoch 800/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.9413     \n",
      "Epoch 801/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.0971     \n",
      "Epoch 802/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.2099     \n",
      "Epoch 803/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.6611      \n",
      "Epoch 804/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.4096     \n",
      "Epoch 805/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.1249     \n",
      "Epoch 806/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.8641     \n",
      "Epoch 807/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.4897     \n",
      "Epoch 808/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.8810     \n",
      "Epoch 809/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.2242    \n",
      "Epoch 810/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.5606     \n",
      "Epoch 811/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.5171     \n",
      "Epoch 812/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.3946    \n",
      "Epoch 813/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.3456     \n",
      "Epoch 814/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.9363    \n",
      "Epoch 815/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.5854     \n",
      "Epoch 816/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.1935     \n",
      "Epoch 817/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.8416     \n",
      "Epoch 818/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.8411     \n",
      "Epoch 819/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.5259     \n",
      "Epoch 820/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.4537     \n",
      "Epoch 821/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.9387     \n",
      "Epoch 822/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.3725     \n",
      "Epoch 823/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.6832     \n",
      "Epoch 824/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.0117     \n",
      "Epoch 825/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.0816     \n",
      "Epoch 826/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.1907     \n",
      "Epoch 827/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.4342     \n",
      "Epoch 828/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.7584    \n",
      "Epoch 829/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.4322     \n",
      "Epoch 830/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.8126     \n",
      "Epoch 831/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.7151     \n",
      "Epoch 832/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.6299     \n",
      "Epoch 833/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.4676     \n",
      "Epoch 834/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.2745     \n",
      "Epoch 835/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.2813     \n",
      "Epoch 836/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.8246     \n",
      "Epoch 837/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.8731     \n",
      "Epoch 838/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.9619     \n",
      "Epoch 839/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.6217      \n",
      "Epoch 840/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.7532     \n",
      "Epoch 841/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.6282     \n",
      "Epoch 842/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.4035     \n",
      "Epoch 843/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.7384    \n",
      "Epoch 844/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.7169    \n",
      "Epoch 845/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.5133      \n",
      "Epoch 846/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.7928     \n",
      "Epoch 847/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.9393    \n",
      "Epoch 848/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.2879     \n",
      "Epoch 849/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.6144      \n",
      "Epoch 850/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.3680     \n",
      "Epoch 851/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.5817     \n",
      "Epoch 852/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.3569    \n",
      "Epoch 853/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.1063    \n",
      "Epoch 854/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.1409     \n",
      "Epoch 855/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.9804     \n",
      "Epoch 856/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.9430     \n",
      "Epoch 857/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.8096    \n",
      "Epoch 858/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.2800    \n",
      "Epoch 859/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.0783    \n",
      "Epoch 860/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.7682      \n",
      "Epoch 861/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.9934     \n",
      "Epoch 862/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.5843    \n",
      "Epoch 863/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.5581     \n",
      "Epoch 864/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.7724    \n",
      "Epoch 865/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.5979     \n",
      "Epoch 866/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.8062     \n",
      "Epoch 867/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.8576      \n",
      "Epoch 868/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.1599    \n",
      "Epoch 869/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.6781     \n",
      "Epoch 870/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.5469    \n",
      "Epoch 871/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.6615     \n",
      "Epoch 872/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.1174     \n",
      "Epoch 873/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.3305     \n",
      "Epoch 874/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 9.9990     \n",
      "Epoch 875/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.0794     \n",
      "Epoch 876/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.1161      \n",
      "Epoch 877/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.2222     \n",
      "Epoch 878/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.7523     \n",
      "Epoch 879/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.6508      \n",
      "Epoch 880/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.2535    \n",
      "Epoch 881/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.4592    \n",
      "Epoch 882/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.3778     \n",
      "Epoch 883/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.2745     \n",
      "Epoch 884/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.5816      \n",
      "Epoch 885/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.0466     \n",
      "Epoch 886/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.7831     \n",
      "Epoch 887/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.7779     \n",
      "Epoch 888/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.3803     \n",
      "Epoch 889/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.3371    \n",
      "Epoch 890/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.7355     \n",
      "Epoch 891/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.0210     \n",
      "Epoch 892/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.0085     \n",
      "Epoch 893/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.5238      \n",
      "Epoch 894/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.4822     \n",
      "Epoch 895/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.2907      \n",
      "Epoch 896/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.1012     \n",
      "Epoch 897/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.8809      \n",
      "Epoch 898/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.9111     \n",
      "Epoch 899/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.6707      \n",
      "Epoch 900/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.1308     \n",
      "Epoch 901/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.3694     \n",
      "Epoch 902/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.3316      \n",
      "Epoch 903/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.7696     \n",
      "Epoch 904/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.7769      \n",
      "Epoch 905/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.6892      \n",
      "Epoch 906/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.0473     \n",
      "Epoch 907/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.8405     \n",
      "Epoch 908/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.8389      \n",
      "Epoch 909/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.5858     \n",
      "Epoch 910/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.9327    \n",
      "Epoch 911/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.9246     \n",
      "Epoch 912/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.9581     \n",
      "Epoch 913/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.8836    \n",
      "Epoch 914/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.2627     \n",
      "Epoch 915/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.1432     \n",
      "Epoch 916/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.8719     \n",
      "Epoch 917/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.3404     \n",
      "Epoch 918/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.9844      \n",
      "Epoch 919/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.3922     \n",
      "Epoch 920/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.9855    \n",
      "Epoch 921/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.9814     \n",
      "Epoch 922/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.9111     \n",
      "Epoch 923/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.6129     \n",
      "Epoch 924/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.2024     \n",
      "Epoch 925/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.0875    \n",
      "Epoch 926/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.2495    \n",
      "Epoch 927/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.0175    \n",
      "Epoch 928/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.5357     \n",
      "Epoch 929/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.0608     \n",
      "Epoch 930/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.3405      \n",
      "Epoch 931/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.4216      \n",
      "Epoch 932/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.5695     \n",
      "Epoch 933/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.1227     \n",
      "Epoch 934/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.5551     \n",
      "Epoch 935/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.7567     \n",
      "Epoch 936/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.9234      \n",
      "Epoch 937/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.2714     \n",
      "Epoch 938/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.8169     \n",
      "Epoch 939/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.4992     \n",
      "Epoch 940/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.3121    \n",
      "Epoch 941/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.7277     \n",
      "Epoch 942/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.4525     \n",
      "Epoch 943/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.3846    \n",
      "Epoch 944/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.7923     \n",
      "Epoch 945/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.2605      \n",
      "Epoch 946/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.7491      \n",
      "Epoch 947/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.9458    \n",
      "Epoch 948/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.7457     \n",
      "Epoch 949/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.5053      \n",
      "Epoch 950/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.6148     \n",
      "Epoch 951/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.8691      \n",
      "Epoch 952/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.0875     \n",
      "Epoch 953/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.2715    \n",
      "Epoch 954/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.3796    \n",
      "Epoch 955/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.4844     \n",
      "Epoch 956/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.3849     \n",
      "Epoch 957/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.7208     \n",
      "Epoch 958/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.9561     \n",
      "Epoch 959/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.7854    \n",
      "Epoch 960/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.2518     \n",
      "Epoch 961/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.5344     \n",
      "Epoch 962/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.7068     \n",
      "Epoch 963/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.4063     \n",
      "Epoch 964/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.6746      \n",
      "Epoch 965/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.4501      \n",
      "Epoch 966/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.0586     \n",
      "Epoch 967/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.2944     - ETA: 0s - loss: 8.569\n",
      "Epoch 968/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.9819     \n",
      "Epoch 969/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.7249     \n",
      "Epoch 970/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.1111     \n",
      "Epoch 971/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 8.2968      \n",
      "Epoch 972/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.7201     \n",
      "Epoch 973/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.2174     \n",
      "Epoch 974/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.7827    \n",
      "Epoch 975/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.7563     \n",
      "Epoch 976/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.4034     \n",
      "Epoch 977/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.8773    \n",
      "Epoch 978/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.2864     \n",
      "Epoch 979/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.0365     \n",
      "Epoch 980/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.7802     \n",
      "Epoch 981/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.2930    \n",
      "Epoch 982/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.5184     \n",
      "Epoch 983/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.7890     \n",
      "Epoch 984/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.3269     \n",
      "Epoch 985/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.0100      \n",
      "Epoch 986/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.0648    \n",
      "Epoch 987/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.7512     \n",
      "Epoch 988/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.4500      \n",
      "Epoch 989/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.8563     \n",
      "Epoch 990/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.6259     \n",
      "Epoch 991/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.6745    \n",
      "Epoch 992/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.1858     \n",
      "Epoch 993/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.0511      \n",
      "Epoch 994/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.6615     \n",
      "Epoch 995/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.4794     \n",
      "Epoch 996/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.9476     \n",
      "Epoch 997/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.1552     \n",
      "Epoch 998/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.8481     \n",
      "Epoch 999/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.1061     \n",
      "Epoch 1000/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.6250     \n",
      " 32/100 [========>.....................] - ETA: 0s87.8623684692\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAJPCAYAAABcoIE1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAzTM4ordmD3zAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1188eec10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "x_train_1d = x_train.reshape(x_train.shape[0], width*height)\n",
    "x_test_1d = x_test.reshape(x_test.shape[0], width*height)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim = width*height))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "\n",
    "model.fit(x_train_1d, y_train, batch_size=32, epochs=1000)\n",
    "\n",
    "score = model.evaluate(x_test_1d, y_test, batch_size=32)\n",
    "\n",
    "print(score)\n",
    "\n",
    "yhat_test = model.predict(x_test_1d, batch_size=32)\n",
    "\n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "    sub_plt = axarr[i/plt_row, i%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_test[i].reshape(width, height))\n",
    "    sub_plt.set_title('R %d P %.1f' % (y_test[i][0], yhat_test[i][0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=1000)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)\n",
    "\n",
    "print(score)\n",
    "\n",
    "yhat_test = model.predict(x_test_1d, batch_size=32)\n",
    "\n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "    sub_plt = axarr[i/plt_row, i%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_test[i].reshape(width, height))\n",
    "    sub_plt.set_title('R %d P %.1f' % (y_test[i][0], yhat_test[i][0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# Generate dummy data\n",
    "x_train = np.random.random((100, 100, 100, 3))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "x_test = np.random.random((20, 100, 100, 3))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)\n",
    "\n",
    "# 데이터셋 생성\n",
    "x_train = np.random.random((1000, 1))\n",
    "y_train = x_train * 2 + np.random.random((1000, 1)) / 3.0\n",
    "x_test = np.random.random((100, 1))\n",
    "y_test = x_test * 2 + np.random.random((100, 1)) / 3.0\n",
    "\n",
    "# 데이터셋 확인\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x_train, y_train, 'ro')\n",
    "plt.plot(x_test, y_test, 'bo')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](http://tykimos.github.com/Keras/warehouse/2017-8-12-Numerical_Prediction_Model_Recipe_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 레이어 준비\n",
    "\n",
    "수치예측 모델에 사용할 레이어는 `Dense`와 `Activation`입니다. `Activation`에는 은닉층(hidden layer)에 사용할 `relu`를 준비했습니다. 데이터셋은 일차원 벡터만 다루도록 하겠습니다.\n",
    "\n",
    "|종류|구분|상세구분|브릭|\n",
    "|:-:|:-:|:-:|:-:|\n",
    "|데이터셋|Vector|-|![img](http://tykimos.github.com/Keras/warehouse/DeepBrick/Model_Recipe_Part_Dataset_Vector_s.png)|\n",
    "|레이어|Dense||![img](http://tykimos.github.com/Keras/warehouse/DeepBrick/Model_Recipe_Part_Dense_s.png)|\n",
    "|레이어|Activation|relu|![img](http://tykimos.github.com/Keras/warehouse/DeepBrick/Model_Recipe_Part_Activation_Relu_s.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 모델 준비\n",
    "\n",
    "수치예측을 하기 위해 `선형회귀 모델`, `퍼셉트론 모델`, `다층퍼셉트론 모델`, `깊은 다층퍼셉트론 모델`을 준비했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 선형회귀 모델\n",
    "\n",
    "가장 간단한 1차 선형회귀 모델로 수치예측을 해보겠습니다. 아래 식에서 x, y는 우리가 만든 데이터셋이고, 회귀분석을 통해서, w와 b값을 구하는 것이 목표입니다. \n",
    "\n",
    "    Y = w * X + b\n",
    "   \n",
    "w와 b값을 구하게 되면, 임의의 입력 x에 대해서 출력 y가 나오는 데 이것이 예측 값입니다. w, b 값은 분산, 공분산, 평균을 이용하여 쉽게 구할 수 있습니다. \n",
    "\n",
    "    w = np.cov(X, Y, bias=1)[0,1] / np.var(X)\n",
    "    b = np.average(Y) - w * np.average(X)\n",
    "    \n",
    "간단한 수식이지만 이 수식을 도출하기란 꽤나 복잡습니다. 오차를 최소화하는 극대값을 구하기 위해 편미분을 수행하고, 다시 식을 전개하는 등등의 과정이 필요합니다.\n",
    "\n",
    "![img](http://tykimos.github.com/Keras/warehouse/2017-8-12-Numerical_Prediction_Model_Recipe_0.png)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 퍼셉트론 모델\n",
    "\n",
    "Dense 레이어가 하나이고, 뉴런의 수도 하나인 가장 기본적인 퍼셉트론 모델입니다. 즉 웨이트(w) 하나, 바이어스(b) 하나로 전형적인 Y = w * X + b를 풀기 위한 모델입니다. 수치 예측을 하기 위해서 출력 레이어에 별도의 활성화 함수를 사용하지 않았습니다. w, b 값이 손으로 푼 선형회귀 최적해에 근접하려면 경우에 따라 만번이상의 에포크가 필요합니다. 실제로 사용하지는 않는 모델이지만 선형회귀부터 공부하시는 분들에게는 입문 모델로 나쁘지 않습니다.\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, input_dim=1))\n",
    "        \n",
    "![img](http://tykimos.github.com/Keras/warehouse/2017-8-12-Numerical_Prediction_Model_Recipe_1m.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다층퍼셉트론 모델\n",
    "\n",
    "Dense 레이어가 두 개인 다층퍼셉트론 모델입니다. 첫 번째 레이어는 64개의 뉴런을 가진 Dense 레이어이고 오류역전파가 용이한 `relu` 활성화 함수를 사용하였습니다. 출력 레이어인 두 번째 레이어는 하나의 수치값을 예측을 하기 위해서 1개의 뉴런을 가지며, 별도의 활성화 함수를 사용하지 않았습니다.\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=1, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "![img](http://tykimos.github.com/Keras/warehouse/2017-8-12-Numerical_Prediction_Model_Recipe_2m.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 깊은 다층퍼셉트론 모델\n",
    "\n",
    "Dense 레이어가 총 세 개인 다층퍼셉트론 모델입니다. 첫 번째, 두 번째 레이어는 64개의 뉴런을 가진 Dense 레이어이고 오류역전파가 용이한 `relu` 활성화 함수를 사용하였습니다. 출력 레이어인 세 번째 레이어는 하나의 수치값을 예측을 하기 위해서 1개의 뉴런을 가지며, 별도의 활성화 함수를 사용하지 않았습니다.\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=1, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "![img](http://tykimos.github.com/Keras/warehouse/2017-8-12-Numerical_Prediction_Model_Recipe_3m.png)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 전체 소스\n",
    "\n",
    "앞서 살펴본 `선형회귀 모델`, `퍼셉트론 모델`, `다층퍼셉트론 모델`, `깊은 다층퍼셉트론 모델`의 전체 소스는 다음과 같습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 선형회귀 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형회귀 모델로 수치예측하기\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "\n",
    "# 1. 데이터셋 준비하기\n",
    "x_train = np.random.random((1000, 1))\n",
    "y_train = x_train * 2 + np.random.random((1000, 1)) / 3.0\n",
    "x_test = np.random.random((100, 1))\n",
    "y_test = x_test * 2 + np.random.random((100, 1)) / 3.0\n",
    "\n",
    "x_train = x_train.reshape(1000,)\n",
    "y_train = y_train.reshape(1000,)\n",
    "x_test = x_test.reshape(100,)\n",
    "y_test = y_test.reshape(100,)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "w = np.cov(x_train, y_train, bias=1)[0,1] / np.var(x_train)\n",
    "b = np.average(y_train) - w * np.average(x_train)\n",
    "\n",
    "print w, b\n",
    "\n",
    "# 3. 모델 평가하기\n",
    "\n",
    "y_predict = w * x_test + b\n",
    "mse = mean_squared_error(y_test, y_predict)\n",
    "print('mse : ' + str(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 퍼셉트론 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 퍼셉트론 모델로 수치예측하기\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import random\n",
    "\n",
    "# 1. 데이터셋 준비하기\n",
    "x_train = np.random.random((1000, 1))\n",
    "y_train = x_train * 2 + np.random.random((1000, 1)) / 3.0\n",
    "x_test = np.random.random((100, 1))\n",
    "y_test = x_test * 2 + np.random.random((100, 1)) / 3.0\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=1))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit(x_train, y_train, epochs=50, batch_size=64)\n",
    "w, b = model.get_weights()\n",
    "print w, b\n",
    "\n",
    "# 5. 모델 평가하기\n",
    "loss = model.evaluate(x_test, y_test, batch_size=32)\n",
    "print('loss : ' + str(loss))\n",
    "\n",
    "# 6. 학습과정 확인하기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.ylim(0.0, 1.5)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다층퍼셉트론 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다층퍼셉트론 모델로 수치예측하기\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import random\n",
    "\n",
    "# 1. 데이터셋 준비하기\n",
    "x_train = np.random.random((1000, 1))\n",
    "y_train = x_train * 2 + np.random.random((1000, 1)) / 3.0\n",
    "x_test = np.random.random((100, 1))\n",
    "y_test = x_test * 2 + np.random.random((100, 1)) / 3.0\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=1, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit(x_train, y_train, epochs=50, batch_size=64)\n",
    "\n",
    "# 5. 모델 평가하기\n",
    "loss = model.evaluate(x_test, y_test, batch_size=32)\n",
    "print('loss : ' + str(loss))\n",
    "\n",
    "# 6. 학습과정 확인하기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.ylim(0.0, 1.5)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 깊은 다층퍼셉트론 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 깊은 다층퍼셉트론 모델로 수치예측하기\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import random\n",
    "\n",
    "# 1. 데이터셋 준비하기\n",
    "x_train = np.random.random((1000, 1))\n",
    "y_train = x_train * 2 + np.random.random((1000, 1)) / 3.0\n",
    "x_test = np.random.random((100, 1))\n",
    "y_test = x_test * 2 + np.random.random((100, 1)) / 3.0\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=1, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit(x_train, y_train, epochs=50, batch_size=64)\n",
    "\n",
    "# 5. 모델 평가하기\n",
    "loss = model.evaluate(x_test, y_test, batch_size=32)\n",
    "print('loss : ' + str(loss))\n",
    "\n",
    "# 6. 학습과정 확인하기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.ylim(0.0, 1.5)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 학습결과 비교\n",
    "\n",
    "퍼셉트론 > 다층퍼셉트론 > 깊은 다층퍼셉트론 순으로 학습이 좀 더 빨리 되는 것을 확인할 수 있습니다.\n",
    "\n",
    "|퍼셉트론|다층퍼셉트론|깊은 다층퍼셉트론|\n",
    "|:-:|:-:|:-:|\n",
    "|![img](http://tykimos.github.com/Keras/warehouse/2017-8-12-Numerical_Prediction_Model_Recipe_6.png)|![img](http://tykimos.github.com/Keras/warehouse/2017-8-12-Numerical_Prediction_Model_Recipe_7.png)|![img](http://tykimos.github.com/Keras/warehouse/2017-8-12-Numerical_Prediction_Model_Recipe_8.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 결론\n",
    "\n",
    "수치예측을 위한 퍼셉트론, 다층퍼셉트론, 깊은 다층퍼셉트론 모델을 살펴보고, 그 성능을 확인 해봤습니다.\n",
    "\n",
    "![img](http://tykimos.github.com/Keras/warehouse/2017-8-12-Numerical_Prediction_Model_Recipe_4m.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "### 같이 보기\n",
    "\n",
    "* [강좌 목차](https://tykimos.github.io/Keras/lecture/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
