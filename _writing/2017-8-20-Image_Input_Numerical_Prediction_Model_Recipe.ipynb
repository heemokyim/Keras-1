{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title:  \"영상입력 수치예측 모델 레시피\"\n",
    "author: 김태영\n",
    "date:   2017-08-20 01:00:00\n",
    "categories: Lecture\n",
    "comments: true\n",
    "image: http://tykimos.github.com/Keras/warehouse/2017-8-20-Image_Input_Numerical_Prediction_Model_Recipe_4m.png\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영상을 입력해서 수치를 예측하는 모델들에 대해서 알아보겠습니다. 수치예측을 위한 영상 데이터셋 생성을 해보고, 다층퍼셉트론 및 컨볼루션 신경망 모델을 구성 및 학습 시켜보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 데이터셋 준비\n",
    "\n",
    "아래 코드는 임의의 픽셀 수를 가지는 영상을 생성하고, 데이터(x)를 생성한 영상으로 지정하고, 라벨(y)를 임의의 픽셀 수로 지정하는 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "width = 16\n",
    "height = 16\n",
    "\n",
    "def generate_dataset(samples):\n",
    "\n",
    "    ds_x = []\n",
    "    ds_y = []\n",
    "    \n",
    "    for it in range(samples):\n",
    "        \n",
    "        num_pt = np.random.randint(0, width * height)\n",
    "        img = generate_image(num_pt)\n",
    "        \n",
    "        ds_y.append(num_pt)\n",
    "        ds_x.append(img)\n",
    "    \n",
    "    return np.array(ds_x), np.array(ds_y).reshape(samples, 1)\n",
    "    \n",
    "def generate_image(points):\n",
    "    \n",
    "    img = np.zeros((width, height))\n",
    "    pts = np.random.random((points, 2))\n",
    "    \n",
    "    for ipt in pts:\n",
    "        img[int(ipt[0] * width), int(ipt[1] * height)] = 1\n",
    "    \n",
    "    return img.reshape(width, height, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋으로 훈련셋을 1000개, 시험셋을 100개 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train = generate_dataset(1000)\n",
    "x_test, y_test = generate_dataset(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만든 데이터셋 일부를 가시화 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "        \n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "    sub_plt = axarr[i/plt_row, i%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_train[i].reshape(width, height))\n",
    "    sub_plt.set_title('R ' + str(y_train[i][0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R (Real) 값으로 표시된 것이 표시한 픽셀 수를 의미합니다. 한 번 표시한 픽셀에 다시 표시가 될 수 있기 때문에 실제 픽셀 수와 조금 차이는 날 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 레이어 준비\n",
    "\n",
    "영상입력 수치예측 모델에서 사용할 레이어는 \n",
    "\n",
    "수치예측 모델에 사용할 레이어는 `Dense`와 `Activation`입니다. `Activation`에는 은닉층(hidden layer)에 사용할 `relu`를 준비했습니다. 데이터셋은 일차원 벡터만 다루도록 하겠습니다.\n",
    "\n",
    "|종류|구분|상세구분|브릭|\n",
    "|:-:|:-:|:-:|:-:|\n",
    "|데이터셋|Vector|-|![img](http://tykimos.github.com/Keras/warehouse/DeepBrick/Model_Recipe_Part_Dataset_Vector_s.png)|\n",
    "|레이어|Dense||![img](http://tykimos.github.com/Keras/warehouse/DeepBrick/Model_Recipe_Part_Dense_s.png)|\n",
    "|레이어|Activation|relu|![img](http://tykimos.github.com/Keras/warehouse/DeepBrick/Model_Recipe_Part_Activation_Relu_s.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 모델 준비\n",
    "\n",
    "수치예측을 하기 위해 `다층퍼셉트론 신경망 모델`, `컨볼루션 신경망 모델`을 준비했습니다.\n",
    "\n",
    "#### 다층퍼셉트론 신경망 모델\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation='relu', input_dim = width*height))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "#### 컨볼루션 신경망 모델\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 전체 소스\n",
    "\n",
    "앞서 살펴본 `다층퍼셉트론 신경망 모델`, `컨볼루션 신경망 모델`의 전체 소스는 다음과 같습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다층퍼셉트론 신경망 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "700/700 [==============================] - 0s - loss: 3437.5190 - val_loss: 725.2100\n",
      "Epoch 2/1000\n",
      "700/700 [==============================] - 0s - loss: 504.8809 - val_loss: 388.0676\n",
      "Epoch 3/1000\n",
      "700/700 [==============================] - 0s - loss: 423.4943 - val_loss: 978.5010\n",
      "Epoch 4/1000\n",
      "700/700 [==============================] - 0s - loss: 418.8270 - val_loss: 398.9486\n",
      "Epoch 5/1000\n",
      "700/700 [==============================] - 0s - loss: 375.4778 - val_loss: 178.0073\n",
      "Epoch 6/1000\n",
      "700/700 [==============================] - 0s - loss: 416.9347 - val_loss: 201.3531\n",
      "Epoch 7/1000\n",
      "700/700 [==============================] - 0s - loss: 294.8422 - val_loss: 229.1521\n",
      "Epoch 8/1000\n",
      "700/700 [==============================] - 0s - loss: 279.9129 - val_loss: 483.6633\n",
      "Epoch 9/1000\n",
      "700/700 [==============================] - 0s - loss: 397.2641 - val_loss: 897.9713\n",
      "Epoch 10/1000\n",
      "700/700 [==============================] - 0s - loss: 290.2747 - val_loss: 370.2592\n",
      "Epoch 11/1000\n",
      "700/700 [==============================] - 0s - loss: 339.4743 - val_loss: 171.3837\n",
      "Epoch 12/1000\n",
      "700/700 [==============================] - 0s - loss: 230.9540 - val_loss: 1031.8407\n",
      "Epoch 13/1000\n",
      "700/700 [==============================] - 0s - loss: 325.5270 - val_loss: 155.9396\n",
      "Epoch 14/1000\n",
      "700/700 [==============================] - 0s - loss: 228.9014 - val_loss: 148.9054\n",
      "Epoch 15/1000\n",
      "700/700 [==============================] - 0s - loss: 268.3013 - val_loss: 261.4867\n",
      "Epoch 16/1000\n",
      "700/700 [==============================] - 0s - loss: 233.6553 - val_loss: 990.5605\n",
      "Epoch 17/1000\n",
      "700/700 [==============================] - 0s - loss: 235.6009 - val_loss: 233.9847\n",
      "Epoch 18/1000\n",
      "700/700 [==============================] - 0s - loss: 222.1231 - val_loss: 150.7391\n",
      "Epoch 19/1000\n",
      "700/700 [==============================] - 0s - loss: 295.2761 - val_loss: 148.8348\n",
      "Epoch 20/1000\n",
      "700/700 [==============================] - 0s - loss: 198.3382 - val_loss: 349.6468\n",
      "Epoch 21/1000\n",
      "700/700 [==============================] - 0s - loss: 168.7921 - val_loss: 138.2146\n",
      "Epoch 22/1000\n",
      "700/700 [==============================] - 0s - loss: 175.7437 - val_loss: 566.4098\n",
      "Epoch 23/1000\n",
      "700/700 [==============================] - 0s - loss: 250.5020 - val_loss: 260.1857\n",
      "Epoch 24/1000\n",
      "700/700 [==============================] - 0s - loss: 187.8127 - val_loss: 190.1503\n",
      "Epoch 25/1000\n",
      "700/700 [==============================] - 0s - loss: 182.4635 - val_loss: 170.7013\n",
      "Epoch 26/1000\n",
      "700/700 [==============================] - 0s - loss: 161.9596 - val_loss: 245.0142\n",
      "Epoch 27/1000\n",
      "700/700 [==============================] - 0s - loss: 234.7573 - val_loss: 152.6636\n",
      "Epoch 28/1000\n",
      "700/700 [==============================] - 0s - loss: 151.9830 - val_loss: 450.7679\n",
      "Epoch 29/1000\n",
      "700/700 [==============================] - 0s - loss: 188.2314 - val_loss: 279.6259\n",
      "Epoch 30/1000\n",
      "700/700 [==============================] - 0s - loss: 158.1741 - val_loss: 246.1175\n",
      "Epoch 31/1000\n",
      "700/700 [==============================] - 0s - loss: 149.9842 - val_loss: 363.8602\n",
      "Epoch 32/1000\n",
      "700/700 [==============================] - 0s - loss: 227.5860 - val_loss: 197.3870\n",
      "Epoch 33/1000\n",
      "700/700 [==============================] - 0s - loss: 156.9820 - val_loss: 133.1971\n",
      "Epoch 34/1000\n",
      "700/700 [==============================] - 0s - loss: 119.2201 - val_loss: 132.0310\n",
      "Epoch 35/1000\n",
      "700/700 [==============================] - 0s - loss: 157.2117 - val_loss: 275.0098\n",
      "Epoch 36/1000\n",
      "700/700 [==============================] - 0s - loss: 166.1805 - val_loss: 149.4810\n",
      "Epoch 37/1000\n",
      "700/700 [==============================] - 0s - loss: 100.5957 - val_loss: 147.6446\n",
      "Epoch 38/1000\n",
      "700/700 [==============================] - 0s - loss: 177.5768 - val_loss: 187.0432\n",
      "Epoch 39/1000\n",
      "700/700 [==============================] - 0s - loss: 109.7462 - val_loss: 393.8463\n",
      "Epoch 40/1000\n",
      "700/700 [==============================] - 0s - loss: 168.2529 - val_loss: 263.6622\n",
      "Epoch 41/1000\n",
      "700/700 [==============================] - 0s - loss: 134.1865 - val_loss: 167.7740\n",
      "Epoch 42/1000\n",
      "700/700 [==============================] - 0s - loss: 116.1987 - val_loss: 387.5056\n",
      "Epoch 43/1000\n",
      "700/700 [==============================] - 0s - loss: 201.5311 - val_loss: 128.8648\n",
      "Epoch 44/1000\n",
      "700/700 [==============================] - 0s - loss: 81.0678 - val_loss: 268.5726\n",
      "Epoch 45/1000\n",
      "700/700 [==============================] - 0s - loss: 136.6788 - val_loss: 129.6111\n",
      "Epoch 46/1000\n",
      "700/700 [==============================] - 0s - loss: 132.0205 - val_loss: 131.4477\n",
      "Epoch 47/1000\n",
      "700/700 [==============================] - 0s - loss: 115.8421 - val_loss: 165.8453\n",
      "Epoch 48/1000\n",
      "700/700 [==============================] - 0s - loss: 147.7340 - val_loss: 261.4441\n",
      "Epoch 49/1000\n",
      "700/700 [==============================] - 0s - loss: 129.8190 - val_loss: 151.1746\n",
      "Epoch 50/1000\n",
      "700/700 [==============================] - 0s - loss: 106.6353 - val_loss: 145.8139\n",
      "Epoch 51/1000\n",
      "700/700 [==============================] - 0s - loss: 100.9871 - val_loss: 265.5973\n",
      "Epoch 52/1000\n",
      "700/700 [==============================] - 0s - loss: 154.9832 - val_loss: 145.2859\n",
      "Epoch 53/1000\n",
      "700/700 [==============================] - 0s - loss: 108.8949 - val_loss: 121.7429\n",
      "Epoch 54/1000\n",
      "700/700 [==============================] - 0s - loss: 109.8811 - val_loss: 186.6987\n",
      "Epoch 55/1000\n",
      "700/700 [==============================] - 0s - loss: 95.8108 - val_loss: 121.8489\n",
      "Epoch 56/1000\n",
      "700/700 [==============================] - 0s - loss: 119.8904 - val_loss: 484.3751\n",
      "Epoch 57/1000\n",
      "700/700 [==============================] - 0s - loss: 109.9800 - val_loss: 134.2313\n",
      "Epoch 58/1000\n",
      "700/700 [==============================] - 0s - loss: 117.6155 - val_loss: 438.0776\n",
      "Epoch 59/1000\n",
      "700/700 [==============================] - 0s - loss: 125.4440 - val_loss: 205.9365\n",
      "Epoch 60/1000\n",
      "700/700 [==============================] - 0s - loss: 108.8370 - val_loss: 203.6634\n",
      "Epoch 61/1000\n",
      "700/700 [==============================] - 0s - loss: 71.2865 - val_loss: 171.0844\n",
      "Epoch 62/1000\n",
      "700/700 [==============================] - 0s - loss: 132.8893 - val_loss: 144.6124\n",
      "Epoch 63/1000\n",
      "700/700 [==============================] - 0s - loss: 93.6515 - val_loss: 235.7356\n",
      "Epoch 64/1000\n",
      "700/700 [==============================] - 0s - loss: 87.4552 - val_loss: 171.4815\n",
      "Epoch 65/1000\n",
      "700/700 [==============================] - 0s - loss: 117.4539 - val_loss: 168.0237\n",
      "Epoch 66/1000\n",
      "700/700 [==============================] - 0s - loss: 114.0077 - val_loss: 122.9134\n",
      "Epoch 67/1000\n",
      "700/700 [==============================] - 0s - loss: 81.4553 - val_loss: 193.0370\n",
      "Epoch 68/1000\n",
      "700/700 [==============================] - 0s - loss: 117.4534 - val_loss: 168.9859\n",
      "Epoch 69/1000\n",
      "700/700 [==============================] - 0s - loss: 82.5693 - val_loss: 131.8117\n",
      "Epoch 70/1000\n",
      "700/700 [==============================] - 0s - loss: 91.0989 - val_loss: 156.5550\n",
      "Epoch 71/1000\n",
      "700/700 [==============================] - 0s - loss: 91.2014 - val_loss: 153.4698\n",
      "Epoch 72/1000\n",
      "700/700 [==============================] - 0s - loss: 105.1046 - val_loss: 136.0225\n",
      "Epoch 73/1000\n",
      "700/700 [==============================] - 0s - loss: 98.5053 - val_loss: 215.9853\n",
      "Epoch 74/1000\n",
      "700/700 [==============================] - 0s - loss: 96.8157 - val_loss: 159.1311\n",
      "Epoch 75/1000\n",
      "700/700 [==============================] - 0s - loss: 94.1201 - val_loss: 199.2361\n",
      "Epoch 76/1000\n",
      "700/700 [==============================] - 0s - loss: 65.7616 - val_loss: 433.1280\n",
      "Epoch 77/1000\n",
      "700/700 [==============================] - 0s - loss: 112.7223 - val_loss: 131.6079\n",
      "Epoch 78/1000\n",
      "700/700 [==============================] - 0s - loss: 78.5238 - val_loss: 183.3603\n",
      "Epoch 79/1000\n",
      "700/700 [==============================] - 0s - loss: 79.3606 - val_loss: 124.6138\n",
      "Epoch 80/1000\n",
      "700/700 [==============================] - 0s - loss: 108.0266 - val_loss: 137.1257\n",
      "Epoch 81/1000\n",
      "700/700 [==============================] - 0s - loss: 58.9878 - val_loss: 164.0223\n",
      "Epoch 82/1000\n",
      "700/700 [==============================] - 0s - loss: 78.1038 - val_loss: 171.5794\n",
      "Epoch 83/1000\n",
      "700/700 [==============================] - 0s - loss: 108.4345 - val_loss: 212.7048\n",
      "Epoch 84/1000\n",
      "700/700 [==============================] - 0s - loss: 85.6261 - val_loss: 191.6396\n",
      "Epoch 85/1000\n",
      "700/700 [==============================] - 0s - loss: 67.2670 - val_loss: 268.6940\n",
      "Epoch 86/1000\n",
      "700/700 [==============================] - 0s - loss: 89.1907 - val_loss: 271.3527\n",
      "Epoch 87/1000\n",
      "700/700 [==============================] - 0s - loss: 78.5555 - val_loss: 285.0631\n",
      "Epoch 88/1000\n",
      "700/700 [==============================] - 0s - loss: 78.7982 - val_loss: 288.5204\n",
      "Epoch 89/1000\n",
      "700/700 [==============================] - 0s - loss: 84.7213 - val_loss: 140.3020\n",
      "Epoch 90/1000\n",
      "700/700 [==============================] - 0s - loss: 77.9729 - val_loss: 122.7358\n",
      "Epoch 91/1000\n",
      "700/700 [==============================] - 0s - loss: 66.3587 - val_loss: 152.4147\n",
      "Epoch 92/1000\n",
      "700/700 [==============================] - 0s - loss: 90.3788 - val_loss: 245.5742\n",
      "Epoch 93/1000\n",
      "700/700 [==============================] - 0s - loss: 80.6954 - val_loss: 138.6431\n",
      "Epoch 94/1000\n",
      "700/700 [==============================] - 0s - loss: 64.5319 - val_loss: 515.7571\n",
      "Epoch 95/1000\n",
      "700/700 [==============================] - 0s - loss: 78.6152 - val_loss: 122.7604\n",
      "Epoch 96/1000\n",
      "700/700 [==============================] - 0s - loss: 68.5782 - val_loss: 226.7962\n",
      "Epoch 97/1000\n",
      "700/700 [==============================] - 0s - loss: 78.9056 - val_loss: 119.8621\n",
      "Epoch 98/1000\n",
      "700/700 [==============================] - 0s - loss: 65.2448 - val_loss: 166.2635\n",
      "Epoch 99/1000\n",
      "700/700 [==============================] - 0s - loss: 69.4599 - val_loss: 255.8094\n",
      "Epoch 100/1000\n",
      "700/700 [==============================] - 0s - loss: 62.4851 - val_loss: 140.8431\n",
      "Epoch 101/1000\n",
      "700/700 [==============================] - 0s - loss: 95.2459 - val_loss: 130.5834\n",
      "Epoch 102/1000\n",
      "700/700 [==============================] - 0s - loss: 45.7879 - val_loss: 165.5836\n",
      "Epoch 103/1000\n",
      "700/700 [==============================] - 0s - loss: 80.9319 - val_loss: 457.6585\n",
      "Epoch 104/1000\n",
      "700/700 [==============================] - 0s - loss: 76.9270 - val_loss: 249.1572\n",
      "Epoch 105/1000\n",
      "700/700 [==============================] - 0s - loss: 61.0772 - val_loss: 179.0343\n",
      "Epoch 106/1000\n",
      "700/700 [==============================] - 0s - loss: 73.8060 - val_loss: 180.4304\n",
      "Epoch 107/1000\n",
      "700/700 [==============================] - 0s - loss: 55.9033 - val_loss: 280.3695\n",
      "Epoch 108/1000\n",
      "700/700 [==============================] - 0s - loss: 76.0850 - val_loss: 288.4714\n",
      "Epoch 109/1000\n",
      "700/700 [==============================] - 0s - loss: 81.2303 - val_loss: 176.4707\n",
      "Epoch 110/1000\n",
      "700/700 [==============================] - 0s - loss: 45.0241 - val_loss: 307.9287\n",
      "Epoch 111/1000\n",
      "700/700 [==============================] - 0s - loss: 85.2756 - val_loss: 190.0003\n",
      "Epoch 112/1000\n",
      "700/700 [==============================] - 0s - loss: 41.5801 - val_loss: 130.9287\n",
      "Epoch 113/1000\n",
      "700/700 [==============================] - 0s - loss: 59.7647 - val_loss: 124.5890\n",
      "Epoch 114/1000\n",
      "700/700 [==============================] - 0s - loss: 67.6203 - val_loss: 243.1280\n",
      "Epoch 115/1000\n",
      "700/700 [==============================] - 0s - loss: 68.7886 - val_loss: 126.7333\n",
      "Epoch 116/1000\n",
      "700/700 [==============================] - 0s - loss: 76.4648 - val_loss: 273.8541\n",
      "Epoch 117/1000\n",
      "700/700 [==============================] - 0s - loss: 61.8108 - val_loss: 123.3307\n",
      "Epoch 118/1000\n",
      "700/700 [==============================] - 0s - loss: 56.1205 - val_loss: 130.2413\n",
      "Epoch 119/1000\n",
      "700/700 [==============================] - 0s - loss: 71.0137 - val_loss: 140.2987\n",
      "Epoch 120/1000\n",
      "700/700 [==============================] - 0s - loss: 42.4983 - val_loss: 123.1737\n",
      "Epoch 121/1000\n",
      "700/700 [==============================] - 0s - loss: 69.5661 - val_loss: 226.1866\n",
      "Epoch 122/1000\n",
      "700/700 [==============================] - 0s - loss: 74.5243 - val_loss: 123.5218\n",
      "Epoch 123/1000\n",
      "700/700 [==============================] - 0s - loss: 53.8899 - val_loss: 208.3600\n",
      "Epoch 124/1000\n",
      "700/700 [==============================] - 0s - loss: 66.5400 - val_loss: 142.1141\n",
      "Epoch 125/1000\n",
      "700/700 [==============================] - 0s - loss: 58.0261 - val_loss: 138.2835\n",
      "Epoch 126/1000\n",
      "700/700 [==============================] - 0s - loss: 59.7266 - val_loss: 167.6894\n",
      "Epoch 127/1000\n",
      "700/700 [==============================] - 0s - loss: 51.4479 - val_loss: 156.5735\n",
      "Epoch 128/1000\n",
      "700/700 [==============================] - 0s - loss: 52.5996 - val_loss: 122.5211\n",
      "Epoch 129/1000\n",
      "700/700 [==============================] - 0s - loss: 71.6864 - val_loss: 125.8601\n",
      "Epoch 130/1000\n",
      "700/700 [==============================] - 0s - loss: 59.4041 - val_loss: 481.5349\n",
      "Epoch 131/1000\n",
      "700/700 [==============================] - 0s - loss: 66.2270 - val_loss: 169.4504\n",
      "Epoch 132/1000\n",
      "700/700 [==============================] - 0s - loss: 50.0104 - val_loss: 220.1253\n",
      "Epoch 133/1000\n",
      "700/700 [==============================] - 0s - loss: 52.3097 - val_loss: 138.6051\n",
      "Epoch 134/1000\n",
      "700/700 [==============================] - 0s - loss: 64.5092 - val_loss: 127.7556\n",
      "Epoch 135/1000\n",
      "700/700 [==============================] - 0s - loss: 46.8995 - val_loss: 123.2146\n",
      "Epoch 136/1000\n",
      "700/700 [==============================] - 0s - loss: 60.5545 - val_loss: 167.3938\n",
      "Epoch 137/1000\n",
      "700/700 [==============================] - 0s - loss: 60.8005 - val_loss: 179.2012\n",
      "Epoch 138/1000\n",
      "700/700 [==============================] - 0s - loss: 46.9253 - val_loss: 221.0986\n",
      "Epoch 139/1000\n",
      "700/700 [==============================] - 0s - loss: 55.9076 - val_loss: 215.6816\n",
      "Epoch 140/1000\n",
      "700/700 [==============================] - 0s - loss: 71.9356 - val_loss: 133.1488\n",
      "Epoch 141/1000\n",
      "700/700 [==============================] - 0s - loss: 39.3782 - val_loss: 131.6286\n",
      "Epoch 142/1000\n",
      "700/700 [==============================] - 0s - loss: 49.1414 - val_loss: 142.3376\n",
      "Epoch 143/1000\n",
      "700/700 [==============================] - 0s - loss: 59.9269 - val_loss: 139.6579\n",
      "Epoch 144/1000\n",
      "700/700 [==============================] - 0s - loss: 43.6173 - val_loss: 127.4519\n",
      "Epoch 145/1000\n",
      "700/700 [==============================] - 0s - loss: 50.8084 - val_loss: 130.1810\n",
      "Epoch 146/1000\n",
      "700/700 [==============================] - 0s - loss: 50.1720 - val_loss: 416.8829\n",
      "Epoch 147/1000\n",
      "700/700 [==============================] - 0s - loss: 61.2993 - val_loss: 128.0471\n",
      "Epoch 148/1000\n",
      "700/700 [==============================] - 0s - loss: 37.7647 - val_loss: 183.8447\n",
      "Epoch 149/1000\n",
      "700/700 [==============================] - 0s - loss: 62.9976 - val_loss: 176.4166\n",
      "Epoch 150/1000\n",
      "700/700 [==============================] - 0s - loss: 58.0117 - val_loss: 139.3803\n",
      "Epoch 151/1000\n",
      "700/700 [==============================] - 0s - loss: 38.9546 - val_loss: 200.5202\n",
      "Epoch 152/1000\n",
      "700/700 [==============================] - 0s - loss: 51.3128 - val_loss: 125.3679\n",
      "Epoch 153/1000\n",
      "700/700 [==============================] - 0s - loss: 59.5729 - val_loss: 191.5088\n",
      "Epoch 154/1000\n",
      "700/700 [==============================] - 0s - loss: 46.5275 - val_loss: 176.7464\n",
      "Epoch 155/1000\n",
      "700/700 [==============================] - 0s - loss: 38.9814 - val_loss: 177.1655\n",
      "Epoch 156/1000\n",
      "700/700 [==============================] - 0s - loss: 52.2486 - val_loss: 194.5170\n",
      "Epoch 157/1000\n",
      "700/700 [==============================] - 0s - loss: 47.6524 - val_loss: 313.4911\n",
      "Epoch 158/1000\n",
      "700/700 [==============================] - 0s - loss: 40.9031 - val_loss: 269.2349\n",
      "Epoch 159/1000\n",
      "700/700 [==============================] - 0s - loss: 48.8968 - val_loss: 176.3433\n",
      "Epoch 160/1000\n",
      "700/700 [==============================] - 0s - loss: 56.9211 - val_loss: 234.2820\n",
      "Epoch 161/1000\n",
      "700/700 [==============================] - 0s - loss: 36.6286 - val_loss: 124.7029\n",
      "Epoch 162/1000\n",
      "700/700 [==============================] - 0s - loss: 49.2615 - val_loss: 135.4563\n",
      "Epoch 163/1000\n",
      "700/700 [==============================] - 0s - loss: 59.6232 - val_loss: 151.5588\n",
      "Epoch 164/1000\n",
      "700/700 [==============================] - 0s - loss: 37.9112 - val_loss: 133.1607\n",
      "Epoch 165/1000\n",
      "700/700 [==============================] - 0s - loss: 51.7256 - val_loss: 139.9179\n",
      "Epoch 166/1000\n",
      "700/700 [==============================] - 0s - loss: 47.1993 - val_loss: 141.4231\n",
      "Epoch 167/1000\n",
      "700/700 [==============================] - 0s - loss: 36.4182 - val_loss: 156.1530\n",
      "Epoch 168/1000\n",
      "700/700 [==============================] - 0s - loss: 42.7182 - val_loss: 216.6233\n",
      "Epoch 169/1000\n",
      "700/700 [==============================] - 0s - loss: 48.8958 - val_loss: 176.9557\n",
      "Epoch 170/1000\n",
      "700/700 [==============================] - 0s - loss: 44.9730 - val_loss: 129.4398\n",
      "Epoch 171/1000\n",
      "700/700 [==============================] - 0s - loss: 38.0219 - val_loss: 170.4787\n",
      "Epoch 172/1000\n",
      "700/700 [==============================] - 0s - loss: 59.3592 - val_loss: 130.3819\n",
      "Epoch 173/1000\n",
      "700/700 [==============================] - 0s - loss: 34.1752 - val_loss: 151.0474\n",
      "Epoch 174/1000\n",
      "700/700 [==============================] - 0s - loss: 52.6582 - val_loss: 130.9793\n",
      "Epoch 175/1000\n",
      "700/700 [==============================] - 0s - loss: 39.5866 - val_loss: 137.1930\n",
      "Epoch 176/1000\n",
      "700/700 [==============================] - 0s - loss: 40.0789 - val_loss: 259.7809\n",
      "Epoch 177/1000\n",
      "700/700 [==============================] - 0s - loss: 37.3297 - val_loss: 359.8411\n",
      "Epoch 178/1000\n",
      "700/700 [==============================] - 0s - loss: 50.1460 - val_loss: 290.9955\n",
      "Epoch 179/1000\n",
      "700/700 [==============================] - 0s - loss: 49.0924 - val_loss: 228.2414\n",
      "Epoch 180/1000\n",
      "700/700 [==============================] - 0s - loss: 40.3285 - val_loss: 172.7904\n",
      "Epoch 181/1000\n",
      "700/700 [==============================] - 0s - loss: 44.5278 - val_loss: 382.5724\n",
      "Epoch 182/1000\n",
      "700/700 [==============================] - 0s - loss: 45.4927 - val_loss: 167.6443\n",
      "Epoch 183/1000\n",
      "700/700 [==============================] - 0s - loss: 29.9940 - val_loss: 151.4076\n",
      "Epoch 184/1000\n",
      "700/700 [==============================] - 0s - loss: 39.4611 - val_loss: 167.0086\n",
      "Epoch 185/1000\n",
      "700/700 [==============================] - 0s - loss: 43.1701 - val_loss: 157.8100\n",
      "Epoch 186/1000\n",
      "700/700 [==============================] - 0s - loss: 49.9786 - val_loss: 220.6907\n",
      "Epoch 187/1000\n",
      "700/700 [==============================] - 0s - loss: 37.4401 - val_loss: 137.2905\n",
      "Epoch 188/1000\n",
      "700/700 [==============================] - 0s - loss: 39.0467 - val_loss: 165.2917\n",
      "Epoch 189/1000\n",
      "700/700 [==============================] - 0s - loss: 33.6636 - val_loss: 205.4208\n",
      "Epoch 190/1000\n",
      "700/700 [==============================] - 0s - loss: 51.5993 - val_loss: 214.5546\n",
      "Epoch 191/1000\n",
      "700/700 [==============================] - 0s - loss: 39.4082 - val_loss: 151.6088\n",
      "Epoch 192/1000\n",
      "700/700 [==============================] - 0s - loss: 32.1233 - val_loss: 143.0734\n",
      "Epoch 193/1000\n",
      "700/700 [==============================] - 0s - loss: 41.9846 - val_loss: 202.4341\n",
      "Epoch 194/1000\n",
      "700/700 [==============================] - 0s - loss: 39.6843 - val_loss: 171.2530\n",
      "Epoch 195/1000\n",
      "700/700 [==============================] - 0s - loss: 43.4440 - val_loss: 149.1174\n",
      "Epoch 196/1000\n",
      "700/700 [==============================] - 0s - loss: 42.5587 - val_loss: 357.1393\n",
      "Epoch 197/1000\n",
      "700/700 [==============================] - 0s - loss: 40.8936 - val_loss: 528.2980\n",
      "Epoch 198/1000\n",
      "700/700 [==============================] - 0s - loss: 48.4526 - val_loss: 152.1153\n",
      "Epoch 199/1000\n",
      "700/700 [==============================] - 0s - loss: 34.9008 - val_loss: 296.0219\n",
      "Epoch 200/1000\n",
      "700/700 [==============================] - 0s - loss: 37.9099 - val_loss: 223.4984\n",
      "Epoch 201/1000\n",
      "700/700 [==============================] - 0s - loss: 34.2822 - val_loss: 129.3788\n",
      "Epoch 202/1000\n",
      "700/700 [==============================] - 0s - loss: 38.2760 - val_loss: 151.5918\n",
      "Epoch 203/1000\n",
      "700/700 [==============================] - 0s - loss: 51.6894 - val_loss: 162.5112\n",
      "Epoch 204/1000\n",
      "700/700 [==============================] - 0s - loss: 29.1212 - val_loss: 136.1747\n",
      "Epoch 205/1000\n",
      "700/700 [==============================] - 0s - loss: 31.9667 - val_loss: 158.6588\n",
      "Epoch 206/1000\n",
      "700/700 [==============================] - 0s - loss: 40.4090 - val_loss: 179.4847\n",
      "Epoch 207/1000\n",
      "700/700 [==============================] - 0s - loss: 38.2647 - val_loss: 340.9602\n",
      "Epoch 208/1000\n",
      "700/700 [==============================] - 0s - loss: 39.7306 - val_loss: 214.9581\n",
      "Epoch 209/1000\n",
      "700/700 [==============================] - 0s - loss: 35.7817 - val_loss: 147.1892\n",
      "Epoch 210/1000\n",
      "700/700 [==============================] - 0s - loss: 38.3088 - val_loss: 172.6863\n",
      "Epoch 211/1000\n",
      "700/700 [==============================] - 0s - loss: 36.9037 - val_loss: 246.8964\n",
      "Epoch 212/1000\n",
      "700/700 [==============================] - 0s - loss: 35.6615 - val_loss: 346.3120\n",
      "Epoch 213/1000\n",
      "700/700 [==============================] - 0s - loss: 44.1791 - val_loss: 172.5599\n",
      "Epoch 214/1000\n",
      "700/700 [==============================] - 0s - loss: 33.1726 - val_loss: 149.0587\n",
      "Epoch 215/1000\n",
      "700/700 [==============================] - 0s - loss: 31.0852 - val_loss: 308.9640\n",
      "Epoch 216/1000\n",
      "700/700 [==============================] - 0s - loss: 47.0190 - val_loss: 149.4817\n",
      "Epoch 217/1000\n",
      "700/700 [==============================] - 0s - loss: 34.2590 - val_loss: 155.9610\n",
      "Epoch 218/1000\n",
      "700/700 [==============================] - 0s - loss: 27.6588 - val_loss: 175.0867\n",
      "Epoch 219/1000\n",
      "700/700 [==============================] - 0s - loss: 41.8359 - val_loss: 363.0625\n",
      "Epoch 220/1000\n",
      "700/700 [==============================] - 0s - loss: 45.3563 - val_loss: 166.8393\n",
      "Epoch 221/1000\n",
      "700/700 [==============================] - 0s - loss: 26.6816 - val_loss: 153.8499\n",
      "Epoch 222/1000\n",
      "700/700 [==============================] - 0s - loss: 29.4662 - val_loss: 138.9563\n",
      "Epoch 223/1000\n",
      "700/700 [==============================] - 0s - loss: 43.7907 - val_loss: 134.2315\n",
      "Epoch 224/1000\n",
      "700/700 [==============================] - 0s - loss: 31.1350 - val_loss: 182.2960\n",
      "Epoch 225/1000\n",
      "700/700 [==============================] - 0s - loss: 32.4497 - val_loss: 349.0118\n",
      "Epoch 226/1000\n",
      "700/700 [==============================] - 0s - loss: 40.2187 - val_loss: 126.5079\n",
      "Epoch 227/1000\n",
      "700/700 [==============================] - 0s - loss: 37.9837 - val_loss: 141.1610\n",
      "Epoch 228/1000\n",
      "700/700 [==============================] - 0s - loss: 27.9870 - val_loss: 168.1731\n",
      "Epoch 229/1000\n",
      "700/700 [==============================] - 0s - loss: 42.7253 - val_loss: 165.7158\n",
      "Epoch 230/1000\n",
      "700/700 [==============================] - 0s - loss: 29.0597 - val_loss: 155.9105\n",
      "Epoch 231/1000\n",
      "700/700 [==============================] - 0s - loss: 37.5817 - val_loss: 186.6073\n",
      "Epoch 232/1000\n",
      "700/700 [==============================] - 0s - loss: 33.3955 - val_loss: 178.9681\n",
      "Epoch 233/1000\n",
      "700/700 [==============================] - 0s - loss: 33.8686 - val_loss: 210.4077\n",
      "Epoch 234/1000\n",
      "700/700 [==============================] - 0s - loss: 32.8637 - val_loss: 140.9529\n",
      "Epoch 235/1000\n",
      "700/700 [==============================] - 0s - loss: 34.4637 - val_loss: 198.6050\n",
      "Epoch 236/1000\n",
      "700/700 [==============================] - 0s - loss: 33.0482 - val_loss: 133.4488\n",
      "Epoch 237/1000\n",
      "700/700 [==============================] - 0s - loss: 28.6972 - val_loss: 298.1080\n",
      "Epoch 238/1000\n",
      "700/700 [==============================] - 0s - loss: 45.0527 - val_loss: 211.8377\n",
      "Epoch 239/1000\n",
      "700/700 [==============================] - 0s - loss: 29.3767 - val_loss: 182.5474\n",
      "Epoch 240/1000\n",
      "700/700 [==============================] - 0s - loss: 30.8489 - val_loss: 267.5487\n",
      "Epoch 241/1000\n",
      "700/700 [==============================] - 0s - loss: 36.8299 - val_loss: 152.3321\n",
      "Epoch 242/1000\n",
      "700/700 [==============================] - 0s - loss: 28.1376 - val_loss: 141.2253\n",
      "Epoch 243/1000\n",
      "700/700 [==============================] - 0s - loss: 42.2996 - val_loss: 210.1059\n",
      "Epoch 244/1000\n",
      "700/700 [==============================] - 0s - loss: 29.9347 - val_loss: 168.1576\n",
      "Epoch 245/1000\n",
      "700/700 [==============================] - 0s - loss: 32.4943 - val_loss: 388.1499\n",
      "Epoch 246/1000\n",
      "700/700 [==============================] - 0s - loss: 35.4929 - val_loss: 144.9968\n",
      "Epoch 247/1000\n",
      "700/700 [==============================] - 0s - loss: 32.7594 - val_loss: 145.3137\n",
      "Epoch 248/1000\n",
      "700/700 [==============================] - 0s - loss: 40.0027 - val_loss: 131.3632\n",
      "Epoch 249/1000\n",
      "700/700 [==============================] - 0s - loss: 30.0101 - val_loss: 137.6930\n",
      "Epoch 250/1000\n",
      "700/700 [==============================] - 0s - loss: 31.2168 - val_loss: 138.5430\n",
      "Epoch 251/1000\n",
      "700/700 [==============================] - 0s - loss: 26.0032 - val_loss: 148.4434\n",
      "Epoch 252/1000\n",
      "700/700 [==============================] - 0s - loss: 42.6613 - val_loss: 209.5890\n",
      "Epoch 253/1000\n",
      "700/700 [==============================] - 0s - loss: 26.5307 - val_loss: 132.3250\n",
      "Epoch 254/1000\n",
      "700/700 [==============================] - 0s - loss: 34.1274 - val_loss: 153.6330\n",
      "Epoch 255/1000\n",
      "700/700 [==============================] - 0s - loss: 30.1820 - val_loss: 139.4448\n",
      "Epoch 256/1000\n",
      "700/700 [==============================] - 0s - loss: 38.9621 - val_loss: 146.5704\n",
      "Epoch 257/1000\n",
      "700/700 [==============================] - 0s - loss: 24.0161 - val_loss: 138.2317\n",
      "Epoch 258/1000\n",
      "700/700 [==============================] - 0s - loss: 35.7403 - val_loss: 214.6926\n",
      "Epoch 259/1000\n",
      "700/700 [==============================] - 0s - loss: 27.2872 - val_loss: 348.2931\n",
      "Epoch 260/1000\n",
      "700/700 [==============================] - 0s - loss: 35.8257 - val_loss: 134.8174\n",
      "Epoch 261/1000\n",
      "700/700 [==============================] - 0s - loss: 33.2871 - val_loss: 136.4447\n",
      "Epoch 262/1000\n",
      "700/700 [==============================] - 0s - loss: 27.8444 - val_loss: 142.2534\n",
      "Epoch 263/1000\n",
      "700/700 [==============================] - 0s - loss: 22.4432 - val_loss: 194.5948\n",
      "Epoch 264/1000\n",
      "700/700 [==============================] - 0s - loss: 41.2267 - val_loss: 166.8745\n",
      "Epoch 265/1000\n",
      "700/700 [==============================] - 0s - loss: 30.4481 - val_loss: 175.4997\n",
      "Epoch 266/1000\n",
      "700/700 [==============================] - 0s - loss: 31.1893 - val_loss: 236.9465\n",
      "Epoch 267/1000\n",
      "700/700 [==============================] - 0s - loss: 32.9605 - val_loss: 243.9361\n",
      "Epoch 268/1000\n",
      "700/700 [==============================] - 0s - loss: 25.7111 - val_loss: 287.6775\n",
      "Epoch 269/1000\n",
      "700/700 [==============================] - 0s - loss: 39.1887 - val_loss: 260.6698\n",
      "Epoch 270/1000\n",
      "700/700 [==============================] - 0s - loss: 31.2565 - val_loss: 167.0451\n",
      "Epoch 271/1000\n",
      "700/700 [==============================] - 0s - loss: 21.6973 - val_loss: 136.5012\n",
      "Epoch 272/1000\n",
      "700/700 [==============================] - 0s - loss: 34.5016 - val_loss: 138.4281\n",
      "Epoch 273/1000\n",
      "700/700 [==============================] - 0s - loss: 29.3266 - val_loss: 149.3144\n",
      "Epoch 274/1000\n",
      "700/700 [==============================] - 0s - loss: 29.4753 - val_loss: 210.0664\n",
      "Epoch 275/1000\n",
      "700/700 [==============================] - 0s - loss: 27.9515 - val_loss: 198.3597\n",
      "Epoch 276/1000\n",
      "700/700 [==============================] - 0s - loss: 33.8256 - val_loss: 257.4028\n",
      "Epoch 277/1000\n",
      "700/700 [==============================] - 0s - loss: 32.1290 - val_loss: 155.5180\n",
      "Epoch 278/1000\n",
      "700/700 [==============================] - 0s - loss: 19.8390 - val_loss: 343.2973\n",
      "Epoch 279/1000\n",
      "700/700 [==============================] - 0s - loss: 34.3843 - val_loss: 261.3973\n",
      "Epoch 280/1000\n",
      "700/700 [==============================] - 0s - loss: 27.4123 - val_loss: 218.5704\n",
      "Epoch 281/1000\n",
      "700/700 [==============================] - 0s - loss: 37.2713 - val_loss: 214.5144\n",
      "Epoch 282/1000\n",
      "700/700 [==============================] - 0s - loss: 21.8456 - val_loss: 157.7814\n",
      "Epoch 283/1000\n",
      "700/700 [==============================] - 0s - loss: 30.8995 - val_loss: 144.2956\n",
      "Epoch 284/1000\n",
      "700/700 [==============================] - 0s - loss: 24.0070 - val_loss: 148.1527\n",
      "Epoch 285/1000\n",
      "700/700 [==============================] - 0s - loss: 33.3249 - val_loss: 249.4791\n",
      "Epoch 286/1000\n",
      "700/700 [==============================] - 0s - loss: 32.7830 - val_loss: 334.4143\n",
      "Epoch 287/1000\n",
      "700/700 [==============================] - 0s - loss: 27.3666 - val_loss: 156.6887\n",
      "Epoch 288/1000\n",
      "700/700 [==============================] - 0s - loss: 24.1213 - val_loss: 131.7589\n",
      "Epoch 289/1000\n",
      "700/700 [==============================] - 0s - loss: 30.4274 - val_loss: 158.4886\n",
      "Epoch 290/1000\n",
      "700/700 [==============================] - 0s - loss: 26.6395 - val_loss: 188.8618\n",
      "Epoch 291/1000\n",
      "700/700 [==============================] - 0s - loss: 30.3532 - val_loss: 141.5889\n",
      "Epoch 292/1000\n",
      "700/700 [==============================] - 0s - loss: 25.8782 - val_loss: 148.1162\n",
      "Epoch 293/1000\n",
      "700/700 [==============================] - 0s - loss: 20.0023 - val_loss: 192.3990\n",
      "Epoch 294/1000\n",
      "700/700 [==============================] - 0s - loss: 39.4457 - val_loss: 255.9948\n",
      "Epoch 295/1000\n",
      "700/700 [==============================] - 0s - loss: 21.4636 - val_loss: 211.1293\n",
      "Epoch 296/1000\n",
      "700/700 [==============================] - 0s - loss: 31.8969 - val_loss: 354.2902\n",
      "Epoch 297/1000\n",
      "700/700 [==============================] - 0s - loss: 30.7502 - val_loss: 138.3551\n",
      "Epoch 298/1000\n",
      "700/700 [==============================] - 0s - loss: 28.0785 - val_loss: 143.0791\n",
      "Epoch 299/1000\n",
      "700/700 [==============================] - 0s - loss: 18.7788 - val_loss: 153.2193\n",
      "Epoch 300/1000\n",
      "700/700 [==============================] - 0s - loss: 33.8707 - val_loss: 138.3592\n",
      "Epoch 301/1000\n",
      "700/700 [==============================] - 0s - loss: 25.0367 - val_loss: 137.6596\n",
      "Epoch 302/1000\n",
      "700/700 [==============================] - 0s - loss: 22.6871 - val_loss: 242.8350\n",
      "Epoch 303/1000\n",
      "700/700 [==============================] - 0s - loss: 36.5840 - val_loss: 165.0395\n",
      "Epoch 304/1000\n",
      "700/700 [==============================] - 0s - loss: 19.1272 - val_loss: 203.0019\n",
      "Epoch 305/1000\n",
      "700/700 [==============================] - 0s - loss: 34.4640 - val_loss: 153.3140\n",
      "Epoch 306/1000\n",
      "700/700 [==============================] - 0s - loss: 23.9440 - val_loss: 143.1032\n",
      "Epoch 307/1000\n",
      "700/700 [==============================] - 0s - loss: 21.2615 - val_loss: 138.1680\n",
      "Epoch 308/1000\n",
      "700/700 [==============================] - 0s - loss: 32.8908 - val_loss: 144.5778\n",
      "Epoch 309/1000\n",
      "700/700 [==============================] - 0s - loss: 20.2239 - val_loss: 158.5978\n",
      "Epoch 310/1000\n",
      "700/700 [==============================] - 0s - loss: 32.7863 - val_loss: 136.9152\n",
      "Epoch 311/1000\n",
      "700/700 [==============================] - 0s - loss: 22.3462 - val_loss: 170.1893\n",
      "Epoch 312/1000\n",
      "700/700 [==============================] - 0s - loss: 24.8193 - val_loss: 138.1236\n",
      "Epoch 313/1000\n",
      "700/700 [==============================] - 0s - loss: 33.0776 - val_loss: 143.2292\n",
      "Epoch 314/1000\n",
      "700/700 [==============================] - 0s - loss: 22.7831 - val_loss: 165.8787\n",
      "Epoch 315/1000\n",
      "700/700 [==============================] - 0s - loss: 28.3158 - val_loss: 142.0156\n",
      "Epoch 316/1000\n",
      "700/700 [==============================] - 0s - loss: 22.0697 - val_loss: 135.0443\n",
      "Epoch 317/1000\n",
      "700/700 [==============================] - 0s - loss: 27.3808 - val_loss: 141.9730\n",
      "Epoch 318/1000\n",
      "700/700 [==============================] - 0s - loss: 21.4948 - val_loss: 259.1584\n",
      "Epoch 319/1000\n",
      "700/700 [==============================] - 0s - loss: 31.3303 - val_loss: 184.8963\n",
      "Epoch 320/1000\n",
      "700/700 [==============================] - 0s - loss: 15.2226 - val_loss: 188.8552\n",
      "Epoch 321/1000\n",
      "700/700 [==============================] - 0s - loss: 34.2771 - val_loss: 182.2379\n",
      "Epoch 322/1000\n",
      "700/700 [==============================] - 0s - loss: 27.4001 - val_loss: 257.1327\n",
      "Epoch 323/1000\n",
      "700/700 [==============================] - 0s - loss: 16.8890 - val_loss: 239.7351\n",
      "Epoch 324/1000\n",
      "700/700 [==============================] - 0s - loss: 25.0272 - val_loss: 286.0326\n",
      "Epoch 325/1000\n",
      "700/700 [==============================] - 0s - loss: 32.5783 - val_loss: 221.0769\n",
      "Epoch 326/1000\n",
      "700/700 [==============================] - 0s - loss: 23.4686 - val_loss: 182.3533\n",
      "Epoch 327/1000\n",
      "700/700 [==============================] - 0s - loss: 28.6637 - val_loss: 182.0421\n",
      "Epoch 328/1000\n",
      "700/700 [==============================] - 0s - loss: 21.8911 - val_loss: 194.2653\n",
      "Epoch 329/1000\n",
      "700/700 [==============================] - 0s - loss: 30.5172 - val_loss: 153.8361\n",
      "Epoch 330/1000\n",
      "700/700 [==============================] - 0s - loss: 19.3086 - val_loss: 136.7820\n",
      "Epoch 331/1000\n",
      "700/700 [==============================] - 0s - loss: 24.9015 - val_loss: 191.0980\n",
      "Epoch 332/1000\n",
      "700/700 [==============================] - 0s - loss: 25.6660 - val_loss: 138.8675\n",
      "Epoch 333/1000\n",
      "700/700 [==============================] - 0s - loss: 21.7143 - val_loss: 137.9632\n",
      "Epoch 334/1000\n",
      "700/700 [==============================] - 0s - loss: 29.5681 - val_loss: 142.3083\n",
      "Epoch 335/1000\n",
      "700/700 [==============================] - 0s - loss: 20.4170 - val_loss: 136.8742\n",
      "Epoch 336/1000\n",
      "700/700 [==============================] - 0s - loss: 24.7583 - val_loss: 137.3292\n",
      "Epoch 337/1000\n",
      "700/700 [==============================] - 0s - loss: 25.0899 - val_loss: 159.9155\n",
      "Epoch 338/1000\n",
      "700/700 [==============================] - 0s - loss: 24.4224 - val_loss: 140.1620\n",
      "Epoch 339/1000\n",
      "700/700 [==============================] - 0s - loss: 24.4531 - val_loss: 157.6829\n",
      "Epoch 340/1000\n",
      "700/700 [==============================] - 0s - loss: 25.7568 - val_loss: 139.2522\n",
      "Epoch 341/1000\n",
      "700/700 [==============================] - 0s - loss: 32.9102 - val_loss: 136.9940\n",
      "Epoch 342/1000\n",
      "700/700 [==============================] - 0s - loss: 18.1786 - val_loss: 166.0244\n",
      "Epoch 343/1000\n",
      "700/700 [==============================] - 0s - loss: 21.3218 - val_loss: 215.4027\n",
      "Epoch 344/1000\n",
      "700/700 [==============================] - 0s - loss: 22.5124 - val_loss: 401.4590\n",
      "Epoch 345/1000\n",
      "700/700 [==============================] - 0s - loss: 29.2440 - val_loss: 201.9936\n",
      "Epoch 346/1000\n",
      "700/700 [==============================] - 0s - loss: 21.3223 - val_loss: 153.2405\n",
      "Epoch 347/1000\n",
      "700/700 [==============================] - 0s - loss: 21.7446 - val_loss: 135.9502\n",
      "Epoch 348/1000\n",
      "700/700 [==============================] - 0s - loss: 26.5898 - val_loss: 135.5703\n",
      "Epoch 349/1000\n",
      "700/700 [==============================] - 0s - loss: 20.1889 - val_loss: 241.0090\n",
      "Epoch 350/1000\n",
      "700/700 [==============================] - 0s - loss: 27.8049 - val_loss: 147.0533\n",
      "Epoch 351/1000\n",
      "700/700 [==============================] - 0s - loss: 26.3516 - val_loss: 159.7367\n",
      "Epoch 352/1000\n",
      "700/700 [==============================] - 0s - loss: 22.5112 - val_loss: 177.7565\n",
      "Epoch 353/1000\n",
      "700/700 [==============================] - 0s - loss: 20.7688 - val_loss: 251.5279\n",
      "Epoch 354/1000\n",
      "700/700 [==============================] - 0s - loss: 28.0402 - val_loss: 137.8657\n",
      "Epoch 355/1000\n",
      "700/700 [==============================] - 0s - loss: 21.2665 - val_loss: 143.4460\n",
      "Epoch 356/1000\n",
      "700/700 [==============================] - 0s - loss: 24.8028 - val_loss: 139.4764\n",
      "Epoch 357/1000\n",
      "700/700 [==============================] - 0s - loss: 20.1602 - val_loss: 146.4092\n",
      "Epoch 358/1000\n",
      "700/700 [==============================] - 0s - loss: 24.5950 - val_loss: 140.5533\n",
      "Epoch 359/1000\n",
      "700/700 [==============================] - 0s - loss: 22.2864 - val_loss: 164.3450\n",
      "Epoch 360/1000\n",
      "700/700 [==============================] - 0s - loss: 29.2433 - val_loss: 156.9294\n",
      "Epoch 361/1000\n",
      "700/700 [==============================] - 0s - loss: 18.6451 - val_loss: 183.0836\n",
      "Epoch 362/1000\n",
      "700/700 [==============================] - 0s - loss: 29.9927 - val_loss: 179.4778\n",
      "Epoch 363/1000\n",
      "700/700 [==============================] - 0s - loss: 21.8301 - val_loss: 160.2473\n",
      "Epoch 364/1000\n",
      "700/700 [==============================] - 0s - loss: 19.1885 - val_loss: 186.9346\n",
      "Epoch 365/1000\n",
      "700/700 [==============================] - 0s - loss: 21.5235 - val_loss: 157.4484\n",
      "Epoch 366/1000\n",
      "700/700 [==============================] - 0s - loss: 24.8438 - val_loss: 141.1504\n",
      "Epoch 367/1000\n",
      "700/700 [==============================] - 0s - loss: 25.9164 - val_loss: 139.0718\n",
      "Epoch 368/1000\n",
      "700/700 [==============================] - 0s - loss: 24.6397 - val_loss: 142.8625\n",
      "Epoch 369/1000\n",
      "700/700 [==============================] - 0s - loss: 16.8333 - val_loss: 167.4085\n",
      "Epoch 370/1000\n",
      "700/700 [==============================] - 0s - loss: 22.6155 - val_loss: 262.6224\n",
      "Epoch 371/1000\n",
      "700/700 [==============================] - 0s - loss: 26.2898 - val_loss: 198.2301\n",
      "Epoch 372/1000\n",
      "700/700 [==============================] - 0s - loss: 18.3769 - val_loss: 193.4263\n",
      "Epoch 373/1000\n",
      "700/700 [==============================] - 0s - loss: 25.3168 - val_loss: 267.4244\n",
      "Epoch 374/1000\n",
      "700/700 [==============================] - 0s - loss: 22.9266 - val_loss: 222.1008\n",
      "Epoch 375/1000\n",
      "700/700 [==============================] - 0s - loss: 24.6599 - val_loss: 157.7736\n",
      "Epoch 376/1000\n",
      "700/700 [==============================] - 0s - loss: 15.8387 - val_loss: 148.4865\n",
      "Epoch 377/1000\n",
      "700/700 [==============================] - 0s - loss: 24.3238 - val_loss: 152.0624\n",
      "Epoch 378/1000\n",
      "700/700 [==============================] - 0s - loss: 17.4069 - val_loss: 217.7894\n",
      "Epoch 379/1000\n",
      "700/700 [==============================] - 0s - loss: 32.9947 - val_loss: 204.4615\n",
      "Epoch 380/1000\n",
      "700/700 [==============================] - 0s - loss: 16.3890 - val_loss: 181.5119\n",
      "Epoch 381/1000\n",
      "700/700 [==============================] - 0s - loss: 20.3051 - val_loss: 297.9495\n",
      "Epoch 382/1000\n",
      "700/700 [==============================] - 0s - loss: 30.3473 - val_loss: 158.9433\n",
      "Epoch 383/1000\n",
      "700/700 [==============================] - 0s - loss: 19.4232 - val_loss: 148.7573\n",
      "Epoch 384/1000\n",
      "700/700 [==============================] - 0s - loss: 16.8111 - val_loss: 168.1294\n",
      "Epoch 385/1000\n",
      "700/700 [==============================] - 0s - loss: 20.1073 - val_loss: 195.2463\n",
      "Epoch 386/1000\n",
      "700/700 [==============================] - 0s - loss: 22.4754 - val_loss: 146.3489\n",
      "Epoch 387/1000\n",
      "700/700 [==============================] - 0s - loss: 25.8890 - val_loss: 207.6647\n",
      "Epoch 388/1000\n",
      "700/700 [==============================] - 0s - loss: 23.4550 - val_loss: 176.9287\n",
      "Epoch 389/1000\n",
      "700/700 [==============================] - 0s - loss: 19.6516 - val_loss: 139.2469\n",
      "Epoch 390/1000\n",
      "700/700 [==============================] - 0s - loss: 24.7974 - val_loss: 139.7731\n",
      "Epoch 391/1000\n",
      "700/700 [==============================] - 0s - loss: 19.7800 - val_loss: 152.3043\n",
      "Epoch 392/1000\n",
      "700/700 [==============================] - 0s - loss: 26.8634 - val_loss: 139.9548\n",
      "Epoch 393/1000\n",
      "700/700 [==============================] - 0s - loss: 20.2963 - val_loss: 138.4839\n",
      "Epoch 394/1000\n",
      "700/700 [==============================] - 0s - loss: 23.3079 - val_loss: 141.1159\n",
      "Epoch 395/1000\n",
      "700/700 [==============================] - 0s - loss: 20.8735 - val_loss: 142.8733\n",
      "Epoch 396/1000\n",
      "700/700 [==============================] - 0s - loss: 22.1247 - val_loss: 142.2552\n",
      "Epoch 397/1000\n",
      "700/700 [==============================] - 0s - loss: 19.2775 - val_loss: 194.3892\n",
      "Epoch 398/1000\n",
      "700/700 [==============================] - 0s - loss: 16.2688 - val_loss: 144.6097\n",
      "Epoch 399/1000\n",
      "700/700 [==============================] - 0s - loss: 23.9413 - val_loss: 146.9454\n",
      "Epoch 400/1000\n",
      "700/700 [==============================] - 0s - loss: 22.1756 - val_loss: 421.4379\n",
      "Epoch 401/1000\n",
      "700/700 [==============================] - 0s - loss: 20.4637 - val_loss: 238.4018\n",
      "Epoch 402/1000\n",
      "700/700 [==============================] - 0s - loss: 23.9825 - val_loss: 204.0942\n",
      "Epoch 403/1000\n",
      "700/700 [==============================] - 0s - loss: 20.4107 - val_loss: 201.9315\n",
      "Epoch 404/1000\n",
      "700/700 [==============================] - 0s - loss: 21.6391 - val_loss: 183.4174\n",
      "Epoch 405/1000\n",
      "700/700 [==============================] - 0s - loss: 32.7493 - val_loss: 141.3041\n",
      "Epoch 406/1000\n",
      "700/700 [==============================] - 0s - loss: 13.9234 - val_loss: 149.9873\n",
      "Epoch 407/1000\n",
      "700/700 [==============================] - 0s - loss: 14.4623 - val_loss: 355.2900\n",
      "Epoch 408/1000\n",
      "700/700 [==============================] - 0s - loss: 30.0155 - val_loss: 216.3391\n",
      "Epoch 409/1000\n",
      "700/700 [==============================] - 0s - loss: 15.9365 - val_loss: 173.2872\n",
      "Epoch 410/1000\n",
      "700/700 [==============================] - 0s - loss: 26.4021 - val_loss: 161.3591\n",
      "Epoch 411/1000\n",
      "700/700 [==============================] - 0s - loss: 21.3643 - val_loss: 146.9774\n",
      "Epoch 412/1000\n",
      "700/700 [==============================] - 0s - loss: 17.5546 - val_loss: 145.5725\n",
      "Epoch 413/1000\n",
      "700/700 [==============================] - 0s - loss: 20.6580 - val_loss: 148.7602\n",
      "Epoch 414/1000\n",
      "700/700 [==============================] - 0s - loss: 26.1197 - val_loss: 143.1144\n",
      "Epoch 415/1000\n",
      "700/700 [==============================] - 0s - loss: 18.8446 - val_loss: 136.4395\n",
      "Epoch 416/1000\n",
      "700/700 [==============================] - 0s - loss: 19.0126 - val_loss: 142.7454\n",
      "Epoch 417/1000\n",
      "700/700 [==============================] - 0s - loss: 23.4318 - val_loss: 146.1207\n",
      "Epoch 418/1000\n",
      "700/700 [==============================] - 0s - loss: 21.2676 - val_loss: 148.6211\n",
      "Epoch 419/1000\n",
      "700/700 [==============================] - 0s - loss: 20.7280 - val_loss: 152.7277\n",
      "Epoch 420/1000\n",
      "700/700 [==============================] - 0s - loss: 18.5079 - val_loss: 137.2240\n",
      "Epoch 421/1000\n",
      "700/700 [==============================] - 0s - loss: 21.7882 - val_loss: 136.0123\n",
      "Epoch 422/1000\n",
      "700/700 [==============================] - 0s - loss: 18.9331 - val_loss: 281.7306\n",
      "Epoch 423/1000\n",
      "700/700 [==============================] - 0s - loss: 21.1725 - val_loss: 238.0616\n",
      "Epoch 424/1000\n",
      "700/700 [==============================] - 0s - loss: 23.8214 - val_loss: 182.9360\n",
      "Epoch 425/1000\n",
      "700/700 [==============================] - 0s - loss: 19.0741 - val_loss: 276.4508\n",
      "Epoch 426/1000\n",
      "700/700 [==============================] - 0s - loss: 22.8487 - val_loss: 176.1453\n",
      "Epoch 427/1000\n",
      "700/700 [==============================] - 0s - loss: 21.7444 - val_loss: 204.3533\n",
      "Epoch 428/1000\n",
      "700/700 [==============================] - 0s - loss: 21.6127 - val_loss: 290.9508\n",
      "Epoch 429/1000\n",
      "700/700 [==============================] - 0s - loss: 19.6851 - val_loss: 261.6951\n",
      "Epoch 430/1000\n",
      "700/700 [==============================] - 0s - loss: 22.8886 - val_loss: 184.6200\n",
      "Epoch 431/1000\n",
      "700/700 [==============================] - 0s - loss: 16.8408 - val_loss: 230.9885\n",
      "Epoch 432/1000\n",
      "700/700 [==============================] - 0s - loss: 17.1592 - val_loss: 338.0613\n",
      "Epoch 433/1000\n",
      "700/700 [==============================] - 0s - loss: 25.3263 - val_loss: 184.9584\n",
      "Epoch 434/1000\n",
      "700/700 [==============================] - 0s - loss: 18.4195 - val_loss: 194.0960\n",
      "Epoch 435/1000\n",
      "700/700 [==============================] - 0s - loss: 21.1982 - val_loss: 167.6162\n",
      "Epoch 436/1000\n",
      "700/700 [==============================] - 0s - loss: 17.0006 - val_loss: 140.9058\n",
      "Epoch 437/1000\n",
      "700/700 [==============================] - 0s - loss: 30.3112 - val_loss: 139.3587\n",
      "Epoch 438/1000\n",
      "700/700 [==============================] - 0s - loss: 10.6635 - val_loss: 143.1002\n",
      "Epoch 439/1000\n",
      "700/700 [==============================] - 0s - loss: 24.5885 - val_loss: 138.7433\n",
      "Epoch 440/1000\n",
      "700/700 [==============================] - 0s - loss: 21.8934 - val_loss: 139.2816\n",
      "Epoch 441/1000\n",
      "700/700 [==============================] - 0s - loss: 17.3934 - val_loss: 152.1291\n",
      "Epoch 442/1000\n",
      "700/700 [==============================] - 0s - loss: 18.5205 - val_loss: 161.0955\n",
      "Epoch 443/1000\n",
      "700/700 [==============================] - 0s - loss: 18.8792 - val_loss: 205.2539\n",
      "Epoch 444/1000\n",
      "700/700 [==============================] - 0s - loss: 22.6335 - val_loss: 180.2173\n",
      "Epoch 445/1000\n",
      "700/700 [==============================] - 0s - loss: 18.6191 - val_loss: 133.9456\n",
      "Epoch 446/1000\n",
      "700/700 [==============================] - 0s - loss: 19.1887 - val_loss: 133.9302\n",
      "Epoch 447/1000\n",
      "700/700 [==============================] - 0s - loss: 16.3118 - val_loss: 138.4476\n",
      "Epoch 448/1000\n",
      "700/700 [==============================] - 0s - loss: 26.1224 - val_loss: 142.9577\n",
      "Epoch 449/1000\n",
      "700/700 [==============================] - 0s - loss: 19.0796 - val_loss: 138.2084\n",
      "Epoch 450/1000\n",
      "700/700 [==============================] - 0s - loss: 16.1437 - val_loss: 241.6315\n",
      "Epoch 451/1000\n",
      "700/700 [==============================] - 0s - loss: 20.9454 - val_loss: 251.5080\n",
      "Epoch 452/1000\n",
      "700/700 [==============================] - 0s - loss: 21.7012 - val_loss: 137.3350\n",
      "Epoch 453/1000\n",
      "700/700 [==============================] - 0s - loss: 14.1534 - val_loss: 148.7314\n",
      "Epoch 454/1000\n",
      "700/700 [==============================] - 0s - loss: 18.7615 - val_loss: 301.2100\n",
      "Epoch 455/1000\n",
      "700/700 [==============================] - 0s - loss: 24.0458 - val_loss: 243.8191\n",
      "Epoch 456/1000\n",
      "700/700 [==============================] - 0s - loss: 23.3135 - val_loss: 184.1010\n",
      "Epoch 457/1000\n",
      "700/700 [==============================] - 0s - loss: 14.9921 - val_loss: 152.4247\n",
      "Epoch 458/1000\n",
      "700/700 [==============================] - 0s - loss: 16.7292 - val_loss: 150.1205\n",
      "Epoch 459/1000\n",
      "700/700 [==============================] - 0s - loss: 22.6397 - val_loss: 149.3244\n",
      "Epoch 460/1000\n",
      "700/700 [==============================] - 0s - loss: 18.7059 - val_loss: 140.2611\n",
      "Epoch 461/1000\n",
      "700/700 [==============================] - 0s - loss: 21.1061 - val_loss: 140.9272\n",
      "Epoch 462/1000\n",
      "700/700 [==============================] - 0s - loss: 17.5739 - val_loss: 154.7860\n",
      "Epoch 463/1000\n",
      "700/700 [==============================] - 0s - loss: 22.2982 - val_loss: 145.1889\n",
      "Epoch 464/1000\n",
      "700/700 [==============================] - 0s - loss: 14.2397 - val_loss: 240.0065\n",
      "Epoch 465/1000\n",
      "700/700 [==============================] - 0s - loss: 24.9838 - val_loss: 158.0192\n",
      "Epoch 466/1000\n",
      "700/700 [==============================] - 0s - loss: 15.8551 - val_loss: 140.5299\n",
      "Epoch 467/1000\n",
      "700/700 [==============================] - 0s - loss: 20.2913 - val_loss: 244.7727\n",
      "Epoch 468/1000\n",
      "700/700 [==============================] - 0s - loss: 20.0612 - val_loss: 164.3064\n",
      "Epoch 469/1000\n",
      "700/700 [==============================] - 0s - loss: 14.4529 - val_loss: 222.6104\n",
      "Epoch 470/1000\n",
      "700/700 [==============================] - 0s - loss: 22.0150 - val_loss: 209.5629\n",
      "Epoch 471/1000\n",
      "700/700 [==============================] - 0s - loss: 16.7584 - val_loss: 190.4191\n",
      "Epoch 472/1000\n",
      "700/700 [==============================] - 0s - loss: 25.0469 - val_loss: 148.6184\n",
      "Epoch 473/1000\n",
      "700/700 [==============================] - 0s - loss: 14.3539 - val_loss: 182.0669\n",
      "Epoch 474/1000\n",
      "700/700 [==============================] - 0s - loss: 19.7608 - val_loss: 200.7073\n",
      "Epoch 475/1000\n",
      "700/700 [==============================] - 0s - loss: 16.4949 - val_loss: 295.6829\n",
      "Epoch 476/1000\n",
      "700/700 [==============================] - 0s - loss: 22.9906 - val_loss: 189.6979\n",
      "Epoch 477/1000\n",
      "700/700 [==============================] - 0s - loss: 14.3780 - val_loss: 246.9789\n",
      "Epoch 478/1000\n",
      "700/700 [==============================] - 0s - loss: 22.8538 - val_loss: 168.7386\n",
      "Epoch 479/1000\n",
      "700/700 [==============================] - 0s - loss: 15.6323 - val_loss: 171.2848\n",
      "Epoch 480/1000\n",
      "700/700 [==============================] - 0s - loss: 17.4874 - val_loss: 256.7269\n",
      "Epoch 481/1000\n",
      "700/700 [==============================] - 0s - loss: 18.5863 - val_loss: 192.7686\n",
      "Epoch 482/1000\n",
      "700/700 [==============================] - 0s - loss: 14.6927 - val_loss: 245.6872\n",
      "Epoch 483/1000\n",
      "700/700 [==============================] - 0s - loss: 21.9160 - val_loss: 177.2466\n",
      "Epoch 484/1000\n",
      "700/700 [==============================] - 0s - loss: 16.5050 - val_loss: 179.5551\n",
      "Epoch 485/1000\n",
      "700/700 [==============================] - 0s - loss: 20.0621 - val_loss: 144.0127\n",
      "Epoch 486/1000\n",
      "700/700 [==============================] - 0s - loss: 20.2965 - val_loss: 140.9129\n",
      "Epoch 487/1000\n",
      "700/700 [==============================] - 0s - loss: 15.7970 - val_loss: 143.7883\n",
      "Epoch 488/1000\n",
      "700/700 [==============================] - 0s - loss: 22.5874 - val_loss: 141.2988\n",
      "Epoch 489/1000\n",
      "700/700 [==============================] - 0s - loss: 14.2488 - val_loss: 140.3286\n",
      "Epoch 490/1000\n",
      "700/700 [==============================] - 0s - loss: 19.2834 - val_loss: 162.5157\n",
      "Epoch 491/1000\n",
      "700/700 [==============================] - 0s - loss: 15.6228 - val_loss: 158.2915\n",
      "Epoch 492/1000\n",
      "700/700 [==============================] - 0s - loss: 14.7143 - val_loss: 148.1130\n",
      "Epoch 493/1000\n",
      "700/700 [==============================] - 0s - loss: 23.8641 - val_loss: 199.7201\n",
      "Epoch 494/1000\n",
      "700/700 [==============================] - 0s - loss: 15.2728 - val_loss: 147.9606\n",
      "Epoch 495/1000\n",
      "700/700 [==============================] - 0s - loss: 18.8254 - val_loss: 150.6955\n",
      "Epoch 496/1000\n",
      "700/700 [==============================] - 0s - loss: 18.3018 - val_loss: 145.1793\n",
      "Epoch 497/1000\n",
      "700/700 [==============================] - 0s - loss: 18.1977 - val_loss: 143.0745\n",
      "Epoch 498/1000\n",
      "700/700 [==============================] - 0s - loss: 15.7336 - val_loss: 143.8538\n",
      "Epoch 499/1000\n",
      "700/700 [==============================] - 0s - loss: 21.3301 - val_loss: 146.1576\n",
      "Epoch 500/1000\n",
      "700/700 [==============================] - 0s - loss: 15.0628 - val_loss: 140.2041\n",
      "Epoch 501/1000\n",
      "700/700 [==============================] - 0s - loss: 17.2761 - val_loss: 139.5930\n",
      "Epoch 502/1000\n",
      "700/700 [==============================] - 0s - loss: 17.9450 - val_loss: 139.4037\n",
      "Epoch 503/1000\n",
      "700/700 [==============================] - 0s - loss: 23.8883 - val_loss: 139.2883\n",
      "Epoch 504/1000\n",
      "700/700 [==============================] - 0s - loss: 16.9652 - val_loss: 176.1124\n",
      "Epoch 505/1000\n",
      "700/700 [==============================] - 0s - loss: 14.5430 - val_loss: 157.7219\n",
      "Epoch 506/1000\n",
      "700/700 [==============================] - 0s - loss: 19.5855 - val_loss: 138.9471\n",
      "Epoch 507/1000\n",
      "700/700 [==============================] - 0s - loss: 16.0751 - val_loss: 158.9065\n",
      "Epoch 508/1000\n",
      "700/700 [==============================] - 0s - loss: 15.0872 - val_loss: 139.8617\n",
      "Epoch 509/1000\n",
      "700/700 [==============================] - 0s - loss: 19.2746 - val_loss: 145.4005\n",
      "Epoch 510/1000\n",
      "700/700 [==============================] - 0s - loss: 20.6016 - val_loss: 133.9249\n",
      "Epoch 511/1000\n",
      "700/700 [==============================] - 0s - loss: 13.1692 - val_loss: 159.8381\n",
      "Epoch 512/1000\n",
      "700/700 [==============================] - 0s - loss: 16.2629 - val_loss: 141.4401\n",
      "Epoch 513/1000\n",
      "700/700 [==============================] - 0s - loss: 19.0758 - val_loss: 140.4683\n",
      "Epoch 514/1000\n",
      "700/700 [==============================] - 0s - loss: 17.5434 - val_loss: 148.2586\n",
      "Epoch 515/1000\n",
      "700/700 [==============================] - 0s - loss: 14.1129 - val_loss: 140.8655\n",
      "Epoch 516/1000\n",
      "700/700 [==============================] - 0s - loss: 17.1706 - val_loss: 146.2167\n",
      "Epoch 517/1000\n",
      "700/700 [==============================] - 0s - loss: 19.7697 - val_loss: 139.4807\n",
      "Epoch 518/1000\n",
      "700/700 [==============================] - 0s - loss: 15.0371 - val_loss: 143.8480\n",
      "Epoch 519/1000\n",
      "700/700 [==============================] - 0s - loss: 17.5804 - val_loss: 145.5637\n",
      "Epoch 520/1000\n",
      "700/700 [==============================] - 0s - loss: 20.8336 - val_loss: 141.2106\n",
      "Epoch 521/1000\n",
      "700/700 [==============================] - 0s - loss: 18.7981 - val_loss: 144.5997\n",
      "Epoch 522/1000\n",
      "700/700 [==============================] - 0s - loss: 14.3049 - val_loss: 149.6504\n",
      "Epoch 523/1000\n",
      "700/700 [==============================] - 0s - loss: 20.9118 - val_loss: 144.2952\n",
      "Epoch 524/1000\n",
      "700/700 [==============================] - 0s - loss: 15.0142 - val_loss: 142.8953\n",
      "Epoch 525/1000\n",
      "700/700 [==============================] - 0s - loss: 17.5740 - val_loss: 142.3729\n",
      "Epoch 526/1000\n",
      "700/700 [==============================] - 0s - loss: 14.9194 - val_loss: 261.4444\n",
      "Epoch 527/1000\n",
      "700/700 [==============================] - 0s - loss: 17.2905 - val_loss: 201.9320\n",
      "Epoch 528/1000\n",
      "700/700 [==============================] - 0s - loss: 14.9597 - val_loss: 213.7494\n",
      "Epoch 529/1000\n",
      "700/700 [==============================] - 0s - loss: 18.9435 - val_loss: 222.5078\n",
      "Epoch 530/1000\n",
      "700/700 [==============================] - 0s - loss: 18.0913 - val_loss: 186.6448\n",
      "Epoch 531/1000\n",
      "700/700 [==============================] - 0s - loss: 17.4062 - val_loss: 203.8025\n",
      "Epoch 532/1000\n",
      "700/700 [==============================] - 0s - loss: 13.3140 - val_loss: 171.8395\n",
      "Epoch 533/1000\n",
      "700/700 [==============================] - 0s - loss: 17.5704 - val_loss: 215.9297\n",
      "Epoch 534/1000\n",
      "700/700 [==============================] - 0s - loss: 15.1868 - val_loss: 184.2189\n",
      "Epoch 535/1000\n",
      "700/700 [==============================] - 0s - loss: 21.0749 - val_loss: 174.3443\n",
      "Epoch 536/1000\n",
      "700/700 [==============================] - 0s - loss: 14.3872 - val_loss: 230.0898\n",
      "Epoch 537/1000\n",
      "700/700 [==============================] - 0s - loss: 15.4440 - val_loss: 289.3079\n",
      "Epoch 538/1000\n",
      "700/700 [==============================] - 0s - loss: 18.3299 - val_loss: 202.7714\n",
      "Epoch 539/1000\n",
      "700/700 [==============================] - 0s - loss: 19.0810 - val_loss: 175.0693\n",
      "Epoch 540/1000\n",
      "700/700 [==============================] - 0s - loss: 15.1251 - val_loss: 189.8277\n",
      "Epoch 541/1000\n",
      "700/700 [==============================] - 0s - loss: 16.0922 - val_loss: 268.6080\n",
      "Epoch 542/1000\n",
      "700/700 [==============================] - 0s - loss: 16.5080 - val_loss: 204.3904\n",
      "Epoch 543/1000\n",
      "700/700 [==============================] - 0s - loss: 17.3397 - val_loss: 189.2306\n",
      "Epoch 544/1000\n",
      "700/700 [==============================] - 0s - loss: 13.8150 - val_loss: 135.6106\n",
      "Epoch 545/1000\n",
      "700/700 [==============================] - 0s - loss: 16.2918 - val_loss: 152.6404\n",
      "Epoch 546/1000\n",
      "700/700 [==============================] - 0s - loss: 17.4887 - val_loss: 188.9045\n",
      "Epoch 547/1000\n",
      "700/700 [==============================] - 0s - loss: 13.7043 - val_loss: 246.3056\n",
      "Epoch 548/1000\n",
      "700/700 [==============================] - 0s - loss: 17.8409 - val_loss: 169.1961\n",
      "Epoch 549/1000\n",
      "700/700 [==============================] - 0s - loss: 13.0347 - val_loss: 175.1859\n",
      "Epoch 550/1000\n",
      "700/700 [==============================] - 0s - loss: 20.4002 - val_loss: 206.4788\n",
      "Epoch 551/1000\n",
      "700/700 [==============================] - 0s - loss: 16.7155 - val_loss: 160.6993\n",
      "Epoch 552/1000\n",
      "700/700 [==============================] - 0s - loss: 12.7897 - val_loss: 145.6754\n",
      "Epoch 553/1000\n",
      "700/700 [==============================] - 0s - loss: 14.0318 - val_loss: 144.4283\n",
      "Epoch 554/1000\n",
      "700/700 [==============================] - 0s - loss: 14.7403 - val_loss: 178.7773\n",
      "Epoch 555/1000\n",
      "700/700 [==============================] - 0s - loss: 14.6904 - val_loss: 147.1970\n",
      "Epoch 556/1000\n",
      "700/700 [==============================] - 0s - loss: 22.6443 - val_loss: 138.3230\n",
      "Epoch 557/1000\n",
      "700/700 [==============================] - 0s - loss: 9.0028 - val_loss: 183.7091\n",
      "Epoch 558/1000\n",
      "700/700 [==============================] - 0s - loss: 15.1801 - val_loss: 191.3569\n",
      "Epoch 559/1000\n",
      "700/700 [==============================] - 0s - loss: 20.1845 - val_loss: 181.0663\n",
      "Epoch 560/1000\n",
      "700/700 [==============================] - 0s - loss: 17.4860 - val_loss: 179.6423\n",
      "Epoch 561/1000\n",
      "700/700 [==============================] - 0s - loss: 12.6398 - val_loss: 179.8623\n",
      "Epoch 562/1000\n",
      "700/700 [==============================] - 0s - loss: 17.8014 - val_loss: 208.2741\n",
      "Epoch 563/1000\n",
      "700/700 [==============================] - 0s - loss: 10.8522 - val_loss: 291.8436\n",
      "Epoch 564/1000\n",
      "700/700 [==============================] - 0s - loss: 20.4672 - val_loss: 213.4292\n",
      "Epoch 565/1000\n",
      "700/700 [==============================] - 0s - loss: 13.4746 - val_loss: 162.3765\n",
      "Epoch 566/1000\n",
      "700/700 [==============================] - 0s - loss: 12.9615 - val_loss: 149.2533\n",
      "Epoch 567/1000\n",
      "700/700 [==============================] - 0s - loss: 15.3753 - val_loss: 157.2214\n",
      "Epoch 568/1000\n",
      "700/700 [==============================] - 0s - loss: 17.6365 - val_loss: 136.0695\n",
      "Epoch 569/1000\n",
      "700/700 [==============================] - 0s - loss: 11.7711 - val_loss: 174.8978\n",
      "Epoch 570/1000\n",
      "700/700 [==============================] - 0s - loss: 19.6684 - val_loss: 244.3886\n",
      "Epoch 571/1000\n",
      "700/700 [==============================] - 0s - loss: 12.1508 - val_loss: 209.9389\n",
      "Epoch 572/1000\n",
      "700/700 [==============================] - 0s - loss: 16.2502 - val_loss: 161.5319\n",
      "Epoch 573/1000\n",
      "700/700 [==============================] - 0s - loss: 14.0659 - val_loss: 192.7385\n",
      "Epoch 574/1000\n",
      "700/700 [==============================] - 0s - loss: 16.7276 - val_loss: 204.1733\n",
      "Epoch 575/1000\n",
      "700/700 [==============================] - 0s - loss: 15.2275 - val_loss: 139.4136\n",
      "Epoch 576/1000\n",
      "700/700 [==============================] - 0s - loss: 14.7845 - val_loss: 144.4117\n",
      "Epoch 577/1000\n",
      "700/700 [==============================] - 0s - loss: 17.0852 - val_loss: 139.9609\n",
      "Epoch 578/1000\n",
      "700/700 [==============================] - 0s - loss: 13.1589 - val_loss: 190.1191\n",
      "Epoch 579/1000\n",
      "700/700 [==============================] - 0s - loss: 16.8867 - val_loss: 138.1866\n",
      "Epoch 580/1000\n",
      "700/700 [==============================] - 0s - loss: 16.2754 - val_loss: 147.5229\n",
      "Epoch 581/1000\n",
      "700/700 [==============================] - 0s - loss: 16.3751 - val_loss: 144.0528\n",
      "Epoch 582/1000\n",
      "700/700 [==============================] - 0s - loss: 15.1473 - val_loss: 145.4900\n",
      "Epoch 583/1000\n",
      "700/700 [==============================] - 0s - loss: 15.9909 - val_loss: 146.7650\n",
      "Epoch 584/1000\n",
      "700/700 [==============================] - 0s - loss: 16.3476 - val_loss: 152.3935\n",
      "Epoch 585/1000\n",
      "700/700 [==============================] - 0s - loss: 13.8039 - val_loss: 144.3619\n",
      "Epoch 586/1000\n",
      "700/700 [==============================] - 0s - loss: 14.7927 - val_loss: 158.4566\n",
      "Epoch 587/1000\n",
      "700/700 [==============================] - 0s - loss: 11.1654 - val_loss: 158.9758\n",
      "Epoch 588/1000\n",
      "700/700 [==============================] - 0s - loss: 19.0016 - val_loss: 136.2391\n",
      "Epoch 589/1000\n",
      "700/700 [==============================] - 0s - loss: 15.4137 - val_loss: 146.0254\n",
      "Epoch 590/1000\n",
      "700/700 [==============================] - 0s - loss: 11.5871 - val_loss: 199.3255\n",
      "Epoch 591/1000\n",
      "700/700 [==============================] - 0s - loss: 18.9085 - val_loss: 138.9167\n",
      "Epoch 592/1000\n",
      "700/700 [==============================] - 0s - loss: 15.5072 - val_loss: 139.4244\n",
      "Epoch 593/1000\n",
      "700/700 [==============================] - 0s - loss: 14.0575 - val_loss: 139.2355\n",
      "Epoch 594/1000\n",
      "700/700 [==============================] - 0s - loss: 12.1903 - val_loss: 139.3367\n",
      "Epoch 595/1000\n",
      "700/700 [==============================] - 0s - loss: 15.1674 - val_loss: 137.4376\n",
      "Epoch 596/1000\n",
      "700/700 [==============================] - 0s - loss: 16.7494 - val_loss: 221.0761\n",
      "Epoch 597/1000\n",
      "700/700 [==============================] - 0s - loss: 14.3704 - val_loss: 298.4016\n",
      "Epoch 598/1000\n",
      "700/700 [==============================] - 0s - loss: 16.6342 - val_loss: 142.1811\n",
      "Epoch 599/1000\n",
      "700/700 [==============================] - 0s - loss: 10.0949 - val_loss: 312.2724\n",
      "Epoch 600/1000\n",
      "700/700 [==============================] - 0s - loss: 21.1932 - val_loss: 151.8357\n",
      "Epoch 601/1000\n",
      "700/700 [==============================] - 0s - loss: 11.3874 - val_loss: 177.4698\n",
      "Epoch 602/1000\n",
      "700/700 [==============================] - 0s - loss: 14.5914 - val_loss: 181.8695\n",
      "Epoch 603/1000\n",
      "700/700 [==============================] - 0s - loss: 16.3202 - val_loss: 340.7649\n",
      "Epoch 604/1000\n",
      "700/700 [==============================] - 0s - loss: 15.4932 - val_loss: 260.5743\n",
      "Epoch 605/1000\n",
      "700/700 [==============================] - 0s - loss: 13.9348 - val_loss: 231.4682\n",
      "Epoch 606/1000\n",
      "700/700 [==============================] - 0s - loss: 14.2721 - val_loss: 232.1034\n",
      "Epoch 607/1000\n",
      "700/700 [==============================] - 0s - loss: 13.6176 - val_loss: 152.4296\n",
      "Epoch 608/1000\n",
      "700/700 [==============================] - 0s - loss: 11.2709 - val_loss: 221.8732\n",
      "Epoch 609/1000\n",
      "700/700 [==============================] - 0s - loss: 14.9265 - val_loss: 182.4693\n",
      "Epoch 610/1000\n",
      "700/700 [==============================] - 0s - loss: 16.3845 - val_loss: 204.4717\n",
      "Epoch 611/1000\n",
      "700/700 [==============================] - 0s - loss: 16.3399 - val_loss: 274.4167\n",
      "Epoch 612/1000\n",
      "700/700 [==============================] - 0s - loss: 12.5972 - val_loss: 140.6889\n",
      "Epoch 613/1000\n",
      "700/700 [==============================] - 0s - loss: 13.7977 - val_loss: 144.0928\n",
      "Epoch 614/1000\n",
      "700/700 [==============================] - 0s - loss: 16.0334 - val_loss: 147.2356\n",
      "Epoch 615/1000\n",
      "700/700 [==============================] - 0s - loss: 13.9828 - val_loss: 145.4386\n",
      "Epoch 616/1000\n",
      "700/700 [==============================] - 0s - loss: 13.7353 - val_loss: 146.0783\n",
      "Epoch 617/1000\n",
      "700/700 [==============================] - 0s - loss: 13.9525 - val_loss: 156.1140\n",
      "Epoch 618/1000\n",
      "700/700 [==============================] - 0s - loss: 15.9209 - val_loss: 147.5181\n",
      "Epoch 619/1000\n",
      "700/700 [==============================] - 0s - loss: 16.7066 - val_loss: 142.3411\n",
      "Epoch 620/1000\n",
      "700/700 [==============================] - 0s - loss: 14.3202 - val_loss: 162.6697\n",
      "Epoch 621/1000\n",
      "700/700 [==============================] - 0s - loss: 9.4599 - val_loss: 151.2505\n",
      "Epoch 622/1000\n",
      "700/700 [==============================] - 0s - loss: 17.0605 - val_loss: 142.3797\n",
      "Epoch 623/1000\n",
      "700/700 [==============================] - 0s - loss: 11.7620 - val_loss: 151.0501\n",
      "Epoch 624/1000\n",
      "700/700 [==============================] - 0s - loss: 16.8104 - val_loss: 142.8562\n",
      "Epoch 625/1000\n",
      "700/700 [==============================] - 0s - loss: 15.6203 - val_loss: 165.2408\n",
      "Epoch 626/1000\n",
      "700/700 [==============================] - 0s - loss: 12.5826 - val_loss: 143.7312\n",
      "Epoch 627/1000\n",
      "700/700 [==============================] - 0s - loss: 9.9419 - val_loss: 319.7290\n",
      "Epoch 628/1000\n",
      "700/700 [==============================] - 0s - loss: 21.5095 - val_loss: 180.4220\n",
      "Epoch 629/1000\n",
      "700/700 [==============================] - 0s - loss: 10.7979 - val_loss: 155.5709\n",
      "Epoch 630/1000\n",
      "700/700 [==============================] - 0s - loss: 13.3946 - val_loss: 149.0233\n",
      "Epoch 631/1000\n",
      "700/700 [==============================] - 0s - loss: 14.9119 - val_loss: 160.0191\n",
      "Epoch 632/1000\n",
      "700/700 [==============================] - 0s - loss: 12.0109 - val_loss: 146.7291\n",
      "Epoch 633/1000\n",
      "700/700 [==============================] - 0s - loss: 15.9855 - val_loss: 154.3992\n",
      "Epoch 634/1000\n",
      "700/700 [==============================] - 0s - loss: 13.5048 - val_loss: 185.8512\n",
      "Epoch 635/1000\n",
      "700/700 [==============================] - 0s - loss: 12.7697 - val_loss: 237.8997\n",
      "Epoch 636/1000\n",
      "700/700 [==============================] - 0s - loss: 16.3797 - val_loss: 185.7470\n",
      "Epoch 637/1000\n",
      "700/700 [==============================] - 0s - loss: 10.1581 - val_loss: 142.9710\n",
      "Epoch 638/1000\n",
      "700/700 [==============================] - 0s - loss: 18.8592 - val_loss: 167.3256\n",
      "Epoch 639/1000\n",
      "700/700 [==============================] - 0s - loss: 12.0412 - val_loss: 187.6210\n",
      "Epoch 640/1000\n",
      "700/700 [==============================] - 0s - loss: 13.3777 - val_loss: 171.0282\n",
      "Epoch 641/1000\n",
      "700/700 [==============================] - 0s - loss: 12.3768 - val_loss: 321.0316\n",
      "Epoch 642/1000\n",
      "700/700 [==============================] - 0s - loss: 13.2272 - val_loss: 181.0132\n",
      "Epoch 643/1000\n",
      "700/700 [==============================] - 0s - loss: 10.9050 - val_loss: 160.4772\n",
      "Epoch 644/1000\n",
      "700/700 [==============================] - 0s - loss: 18.1496 - val_loss: 204.7566\n",
      "Epoch 645/1000\n",
      "700/700 [==============================] - 0s - loss: 11.4219 - val_loss: 178.7527\n",
      "Epoch 646/1000\n",
      "700/700 [==============================] - 0s - loss: 14.8606 - val_loss: 254.1244\n",
      "Epoch 647/1000\n",
      "700/700 [==============================] - 0s - loss: 13.8913 - val_loss: 153.6223\n",
      "Epoch 648/1000\n",
      "700/700 [==============================] - 0s - loss: 9.4121 - val_loss: 146.6972\n",
      "Epoch 649/1000\n",
      "700/700 [==============================] - 0s - loss: 16.1224 - val_loss: 146.0058\n",
      "Epoch 650/1000\n",
      "700/700 [==============================] - 0s - loss: 15.3098 - val_loss: 144.0291\n",
      "Epoch 651/1000\n",
      "700/700 [==============================] - 0s - loss: 11.4319 - val_loss: 141.8170\n",
      "Epoch 652/1000\n",
      "700/700 [==============================] - 0s - loss: 16.9838 - val_loss: 158.0920\n",
      "Epoch 653/1000\n",
      "700/700 [==============================] - 0s - loss: 13.8470 - val_loss: 139.6453\n",
      "Epoch 654/1000\n",
      "700/700 [==============================] - 0s - loss: 16.2530 - val_loss: 144.6466\n",
      "Epoch 655/1000\n",
      "700/700 [==============================] - 0s - loss: 11.0798 - val_loss: 139.1024\n",
      "Epoch 656/1000\n",
      "700/700 [==============================] - 0s - loss: 13.8923 - val_loss: 140.4637\n",
      "Epoch 657/1000\n",
      "700/700 [==============================] - 0s - loss: 13.4357 - val_loss: 147.5742\n",
      "Epoch 658/1000\n",
      "700/700 [==============================] - 0s - loss: 11.2703 - val_loss: 155.2267\n",
      "Epoch 659/1000\n",
      "700/700 [==============================] - 0s - loss: 17.3491 - val_loss: 188.7860\n",
      "Epoch 660/1000\n",
      "700/700 [==============================] - 0s - loss: 13.3404 - val_loss: 161.8520\n",
      "Epoch 661/1000\n",
      "700/700 [==============================] - 0s - loss: 10.7656 - val_loss: 160.0728\n",
      "Epoch 662/1000\n",
      "700/700 [==============================] - 0s - loss: 12.7913 - val_loss: 206.1512\n",
      "Epoch 663/1000\n",
      "700/700 [==============================] - 0s - loss: 8.4443 - val_loss: 302.0199\n",
      "Epoch 664/1000\n",
      "700/700 [==============================] - 0s - loss: 20.0034 - val_loss: 175.0828\n",
      "Epoch 665/1000\n",
      "700/700 [==============================] - 0s - loss: 9.3520 - val_loss: 172.5156\n",
      "Epoch 666/1000\n",
      "700/700 [==============================] - 0s - loss: 13.0209 - val_loss: 283.2729\n",
      "Epoch 667/1000\n",
      "700/700 [==============================] - 0s - loss: 13.7887 - val_loss: 208.0283\n",
      "Epoch 668/1000\n",
      "700/700 [==============================] - 0s - loss: 16.2293 - val_loss: 178.0602\n",
      "Epoch 669/1000\n",
      "700/700 [==============================] - 0s - loss: 11.5640 - val_loss: 228.6044\n",
      "Epoch 670/1000\n",
      "700/700 [==============================] - 0s - loss: 12.5677 - val_loss: 197.9083\n",
      "Epoch 671/1000\n",
      "700/700 [==============================] - 0s - loss: 18.2847 - val_loss: 180.7437\n",
      "Epoch 672/1000\n",
      "700/700 [==============================] - 0s - loss: 7.7891 - val_loss: 152.2832\n",
      "Epoch 673/1000\n",
      "700/700 [==============================] - 0s - loss: 14.1599 - val_loss: 145.1351\n",
      "Epoch 674/1000\n",
      "700/700 [==============================] - 0s - loss: 13.3441 - val_loss: 144.3588\n",
      "Epoch 675/1000\n",
      "700/700 [==============================] - 0s - loss: 15.3025 - val_loss: 144.3371\n",
      "Epoch 676/1000\n",
      "700/700 [==============================] - 0s - loss: 12.4327 - val_loss: 148.9871\n",
      "Epoch 677/1000\n",
      "700/700 [==============================] - 0s - loss: 9.2464 - val_loss: 143.6803\n",
      "Epoch 678/1000\n",
      "700/700 [==============================] - 0s - loss: 15.5005 - val_loss: 148.3217\n",
      "Epoch 679/1000\n",
      "700/700 [==============================] - 0s - loss: 15.0403 - val_loss: 152.7414\n",
      "Epoch 680/1000\n",
      "700/700 [==============================] - 0s - loss: 11.7411 - val_loss: 165.7443\n",
      "Epoch 681/1000\n",
      "700/700 [==============================] - 0s - loss: 13.6140 - val_loss: 221.7965\n",
      "Epoch 682/1000\n",
      "700/700 [==============================] - 0s - loss: 11.3775 - val_loss: 167.4468\n",
      "Epoch 683/1000\n",
      "700/700 [==============================] - 0s - loss: 10.1387 - val_loss: 166.6389\n",
      "Epoch 684/1000\n",
      "700/700 [==============================] - 0s - loss: 15.8368 - val_loss: 194.4864\n",
      "Epoch 685/1000\n",
      "700/700 [==============================] - 0s - loss: 14.1389 - val_loss: 180.3084\n",
      "Epoch 686/1000\n",
      "700/700 [==============================] - 0s - loss: 10.1716 - val_loss: 190.2990\n",
      "Epoch 687/1000\n",
      "700/700 [==============================] - 0s - loss: 13.9407 - val_loss: 187.0035\n",
      "Epoch 688/1000\n",
      "700/700 [==============================] - 0s - loss: 12.6664 - val_loss: 235.4735\n",
      "Epoch 689/1000\n",
      "700/700 [==============================] - 0s - loss: 14.9065 - val_loss: 170.4051\n",
      "Epoch 690/1000\n",
      "700/700 [==============================] - 0s - loss: 13.7707 - val_loss: 188.0541\n",
      "Epoch 691/1000\n",
      "700/700 [==============================] - 0s - loss: 12.5130 - val_loss: 201.7893\n",
      "Epoch 692/1000\n",
      "700/700 [==============================] - 0s - loss: 12.8477 - val_loss: 145.2745\n",
      "Epoch 693/1000\n",
      "700/700 [==============================] - 0s - loss: 12.1217 - val_loss: 318.2540\n",
      "Epoch 694/1000\n",
      "700/700 [==============================] - 0s - loss: 16.4464 - val_loss: 186.5686\n",
      "Epoch 695/1000\n",
      "700/700 [==============================] - 0s - loss: 10.6955 - val_loss: 199.4120\n",
      "Epoch 696/1000\n",
      "700/700 [==============================] - 0s - loss: 12.4064 - val_loss: 272.2745\n",
      "Epoch 697/1000\n",
      "700/700 [==============================] - 0s - loss: 14.5181 - val_loss: 198.9870\n",
      "Epoch 698/1000\n",
      "700/700 [==============================] - 0s - loss: 14.4949 - val_loss: 171.4088\n",
      "Epoch 699/1000\n",
      "700/700 [==============================] - 0s - loss: 9.4735 - val_loss: 184.3489\n",
      "Epoch 700/1000\n",
      "700/700 [==============================] - 0s - loss: 12.8962 - val_loss: 259.1290\n",
      "Epoch 701/1000\n",
      "700/700 [==============================] - 0s - loss: 15.6449 - val_loss: 181.5857\n",
      "Epoch 702/1000\n",
      "700/700 [==============================] - 0s - loss: 12.9236 - val_loss: 261.0109\n",
      "Epoch 703/1000\n",
      "700/700 [==============================] - 0s - loss: 16.8055 - val_loss: 163.7474\n",
      "Epoch 704/1000\n",
      "700/700 [==============================] - 0s - loss: 9.2944 - val_loss: 210.5004\n",
      "Epoch 705/1000\n",
      "700/700 [==============================] - 0s - loss: 13.7766 - val_loss: 227.3438\n",
      "Epoch 706/1000\n",
      "700/700 [==============================] - 0s - loss: 12.1170 - val_loss: 199.7992\n",
      "Epoch 707/1000\n",
      "700/700 [==============================] - 0s - loss: 13.4022 - val_loss: 226.9338\n",
      "Epoch 708/1000\n",
      "700/700 [==============================] - 0s - loss: 11.8854 - val_loss: 236.1384\n",
      "Epoch 709/1000\n",
      "700/700 [==============================] - 0s - loss: 15.0573 - val_loss: 211.8577\n",
      "Epoch 710/1000\n",
      "700/700 [==============================] - 0s - loss: 14.0512 - val_loss: 264.6616\n",
      "Epoch 711/1000\n",
      "700/700 [==============================] - 0s - loss: 9.5882 - val_loss: 192.1666\n",
      "Epoch 712/1000\n",
      "700/700 [==============================] - 0s - loss: 12.5416 - val_loss: 270.4994\n",
      "Epoch 713/1000\n",
      "700/700 [==============================] - 0s - loss: 14.8685 - val_loss: 250.5719\n",
      "Epoch 714/1000\n",
      "700/700 [==============================] - 0s - loss: 14.4384 - val_loss: 195.0193\n",
      "Epoch 715/1000\n",
      "700/700 [==============================] - 0s - loss: 11.8858 - val_loss: 179.5316\n",
      "Epoch 716/1000\n",
      "700/700 [==============================] - 0s - loss: 11.6369 - val_loss: 234.9665\n",
      "Epoch 717/1000\n",
      "700/700 [==============================] - 0s - loss: 13.0668 - val_loss: 192.4769\n",
      "Epoch 718/1000\n",
      "700/700 [==============================] - 0s - loss: 12.2885 - val_loss: 200.5837\n",
      "Epoch 719/1000\n",
      "700/700 [==============================] - 0s - loss: 12.4794 - val_loss: 230.6745\n",
      "Epoch 720/1000\n",
      "700/700 [==============================] - 0s - loss: 15.4956 - val_loss: 179.2203\n",
      "Epoch 721/1000\n",
      "700/700 [==============================] - 0s - loss: 10.5965 - val_loss: 273.1244\n",
      "Epoch 722/1000\n",
      "700/700 [==============================] - 0s - loss: 13.6119 - val_loss: 218.6039\n",
      "Epoch 723/1000\n",
      "700/700 [==============================] - 0s - loss: 14.0243 - val_loss: 162.9688\n",
      "Epoch 724/1000\n",
      "700/700 [==============================] - 0s - loss: 10.9650 - val_loss: 212.5412\n",
      "Epoch 725/1000\n",
      "700/700 [==============================] - 0s - loss: 15.7095 - val_loss: 145.1042\n",
      "Epoch 726/1000\n",
      "700/700 [==============================] - 0s - loss: 11.6594 - val_loss: 145.6745\n",
      "Epoch 727/1000\n",
      "700/700 [==============================] - 0s - loss: 11.4017 - val_loss: 159.7999\n",
      "Epoch 728/1000\n",
      "700/700 [==============================] - 0s - loss: 13.4604 - val_loss: 141.9652\n",
      "Epoch 729/1000\n",
      "700/700 [==============================] - 0s - loss: 14.0444 - val_loss: 156.6393\n",
      "Epoch 730/1000\n",
      "700/700 [==============================] - 0s - loss: 9.8623 - val_loss: 146.7636\n",
      "Epoch 731/1000\n",
      "700/700 [==============================] - 0s - loss: 14.6974 - val_loss: 146.0688\n",
      "Epoch 732/1000\n",
      "700/700 [==============================] - 0s - loss: 12.1395 - val_loss: 141.2078\n",
      "Epoch 733/1000\n",
      "700/700 [==============================] - 0s - loss: 13.5641 - val_loss: 144.1906\n",
      "Epoch 734/1000\n",
      "700/700 [==============================] - 0s - loss: 12.2108 - val_loss: 137.8830\n",
      "Epoch 735/1000\n",
      "700/700 [==============================] - 0s - loss: 14.9844 - val_loss: 294.0845\n",
      "Epoch 736/1000\n",
      "700/700 [==============================] - 0s - loss: 11.2707 - val_loss: 220.9374\n",
      "Epoch 737/1000\n",
      "700/700 [==============================] - 0s - loss: 12.2378 - val_loss: 183.0515\n",
      "Epoch 738/1000\n",
      "700/700 [==============================] - 0s - loss: 13.6591 - val_loss: 184.7230\n",
      "Epoch 739/1000\n",
      "700/700 [==============================] - 0s - loss: 13.5451 - val_loss: 190.1662\n",
      "Epoch 740/1000\n",
      "700/700 [==============================] - 0s - loss: 12.2906 - val_loss: 193.1477\n",
      "Epoch 741/1000\n",
      "700/700 [==============================] - 0s - loss: 11.0387 - val_loss: 185.1016\n",
      "Epoch 742/1000\n",
      "700/700 [==============================] - 0s - loss: 12.2673 - val_loss: 193.8979\n",
      "Epoch 743/1000\n",
      "700/700 [==============================] - 0s - loss: 7.4985 - val_loss: 202.8436\n",
      "Epoch 744/1000\n",
      "700/700 [==============================] - 0s - loss: 18.2155 - val_loss: 189.6808\n",
      "Epoch 745/1000\n",
      "700/700 [==============================] - 0s - loss: 10.3752 - val_loss: 148.9653\n",
      "Epoch 746/1000\n",
      "700/700 [==============================] - 0s - loss: 9.1720 - val_loss: 257.4763\n",
      "Epoch 747/1000\n",
      "700/700 [==============================] - 0s - loss: 15.1454 - val_loss: 233.0429\n",
      "Epoch 748/1000\n",
      "700/700 [==============================] - 0s - loss: 11.1854 - val_loss: 209.1681\n",
      "Epoch 749/1000\n",
      "700/700 [==============================] - 0s - loss: 14.6270 - val_loss: 212.6725\n",
      "Epoch 750/1000\n",
      "700/700 [==============================] - 0s - loss: 13.3119 - val_loss: 222.6458\n",
      "Epoch 751/1000\n",
      "700/700 [==============================] - 0s - loss: 11.6880 - val_loss: 174.9832\n",
      "Epoch 752/1000\n",
      "700/700 [==============================] - 0s - loss: 10.0631 - val_loss: 182.9917\n",
      "Epoch 753/1000\n",
      "700/700 [==============================] - 0s - loss: 13.2414 - val_loss: 348.7021\n",
      "Epoch 754/1000\n",
      "700/700 [==============================] - 0s - loss: 13.8983 - val_loss: 211.7524\n",
      "Epoch 755/1000\n",
      "700/700 [==============================] - 0s - loss: 11.9884 - val_loss: 193.3136\n",
      "Epoch 756/1000\n",
      "700/700 [==============================] - 0s - loss: 11.4327 - val_loss: 166.3483\n",
      "Epoch 757/1000\n",
      "700/700 [==============================] - 0s - loss: 13.1006 - val_loss: 202.7264\n",
      "Epoch 758/1000\n",
      "700/700 [==============================] - 0s - loss: 11.4883 - val_loss: 199.5137\n",
      "Epoch 759/1000\n",
      "700/700 [==============================] - 0s - loss: 13.4489 - val_loss: 256.0325\n",
      "Epoch 760/1000\n",
      "700/700 [==============================] - 0s - loss: 10.7274 - val_loss: 179.4632\n",
      "Epoch 761/1000\n",
      "700/700 [==============================] - 0s - loss: 14.2832 - val_loss: 223.5845\n",
      "Epoch 762/1000\n",
      "700/700 [==============================] - 0s - loss: 9.7282 - val_loss: 169.9266\n",
      "Epoch 763/1000\n",
      "700/700 [==============================] - 0s - loss: 11.6719 - val_loss: 196.4297\n",
      "Epoch 764/1000\n",
      "700/700 [==============================] - 0s - loss: 15.2132 - val_loss: 142.6910\n",
      "Epoch 765/1000\n",
      "700/700 [==============================] - 0s - loss: 11.2329 - val_loss: 196.8313\n",
      "Epoch 766/1000\n",
      "700/700 [==============================] - 0s - loss: 12.3279 - val_loss: 219.0385\n",
      "Epoch 767/1000\n",
      "700/700 [==============================] - 0s - loss: 13.0368 - val_loss: 152.7421\n",
      "Epoch 768/1000\n",
      "700/700 [==============================] - 0s - loss: 9.6118 - val_loss: 145.0093\n",
      "Epoch 769/1000\n",
      "700/700 [==============================] - 0s - loss: 15.8153 - val_loss: 187.6102\n",
      "Epoch 770/1000\n",
      "700/700 [==============================] - 0s - loss: 11.1365 - val_loss: 148.4503\n",
      "Epoch 771/1000\n",
      "700/700 [==============================] - 0s - loss: 12.3549 - val_loss: 156.6045\n",
      "Epoch 772/1000\n",
      "700/700 [==============================] - 0s - loss: 8.8334 - val_loss: 179.8074\n",
      "Epoch 773/1000\n",
      "700/700 [==============================] - 0s - loss: 11.1308 - val_loss: 216.6701\n",
      "Epoch 774/1000\n",
      "700/700 [==============================] - 0s - loss: 16.7236 - val_loss: 229.5241\n",
      "Epoch 775/1000\n",
      "700/700 [==============================] - 0s - loss: 14.1366 - val_loss: 153.3948\n",
      "Epoch 776/1000\n",
      "700/700 [==============================] - 0s - loss: 10.2884 - val_loss: 262.3427\n",
      "Epoch 777/1000\n",
      "700/700 [==============================] - 0s - loss: 10.4578 - val_loss: 144.5117\n",
      "Epoch 778/1000\n",
      "700/700 [==============================] - 0s - loss: 13.2636 - val_loss: 149.5896\n",
      "Epoch 779/1000\n",
      "700/700 [==============================] - 0s - loss: 9.8587 - val_loss: 186.0496\n",
      "Epoch 780/1000\n",
      "700/700 [==============================] - 0s - loss: 14.1560 - val_loss: 214.5745\n",
      "Epoch 781/1000\n",
      "700/700 [==============================] - 0s - loss: 9.3725 - val_loss: 153.2401\n",
      "Epoch 782/1000\n",
      "700/700 [==============================] - 0s - loss: 11.4261 - val_loss: 171.9922\n",
      "Epoch 783/1000\n",
      "700/700 [==============================] - 0s - loss: 14.9241 - val_loss: 160.8348\n",
      "Epoch 784/1000\n",
      "700/700 [==============================] - 0s - loss: 7.8350 - val_loss: 141.2196\n",
      "Epoch 785/1000\n",
      "700/700 [==============================] - 0s - loss: 14.3121 - val_loss: 147.6802\n",
      "Epoch 786/1000\n",
      "700/700 [==============================] - 0s - loss: 12.1897 - val_loss: 143.6169\n",
      "Epoch 787/1000\n",
      "700/700 [==============================] - 0s - loss: 15.0780 - val_loss: 153.7492\n",
      "Epoch 788/1000\n",
      "700/700 [==============================] - 0s - loss: 9.7034 - val_loss: 148.4555\n",
      "Epoch 789/1000\n",
      "700/700 [==============================] - 0s - loss: 10.7775 - val_loss: 144.2691\n",
      "Epoch 790/1000\n",
      "700/700 [==============================] - 0s - loss: 11.9277 - val_loss: 159.7654\n",
      "Epoch 791/1000\n",
      "700/700 [==============================] - 0s - loss: 12.1776 - val_loss: 149.0772\n",
      "Epoch 792/1000\n",
      "700/700 [==============================] - 0s - loss: 14.4059 - val_loss: 142.7792\n",
      "Epoch 793/1000\n",
      "700/700 [==============================] - 0s - loss: 10.6649 - val_loss: 159.5496\n",
      "Epoch 794/1000\n",
      "700/700 [==============================] - 0s - loss: 11.3136 - val_loss: 141.6552\n",
      "Epoch 795/1000\n",
      "700/700 [==============================] - 0s - loss: 13.1438 - val_loss: 145.4580\n",
      "Epoch 796/1000\n",
      "700/700 [==============================] - 0s - loss: 11.3166 - val_loss: 144.0552\n",
      "Epoch 797/1000\n",
      "700/700 [==============================] - 0s - loss: 14.0059 - val_loss: 169.4029\n",
      "Epoch 798/1000\n",
      "700/700 [==============================] - 0s - loss: 11.3008 - val_loss: 225.9158\n",
      "Epoch 799/1000\n",
      "700/700 [==============================] - 0s - loss: 12.6995 - val_loss: 192.6365\n",
      "Epoch 800/1000\n",
      "700/700 [==============================] - 0s - loss: 12.0305 - val_loss: 183.0706\n",
      "Epoch 801/1000\n",
      "700/700 [==============================] - 0s - loss: 14.2673 - val_loss: 227.8879\n",
      "Epoch 802/1000\n",
      "700/700 [==============================] - 0s - loss: 11.7133 - val_loss: 158.2351\n",
      "Epoch 803/1000\n",
      "700/700 [==============================] - 0s - loss: 11.5294 - val_loss: 140.5607\n",
      "Epoch 804/1000\n",
      "700/700 [==============================] - 0s - loss: 10.2209 - val_loss: 145.5901\n",
      "Epoch 805/1000\n",
      "700/700 [==============================] - 0s - loss: 16.0201 - val_loss: 147.8720\n",
      "Epoch 806/1000\n",
      "700/700 [==============================] - 0s - loss: 8.1627 - val_loss: 180.1517\n",
      "Epoch 807/1000\n",
      "700/700 [==============================] - 0s - loss: 10.1317 - val_loss: 215.6945\n",
      "Epoch 808/1000\n",
      "700/700 [==============================] - 0s - loss: 12.5311 - val_loss: 187.4374\n",
      "Epoch 809/1000\n",
      "700/700 [==============================] - 0s - loss: 13.5751 - val_loss: 226.7487\n",
      "Epoch 810/1000\n",
      "700/700 [==============================] - 0s - loss: 12.1323 - val_loss: 182.4336\n",
      "Epoch 811/1000\n",
      "700/700 [==============================] - 0s - loss: 13.1804 - val_loss: 190.3760\n",
      "Epoch 812/1000\n",
      "700/700 [==============================] - 0s - loss: 9.3003 - val_loss: 150.1998\n",
      "Epoch 813/1000\n",
      "700/700 [==============================] - 0s - loss: 17.1925 - val_loss: 151.8901\n",
      "Epoch 814/1000\n",
      "700/700 [==============================] - 0s - loss: 8.1325 - val_loss: 185.3500\n",
      "Epoch 815/1000\n",
      "700/700 [==============================] - 0s - loss: 8.1674 - val_loss: 167.4687\n",
      "Epoch 816/1000\n",
      "700/700 [==============================] - 0s - loss: 12.0220 - val_loss: 164.1070\n",
      "Epoch 817/1000\n",
      "700/700 [==============================] - 0s - loss: 15.0798 - val_loss: 176.1791\n",
      "Epoch 818/1000\n",
      "700/700 [==============================] - 0s - loss: 8.3196 - val_loss: 197.2179\n",
      "Epoch 819/1000\n",
      "700/700 [==============================] - 0s - loss: 11.9629 - val_loss: 145.3316\n",
      "Epoch 820/1000\n",
      "700/700 [==============================] - 0s - loss: 12.4270 - val_loss: 156.7397\n",
      "Epoch 821/1000\n",
      "700/700 [==============================] - 0s - loss: 10.2328 - val_loss: 139.9502\n",
      "Epoch 822/1000\n",
      "700/700 [==============================] - 0s - loss: 11.9350 - val_loss: 142.4422\n",
      "Epoch 823/1000\n",
      "700/700 [==============================] - 0s - loss: 11.7806 - val_loss: 143.1684\n",
      "Epoch 824/1000\n",
      "700/700 [==============================] - 0s - loss: 12.6015 - val_loss: 139.9715\n",
      "Epoch 825/1000\n",
      "700/700 [==============================] - 0s - loss: 11.3388 - val_loss: 151.2813\n",
      "Epoch 826/1000\n",
      "700/700 [==============================] - 0s - loss: 9.9377 - val_loss: 162.1424\n",
      "Epoch 827/1000\n",
      "700/700 [==============================] - 0s - loss: 13.7366 - val_loss: 183.0493\n",
      "Epoch 828/1000\n",
      "700/700 [==============================] - 0s - loss: 14.1870 - val_loss: 143.4471\n",
      "Epoch 829/1000\n",
      "700/700 [==============================] - 0s - loss: 10.4358 - val_loss: 146.5087\n",
      "Epoch 830/1000\n",
      "700/700 [==============================] - 0s - loss: 10.6044 - val_loss: 156.8649\n",
      "Epoch 831/1000\n",
      "700/700 [==============================] - 0s - loss: 13.6964 - val_loss: 141.0837\n",
      "Epoch 832/1000\n",
      "700/700 [==============================] - 0s - loss: 10.7262 - val_loss: 144.2091\n",
      "Epoch 833/1000\n",
      "700/700 [==============================] - 0s - loss: 10.4141 - val_loss: 154.1513\n",
      "Epoch 834/1000\n",
      "700/700 [==============================] - 0s - loss: 13.4834 - val_loss: 227.9247\n",
      "Epoch 835/1000\n",
      "700/700 [==============================] - 0s - loss: 10.1817 - val_loss: 197.2140\n",
      "Epoch 836/1000\n",
      "700/700 [==============================] - 0s - loss: 11.8209 - val_loss: 212.3959\n",
      "Epoch 837/1000\n",
      "700/700 [==============================] - 0s - loss: 12.4562 - val_loss: 218.7948\n",
      "Epoch 838/1000\n",
      "700/700 [==============================] - 0s - loss: 10.7203 - val_loss: 216.3363\n",
      "Epoch 839/1000\n",
      "700/700 [==============================] - 0s - loss: 11.5801 - val_loss: 186.9748\n",
      "Epoch 840/1000\n",
      "700/700 [==============================] - 0s - loss: 8.6977 - val_loss: 178.2261\n",
      "Epoch 841/1000\n",
      "700/700 [==============================] - 0s - loss: 13.0848 - val_loss: 252.9170\n",
      "Epoch 842/1000\n",
      "700/700 [==============================] - 0s - loss: 11.9248 - val_loss: 164.4745\n",
      "Epoch 843/1000\n",
      "700/700 [==============================] - 0s - loss: 8.5246 - val_loss: 182.6842\n",
      "Epoch 844/1000\n",
      "700/700 [==============================] - 0s - loss: 11.0566 - val_loss: 155.8569\n",
      "Epoch 845/1000\n",
      "700/700 [==============================] - 0s - loss: 12.0545 - val_loss: 147.8224\n",
      "Epoch 846/1000\n",
      "700/700 [==============================] - 0s - loss: 13.9680 - val_loss: 139.1386\n",
      "Epoch 847/1000\n",
      "700/700 [==============================] - 0s - loss: 11.2936 - val_loss: 160.0702\n",
      "Epoch 848/1000\n",
      "700/700 [==============================] - 0s - loss: 8.4916 - val_loss: 145.9845\n",
      "Epoch 849/1000\n",
      "700/700 [==============================] - 0s - loss: 15.3297 - val_loss: 149.7955\n",
      "Epoch 850/1000\n",
      "700/700 [==============================] - 0s - loss: 10.4616 - val_loss: 195.7025\n",
      "Epoch 851/1000\n",
      "700/700 [==============================] - 0s - loss: 8.9972 - val_loss: 203.7017\n",
      "Epoch 852/1000\n",
      "700/700 [==============================] - 0s - loss: 10.8103 - val_loss: 264.9705\n",
      "Epoch 853/1000\n",
      "700/700 [==============================] - 0s - loss: 12.0241 - val_loss: 190.2051\n",
      "Epoch 854/1000\n",
      "700/700 [==============================] - 0s - loss: 11.1744 - val_loss: 189.4668\n",
      "Epoch 855/1000\n",
      "700/700 [==============================] - 0s - loss: 9.4664 - val_loss: 173.7563\n",
      "Epoch 856/1000\n",
      "700/700 [==============================] - 0s - loss: 11.5684 - val_loss: 147.6533\n",
      "Epoch 857/1000\n",
      "700/700 [==============================] - 0s - loss: 12.3061 - val_loss: 145.7525\n",
      "Epoch 858/1000\n",
      "700/700 [==============================] - 0s - loss: 11.2649 - val_loss: 154.4417\n",
      "Epoch 859/1000\n",
      "700/700 [==============================] - 0s - loss: 8.6808 - val_loss: 156.1882\n",
      "Epoch 860/1000\n",
      "700/700 [==============================] - 0s - loss: 12.7524 - val_loss: 147.6106\n",
      "Epoch 861/1000\n",
      "700/700 [==============================] - 0s - loss: 10.9754 - val_loss: 144.1660\n",
      "Epoch 862/1000\n",
      "700/700 [==============================] - 0s - loss: 10.8259 - val_loss: 143.4825\n",
      "Epoch 863/1000\n",
      "700/700 [==============================] - 0s - loss: 12.4935 - val_loss: 150.8928\n",
      "Epoch 864/1000\n",
      "700/700 [==============================] - 0s - loss: 13.0674 - val_loss: 153.1131\n",
      "Epoch 865/1000\n",
      "700/700 [==============================] - 0s - loss: 10.3554 - val_loss: 158.7523\n",
      "Epoch 866/1000\n",
      "700/700 [==============================] - 0s - loss: 9.0506 - val_loss: 178.0667\n",
      "Epoch 867/1000\n",
      "700/700 [==============================] - 0s - loss: 14.8959 - val_loss: 143.9873\n",
      "Epoch 868/1000\n",
      "700/700 [==============================] - 0s - loss: 10.5549 - val_loss: 150.2131\n",
      "Epoch 869/1000\n",
      "700/700 [==============================] - 0s - loss: 11.4134 - val_loss: 147.6123\n",
      "Epoch 870/1000\n",
      "700/700 [==============================] - 0s - loss: 10.8068 - val_loss: 158.3467\n",
      "Epoch 871/1000\n",
      "700/700 [==============================] - 0s - loss: 11.0416 - val_loss: 145.5857\n",
      "Epoch 872/1000\n",
      "700/700 [==============================] - 0s - loss: 12.6169 - val_loss: 169.5956\n",
      "Epoch 873/1000\n",
      "700/700 [==============================] - 0s - loss: 9.5558 - val_loss: 217.6034\n",
      "Epoch 874/1000\n",
      "700/700 [==============================] - 0s - loss: 13.4510 - val_loss: 265.0715\n",
      "Epoch 875/1000\n",
      "700/700 [==============================] - 0s - loss: 8.8354 - val_loss: 142.8692\n",
      "Epoch 876/1000\n",
      "700/700 [==============================] - 0s - loss: 11.8906 - val_loss: 146.6738\n",
      "Epoch 877/1000\n",
      "700/700 [==============================] - 0s - loss: 9.1312 - val_loss: 208.9561\n",
      "Epoch 878/1000\n",
      "700/700 [==============================] - 0s - loss: 10.4697 - val_loss: 290.6528\n",
      "Epoch 879/1000\n",
      "700/700 [==============================] - 0s - loss: 13.8578 - val_loss: 177.5920\n",
      "Epoch 880/1000\n",
      "700/700 [==============================] - 0s - loss: 10.5277 - val_loss: 195.1577\n",
      "Epoch 881/1000\n",
      "700/700 [==============================] - 0s - loss: 10.9259 - val_loss: 222.0059\n",
      "Epoch 882/1000\n",
      "700/700 [==============================] - 0s - loss: 12.3437 - val_loss: 167.2899\n",
      "Epoch 883/1000\n",
      "700/700 [==============================] - 0s - loss: 9.4853 - val_loss: 151.3071\n",
      "Epoch 884/1000\n",
      "700/700 [==============================] - 0s - loss: 10.0870 - val_loss: 142.8405\n",
      "Epoch 885/1000\n",
      "700/700 [==============================] - 0s - loss: 11.4016 - val_loss: 154.5756\n",
      "Epoch 886/1000\n",
      "700/700 [==============================] - 0s - loss: 11.1300 - val_loss: 174.5330\n",
      "Epoch 887/1000\n",
      "700/700 [==============================] - 0s - loss: 12.8707 - val_loss: 171.0062\n",
      "Epoch 888/1000\n",
      "700/700 [==============================] - 0s - loss: 9.0964 - val_loss: 200.3260\n",
      "Epoch 889/1000\n",
      "700/700 [==============================] - 0s - loss: 10.2891 - val_loss: 148.5479\n",
      "Epoch 890/1000\n",
      "700/700 [==============================] - 0s - loss: 13.1611 - val_loss: 160.4779\n",
      "Epoch 891/1000\n",
      "700/700 [==============================] - 0s - loss: 8.3099 - val_loss: 140.2901\n",
      "Epoch 892/1000\n",
      "700/700 [==============================] - 0s - loss: 12.4628 - val_loss: 145.9023\n",
      "Epoch 893/1000\n",
      "700/700 [==============================] - 0s - loss: 10.3801 - val_loss: 149.5439\n",
      "Epoch 894/1000\n",
      "700/700 [==============================] - 0s - loss: 12.8651 - val_loss: 155.5121\n",
      "Epoch 895/1000\n",
      "700/700 [==============================] - 0s - loss: 9.1361 - val_loss: 146.0950\n",
      "Epoch 896/1000\n",
      "700/700 [==============================] - 0s - loss: 12.2736 - val_loss: 148.5507\n",
      "Epoch 897/1000\n",
      "700/700 [==============================] - 0s - loss: 11.9529 - val_loss: 179.1806\n",
      "Epoch 898/1000\n",
      "700/700 [==============================] - 0s - loss: 10.2188 - val_loss: 241.9837\n",
      "Epoch 899/1000\n",
      "700/700 [==============================] - 0s - loss: 12.1349 - val_loss: 165.2505\n",
      "Epoch 900/1000\n",
      "700/700 [==============================] - 0s - loss: 9.8969 - val_loss: 168.0397\n",
      "Epoch 901/1000\n",
      "700/700 [==============================] - 0s - loss: 13.2305 - val_loss: 172.0789\n",
      "Epoch 902/1000\n",
      "700/700 [==============================] - 0s - loss: 11.5151 - val_loss: 190.0701\n",
      "Epoch 903/1000\n",
      "700/700 [==============================] - 0s - loss: 7.8626 - val_loss: 196.0796\n",
      "Epoch 904/1000\n",
      "700/700 [==============================] - 0s - loss: 9.1637 - val_loss: 196.4888\n",
      "Epoch 905/1000\n",
      "700/700 [==============================] - 0s - loss: 11.7083 - val_loss: 155.7634\n",
      "Epoch 906/1000\n",
      "700/700 [==============================] - 0s - loss: 11.9283 - val_loss: 143.3176\n",
      "Epoch 907/1000\n",
      "700/700 [==============================] - 0s - loss: 9.4659 - val_loss: 150.4013\n",
      "Epoch 908/1000\n",
      "700/700 [==============================] - 0s - loss: 9.8135 - val_loss: 241.3279\n",
      "Epoch 909/1000\n",
      "700/700 [==============================] - 0s - loss: 12.4812 - val_loss: 149.8900\n",
      "Epoch 910/1000\n",
      "700/700 [==============================] - 0s - loss: 12.7878 - val_loss: 141.7066\n",
      "Epoch 911/1000\n",
      "700/700 [==============================] - 0s - loss: 10.2776 - val_loss: 165.9266\n",
      "Epoch 912/1000\n",
      "700/700 [==============================] - 0s - loss: 10.1767 - val_loss: 173.8345\n",
      "Epoch 913/1000\n",
      "700/700 [==============================] - 0s - loss: 7.7604 - val_loss: 218.7650\n",
      "Epoch 914/1000\n",
      "700/700 [==============================] - 0s - loss: 15.2635 - val_loss: 178.5529\n",
      "Epoch 915/1000\n",
      "700/700 [==============================] - 0s - loss: 8.4049 - val_loss: 240.7532\n",
      "Epoch 916/1000\n",
      "700/700 [==============================] - 0s - loss: 11.0259 - val_loss: 202.2575\n",
      "Epoch 917/1000\n",
      "700/700 [==============================] - 0s - loss: 10.9628 - val_loss: 221.7793\n",
      "Epoch 918/1000\n",
      "700/700 [==============================] - 0s - loss: 9.8962 - val_loss: 175.3724\n",
      "Epoch 919/1000\n",
      "700/700 [==============================] - 0s - loss: 11.3726 - val_loss: 168.6271\n",
      "Epoch 920/1000\n",
      "700/700 [==============================] - 0s - loss: 7.8039 - val_loss: 148.3442\n",
      "Epoch 921/1000\n",
      "700/700 [==============================] - 0s - loss: 13.2178 - val_loss: 153.9333\n",
      "Epoch 922/1000\n",
      "700/700 [==============================] - 0s - loss: 10.0898 - val_loss: 149.5033\n",
      "Epoch 923/1000\n",
      "700/700 [==============================] - 0s - loss: 10.2140 - val_loss: 154.8721\n",
      "Epoch 924/1000\n",
      "700/700 [==============================] - 0s - loss: 9.4041 - val_loss: 144.9727\n",
      "Epoch 925/1000\n",
      "700/700 [==============================] - 0s - loss: 13.4860 - val_loss: 167.6660\n",
      "Epoch 926/1000\n",
      "700/700 [==============================] - 0s - loss: 7.5640 - val_loss: 168.8217\n",
      "Epoch 927/1000\n",
      "700/700 [==============================] - 0s - loss: 9.6979 - val_loss: 148.4038\n",
      "Epoch 928/1000\n",
      "700/700 [==============================] - 0s - loss: 13.6264 - val_loss: 146.8911\n",
      "Epoch 929/1000\n",
      "700/700 [==============================] - 0s - loss: 7.6603 - val_loss: 159.3117\n",
      "Epoch 930/1000\n",
      "700/700 [==============================] - 0s - loss: 12.6018 - val_loss: 148.6498\n",
      "Epoch 931/1000\n",
      "700/700 [==============================] - 0s - loss: 10.8668 - val_loss: 158.0120\n",
      "Epoch 932/1000\n",
      "700/700 [==============================] - 0s - loss: 8.7254 - val_loss: 182.8036\n",
      "Epoch 933/1000\n",
      "700/700 [==============================] - 0s - loss: 10.5529 - val_loss: 176.6055\n",
      "Epoch 934/1000\n",
      "700/700 [==============================] - 0s - loss: 8.4191 - val_loss: 182.6094\n",
      "Epoch 935/1000\n",
      "700/700 [==============================] - 0s - loss: 12.2840 - val_loss: 225.8378\n",
      "Epoch 936/1000\n",
      "700/700 [==============================] - 0s - loss: 10.9097 - val_loss: 161.1505\n",
      "Epoch 937/1000\n",
      "700/700 [==============================] - 0s - loss: 9.8500 - val_loss: 172.2720\n",
      "Epoch 938/1000\n",
      "700/700 [==============================] - 0s - loss: 9.9938 - val_loss: 146.4222\n",
      "Epoch 939/1000\n",
      "700/700 [==============================] - 0s - loss: 9.2610 - val_loss: 157.6789\n",
      "Epoch 940/1000\n",
      "700/700 [==============================] - 0s - loss: 9.2326 - val_loss: 219.7556\n",
      "Epoch 941/1000\n",
      "700/700 [==============================] - 0s - loss: 12.8525 - val_loss: 198.6234\n",
      "Epoch 942/1000\n",
      "700/700 [==============================] - 0s - loss: 8.6442 - val_loss: 222.6298\n",
      "Epoch 943/1000\n",
      "700/700 [==============================] - 0s - loss: 11.3058 - val_loss: 251.3918\n",
      "Epoch 944/1000\n",
      "700/700 [==============================] - 0s - loss: 11.7207 - val_loss: 220.7030\n",
      "Epoch 945/1000\n",
      "700/700 [==============================] - 0s - loss: 10.3650 - val_loss: 193.8518\n",
      "Epoch 946/1000\n",
      "700/700 [==============================] - 0s - loss: 11.4098 - val_loss: 193.5879\n",
      "Epoch 947/1000\n",
      "700/700 [==============================] - 0s - loss: 8.7244 - val_loss: 267.9777\n",
      "Epoch 948/1000\n",
      "700/700 [==============================] - 0s - loss: 11.0514 - val_loss: 195.8315\n",
      "Epoch 949/1000\n",
      "700/700 [==============================] - 0s - loss: 12.2578 - val_loss: 232.2365\n",
      "Epoch 950/1000\n",
      "700/700 [==============================] - 0s - loss: 10.3664 - val_loss: 171.2163\n",
      "Epoch 951/1000\n",
      "700/700 [==============================] - 0s - loss: 8.9554 - val_loss: 153.5146\n",
      "Epoch 952/1000\n",
      "700/700 [==============================] - 0s - loss: 10.2722 - val_loss: 165.2838\n",
      "Epoch 953/1000\n",
      "700/700 [==============================] - 0s - loss: 7.1578 - val_loss: 212.9541\n",
      "Epoch 954/1000\n",
      "700/700 [==============================] - 0s - loss: 12.7958 - val_loss: 184.5313\n",
      "Epoch 955/1000\n",
      "700/700 [==============================] - 0s - loss: 9.0764 - val_loss: 162.7529\n",
      "Epoch 956/1000\n",
      "700/700 [==============================] - 0s - loss: 7.9024 - val_loss: 258.7770\n",
      "Epoch 957/1000\n",
      "700/700 [==============================] - 0s - loss: 12.9623 - val_loss: 151.7169\n",
      "Epoch 958/1000\n",
      "700/700 [==============================] - 0s - loss: 11.0161 - val_loss: 148.4948\n",
      "Epoch 959/1000\n",
      "700/700 [==============================] - 0s - loss: 8.9851 - val_loss: 150.4096\n",
      "Epoch 960/1000\n",
      "700/700 [==============================] - 0s - loss: 9.8479 - val_loss: 161.1264\n",
      "Epoch 961/1000\n",
      "700/700 [==============================] - 0s - loss: 8.7365 - val_loss: 210.2423\n",
      "Epoch 962/1000\n",
      "700/700 [==============================] - 0s - loss: 13.3866 - val_loss: 204.0159\n",
      "Epoch 963/1000\n",
      "700/700 [==============================] - 0s - loss: 9.6222 - val_loss: 211.9332\n",
      "Epoch 964/1000\n",
      "700/700 [==============================] - 0s - loss: 10.7917 - val_loss: 177.3411\n",
      "Epoch 965/1000\n",
      "700/700 [==============================] - 0s - loss: 8.5611 - val_loss: 144.2024\n",
      "Epoch 966/1000\n",
      "700/700 [==============================] - 0s - loss: 10.8183 - val_loss: 153.5900\n",
      "Epoch 967/1000\n",
      "700/700 [==============================] - 0s - loss: 11.9043 - val_loss: 210.9323\n",
      "Epoch 968/1000\n",
      "700/700 [==============================] - 0s - loss: 11.0452 - val_loss: 160.0995\n",
      "Epoch 969/1000\n",
      "700/700 [==============================] - 0s - loss: 7.7688 - val_loss: 164.6523\n",
      "Epoch 970/1000\n",
      "700/700 [==============================] - 0s - loss: 8.8836 - val_loss: 158.5727\n",
      "Epoch 971/1000\n",
      "700/700 [==============================] - 0s - loss: 9.9069 - val_loss: 235.6795\n",
      "Epoch 972/1000\n",
      "700/700 [==============================] - 0s - loss: 13.8018 - val_loss: 171.4466\n",
      "Epoch 973/1000\n",
      "700/700 [==============================] - 0s - loss: 8.5979 - val_loss: 143.3822\n",
      "Epoch 974/1000\n",
      "700/700 [==============================] - 0s - loss: 7.4804 - val_loss: 154.2128\n",
      "Epoch 975/1000\n",
      "700/700 [==============================] - 0s - loss: 11.4321 - val_loss: 148.3998\n",
      "Epoch 976/1000\n",
      "700/700 [==============================] - 0s - loss: 11.2283 - val_loss: 150.7723\n",
      "Epoch 977/1000\n",
      "700/700 [==============================] - 0s - loss: 8.6079 - val_loss: 145.1641\n",
      "Epoch 978/1000\n",
      "700/700 [==============================] - 0s - loss: 12.1028 - val_loss: 145.0668\n",
      "Epoch 979/1000\n",
      "700/700 [==============================] - 0s - loss: 10.2328 - val_loss: 148.5647\n",
      "Epoch 980/1000\n",
      "700/700 [==============================] - 0s - loss: 11.0902 - val_loss: 154.3944\n",
      "Epoch 981/1000\n",
      "700/700 [==============================] - 0s - loss: 9.6124 - val_loss: 147.5698\n",
      "Epoch 982/1000\n",
      "700/700 [==============================] - 0s - loss: 10.1868 - val_loss: 152.7643\n",
      "Epoch 983/1000\n",
      "700/700 [==============================] - 0s - loss: 9.1155 - val_loss: 150.8485\n",
      "Epoch 984/1000\n",
      "700/700 [==============================] - 0s - loss: 12.1316 - val_loss: 150.0450\n",
      "Epoch 985/1000\n",
      "700/700 [==============================] - 0s - loss: 8.0566 - val_loss: 152.0758\n",
      "Epoch 986/1000\n",
      "700/700 [==============================] - 0s - loss: 13.5374 - val_loss: 144.1397\n",
      "Epoch 987/1000\n",
      "700/700 [==============================] - 0s - loss: 8.4389 - val_loss: 156.0043\n",
      "Epoch 988/1000\n",
      "700/700 [==============================] - 0s - loss: 9.2682 - val_loss: 150.8184\n",
      "Epoch 989/1000\n",
      "700/700 [==============================] - 0s - loss: 12.3427 - val_loss: 152.2112\n",
      "Epoch 990/1000\n",
      "700/700 [==============================] - 0s - loss: 9.9568 - val_loss: 164.0760\n",
      "Epoch 991/1000\n",
      "700/700 [==============================] - 0s - loss: 10.1194 - val_loss: 162.3687\n",
      "Epoch 992/1000\n",
      "700/700 [==============================] - 0s - loss: 9.3461 - val_loss: 140.1459\n",
      "Epoch 993/1000\n",
      "700/700 [==============================] - 0s - loss: 10.5919 - val_loss: 150.4158\n",
      "Epoch 994/1000\n",
      "700/700 [==============================] - 0s - loss: 10.3906 - val_loss: 180.3555\n",
      "Epoch 995/1000\n",
      "700/700 [==============================] - 0s - loss: 8.6041 - val_loss: 215.7613\n",
      "Epoch 996/1000\n",
      "700/700 [==============================] - 0s - loss: 10.5929 - val_loss: 228.6602\n",
      "Epoch 997/1000\n",
      "700/700 [==============================] - 0s - loss: 9.3416 - val_loss: 187.9840\n",
      "Epoch 998/1000\n",
      "700/700 [==============================] - 0s - loss: 14.2943 - val_loss: 182.4368\n",
      "Epoch 999/1000\n",
      "700/700 [==============================] - 0s - loss: 7.6071 - val_loss: 159.5882\n",
      "Epoch 1000/1000\n",
      "700/700 [==============================] - 0s - loss: 8.1631 - val_loss: 140.1770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c5bfa50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/100 [========>.....................] - ETA: 0s160.230983276\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAJPCAYAAABcoIE1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w8QDDFhgWOtxwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e2e8910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0. 사용할 패키지 불러오기\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "width = 16\n",
    "height = 16\n",
    "\n",
    "def generate_dataset(samples):\n",
    "\n",
    "    ds_x = []\n",
    "    ds_y = []\n",
    "    \n",
    "    for it in range(samples):\n",
    "        \n",
    "        num_pt = np.random.randint(0, width * height)\n",
    "        img = generate_image(num_pt)\n",
    "        \n",
    "        ds_y.append(num_pt)\n",
    "        ds_x.append(img)\n",
    "    \n",
    "    return np.array(ds_x), np.array(ds_y).reshape(samples, 1)\n",
    "    \n",
    "def generate_image(points):\n",
    "    \n",
    "    img = np.zeros((width, height))\n",
    "    pts = np.random.random((points, 2))\n",
    "    \n",
    "    for ipt in pts:\n",
    "        img[int(ipt[0] * width), int(ipt[1] * height)] = 1\n",
    "    \n",
    "    return img.reshape(width, height, 1)\n",
    "\n",
    "# 1. 데이터셋 생성하기\n",
    "x_train, y_train = generate_dataset(700)\n",
    "x_val, y_val = generate_dataset(300)\n",
    "x_test, y_test = generate_dataset(100)\n",
    "\n",
    "x_train_1d = x_train.reshape(x_train.shape[0], width*height)\n",
    "x_val_1d = x_val.reshape(x_val.shape[0], width*height)\n",
    "x_test_1d = x_test.reshape(x_test.shape[0], width*height)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim = width*height))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "\n",
    "# 5. 모델 학습시키기\n",
    "hist = model.fit(x_train_1d, y_train, batch_size=32, epochs=1000, validation_data=(x_val_1d, y_val))\n",
    "\n",
    "# 6. 학습과정 살펴보기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylim(0.0, 1000)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 7. 모델 평가하기\n",
    "score = model.evaluate(x_test_1d, y_test, batch_size=32)\n",
    "\n",
    "print(score)\n",
    "\n",
    "# 8. 모델 사용하기\n",
    "yhat_test = model.predict(x_test_1d, batch_size=32)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "    sub_plt = axarr[i/plt_row, i%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_test[i].reshape(width, height))\n",
    "    sub_plt.set_title('R %d P %.1f' % (y_test[i][0], yhat_test[i][0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 컨볼루션 신경망 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "width = 16\n",
    "height = 16\n",
    "\n",
    "def generate_dataset(samples):\n",
    "\n",
    "    ds_x = []\n",
    "    ds_y = []\n",
    "    \n",
    "    for it in range(samples):\n",
    "        \n",
    "        num_pt = np.random.randint(0, width * height)\n",
    "        img = generate_image(num_pt)\n",
    "        \n",
    "        ds_y.append(num_pt)\n",
    "        ds_x.append(img)\n",
    "    \n",
    "    return np.array(ds_x), np.array(ds_y).reshape(samples, 1)\n",
    "    \n",
    "def generate_image(points):\n",
    "    \n",
    "    img = np.zeros((width, height))\n",
    "    pts = np.random.random((points, 2))\n",
    "    \n",
    "    for ipt in pts:\n",
    "        img[int(ipt[0] * width), int(ipt[1] * height)] = 1\n",
    "    \n",
    "    return img.reshape(width, height, 1)\n",
    "\n",
    "x_train, y_train = generate_dataset(1000)\n",
    "x_test, y_test = generate_dataset(100)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=1000)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)\n",
    "\n",
    "print(score)\n",
    "\n",
    "yhat_test = model.predict(x_test_1d, batch_size=32)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "    sub_plt = axarr[i/plt_row, i%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_test[i].reshape(width, height))\n",
    "    sub_plt.set_title('R %d P %.1f' % (y_test[i][0], yhat_test[i][0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 요약\n",
    "\n",
    "N/A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "### 같이 보기\n",
    "\n",
    "* [강좌 목차](https://tykimos.github.io/Keras/lecture/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
