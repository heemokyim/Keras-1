{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title:  \"다층 퍼셉트론 모델 만들어보기\"\n",
    "author: Taeyoung, Kim\n",
    "date:   2017-02-04 00:00:00\n",
    "categories: Keras\n",
    "comments: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named model_selection",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-98b5332ae539>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscikit_learn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named model_selection"
     ]
    }
   ],
   "source": [
    "# Regression Example With Boston Dataset: Baseline\n",
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# load dataset\n",
    "dataframe = pandas.read_csv(\"housing.data\", delim_whitespace=True, header=None)\n",
    "dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:13]\n",
    "Y = dataset[:,13]\n",
    "\n",
    "# define base model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=13, init='normal', activation='relu'))\n",
    "    model.add(Dense(1, init='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Baseline: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본 강좌에서는 간단한 다층 퍼셉트론을 만들어보면서 다음 항목들에 대해서 살펴봅니다.\n",
    "\n",
    "* 케라스를 사용하기 위한 CSV 데이터셋 로딩하는 법\n",
    "* 다층 퍼셉트론 (Multilayer Perceptron)을 정의하고 컴파일하는 법\n",
    "\n",
    "다음과 같은 순서로 진행하겠습니다.\n",
    "\n",
    "1. 데이터셋 준비하기\n",
    "1. 모델 구성하기\n",
    "1. 모델 엮기\n",
    "1. 모델 학습시키기\n",
    "1. 모델 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 데이터셋 준비하기\n",
    "\n",
    "피마족 인디언 당뇨병 발병 데이터셋\n",
    "\n",
    "- 인스턴스 수 : 768개\n",
    "- 특징 수 : 8가지\n",
    "- 클래스 수 : 2가지\n",
    "\n",
    "8가지 특징(1번~8번)과 결과(9번)\n",
    "\n",
    "1. 임신 횟수\n",
    "2. 경구 포도당 내성 검사에서 2시간 동안의 혈장 포도당 농도\n",
    "3. 확장기 혈압 (mm Hg)\n",
    "4. 삼두근 피부의 접은 두께 (mm)\n",
    "5. 2 시간 혈청 인슐린 (mu U/ml)\n",
    "6. 체질량 지수\n",
    "7. 당뇨병 혈통 함수\n",
    "8. 나이 (세)\n",
    "9. 5년 이내 당뇨병이 발병 여부\n",
    "\n",
    "데이터셋 샘플\n",
    "\n",
    "    6,148,72,35,0,33.6,0.627,50,1\n",
    "    1,85,66,29,0,26.6,0.351,31,0\n",
    "    8,183,64,0,0,23.3,0.672,32,1\n",
    "    1,89,66,23,94,28.1,0.167,21,0\n",
    "    0,137,40,35,168,43.1,2.288,33,1\n",
    "    \n",
    "좀 더 살펴보면, 양성인 경우가 268개(34.9%), 음성인 경우가 500개(65.1%)이다. 즉 모델이 모두 음성이라고 판별을 한다하더라도 65.1%의 기본 정확도(baseline accuracy)를 달성할 수 있다. 현존하는 최대 정확도는 10-fold 교차검증(cross validataion) 했을 때 77.7%이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv 파일은 loadtxt()로 직접 불러올 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"./warehouse/pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 모델 구성하기\n",
    "\n",
    "Dense 클래스를 사용하여 완전 연결 레이어(Fully Connected Layer)를 정의할 수 있다.\n",
    "\n",
    "- 첫번째 인자 : 뉴런의 수\n",
    "- 두번째 인자 : 네트워크 가중치(network weight) 초기화 방법\n",
    " - uniform : 균등분포 (uniform distribution)의 작은 난수들로 초기화 (0~0.05 사이)\n",
    " - normal : 가우시안 분포 (Gaussian distribution)로 생성된 작은 난수들로 초기화 \n",
    "- 세번째 인자 : 활성화 함수(activation function) 지정\n",
    " - relu : rectifier 활성화 함수\n",
    " - sigmoid : sigmoid 활성화 함수\n",
    " - tanh : tanh 활성화 함수\n",
    " \n",
    "마지막 레이어는 sigmoid 할성화 함수를 사용하는데, 이유는 결과가 0과 1사이로 나오는 것을 보장하며, 양성 클래스의 확률로 쉽게 매핑할 수 있기 때문이다. 또한 0.5 임계치(threshold)을 같은 클래스의 범주형 분류(hard classification)를 할 수 있다.\n",
    "\n",
    "- 첫번째 은닉층(hidden layer)는 12개 뉴런을 가지고, 8개 입력을 받아들인다.\n",
    "- 두번째 은닉층은 8개 뉴런을 가진다.\n",
    "- 마지막 레이어는 클래스를 예측하는 1개의 뉴런을 가진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3a5fa26e608e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# pip install pydot-ng\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mSVG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "# brew install graphviz\n",
    "# pip uninstall -y pydot\n",
    "# pip install pydot-ng\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![svg]({{ site.baseurl }}/posts_warehouse/2017-2-4-1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 모델 엮기\n",
    "\n",
    "컴파일 시에 정의해야하는 것들\n",
    "- 가중치 세트를 평가하는 데 사용할 손실함수(loss function)\n",
    " - binary_crossentropy : 이진 분류를 위한 logarithmic loss\n",
    "- 네트워크의 다른 가중치를 검객하는 데 사용되는 최적화 알고리즘\n",
    " - adam : 효율적인 경사 하강법(gradient descent) 알고리즘\n",
    "- 학습과정에서 수집하기 싶은 측정 기준"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 모델 학습시키기\n",
    "\n",
    "- nb_epoch : 데이터셋에 대한 반복 횟수\n",
    "- batch_size : 네트워크에서 가중치 개갱신 전에 평가되는 인스턴스의 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "768/768 [==============================] - 0s - loss: 0.6826 - acc: 0.6328     \n",
      "Epoch 2/10\n",
      "768/768 [==============================] - 0s - loss: 0.6590 - acc: 0.6510     \n",
      "Epoch 3/10\n",
      "768/768 [==============================] - 0s - loss: 0.6475 - acc: 0.6549     \n",
      "Epoch 4/10\n",
      "768/768 [==============================] - 0s - loss: 0.6416 - acc: 0.6615     \n",
      "Epoch 5/10\n",
      "768/768 [==============================] - 0s - loss: 0.6216 - acc: 0.6745     \n",
      "Epoch 6/10\n",
      "768/768 [==============================] - 0s - loss: 0.6128 - acc: 0.6680     \n",
      "Epoch 7/10\n",
      "768/768 [==============================] - 0s - loss: 0.6018 - acc: 0.6927     \n",
      "Epoch 8/10\n",
      "768/768 [==============================] - 0s - loss: 0.5962 - acc: 0.6927     \n",
      "Epoch 9/10\n",
      "768/768 [==============================] - 0s - loss: 0.5991 - acc: 0.6953     \n",
      "Epoch 10/10\n",
      "768/768 [==============================] - 0s - loss: 0.5920 - acc: 0.6927     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x106873b90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X, Y, nb_epoch=10, batch_size=10) # nb_epoch 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 모델 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s     \n",
      "acc: 70.18%\n"
     ]
    }
   ],
   "source": [
    "# evaliuate\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "### 같이 보기\n",
    "\n",
    "* [강좌 목차](https://tykimos.github.io/Keras/2017/01/27/Keras_Lecture_Plan/)\n",
    "* 이전 : [딥러닝 이야기/레이어 이야기](https://tykimos.github.io/Keras/2017/01/27/Layer_Talk/)\n",
    "* 다음 : [딥러닝 기본 실습/컨볼루션 신경망 모델 만들어보기](https://tykimos.github.io/Keras/2017/02/04/CNN_Getting_Started/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
